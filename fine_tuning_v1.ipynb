{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUPM_w4HjJ3U"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "203bvpDsQLUW"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import tiktoken\n",
    "from transformers import GPT2Tokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from torchsummaryX import summary\n",
    "import wandb\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from multiprocessing import cpu_count\n",
    "import random\n",
    "import gc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LovtcItVQLUX"
   },
   "outputs": [],
   "source": [
    "# set seeds\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = False\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_H8zHj2Swll"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68u9am1JSzIX",
    "outputId": "13e957ad-9193-40f8-8423-f2960c9e4f15"
   },
   "outputs": [],
   "source": [
    "datasets_train = load_dataset(\"Shannnh/hw5-changed\", split = 'train')\n",
    "datasets_val = load_dataset(\"Shannnh/hw5-changed\", split = 'validation')\n",
    "datasets_test = load_dataset(\"Shannnh/hw5-changed\", split = 'test_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m40ZM0re8-RR",
    "outputId": "95fcac78-6bd7-4a4e-aa07-301989b5cb47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Classifier', 'Prompt', 'Messages', 'PromptId'])\n",
      "392632\n",
      "27664\n",
      "15434\n"
     ]
    }
   ],
   "source": [
    "print(datasets_train[0].keys())\n",
    "print(len(datasets_train))\n",
    "print(len(datasets_val))\n",
    "print(len(datasets_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_train = datasets_train.shuffle(seed=42).select(range(100))\n",
    "datasets_val = datasets_val.shuffle(seed=42).select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Question&Answer', 'Summarization', 'NamedEntity']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_train.unique('Classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-849v2wQQLUX"
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Prz8c1bYQLUY",
    "outputId": "00ae83ef-d32f-4dc3-c3a2-5e955407869c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IDeaLGPTConfig(batch_size=8, gradient_accumulation_steps=4, num_iters=10000, eval_iters=3, eval_interval=1000, device='cuda', sequence_length=256, vocab_size=50257, num_blocks=8, num_heads=8, embed_dim=512, dropout=0.1, bias=False, num_workers=8, train_test_split=0.8, SUBSET_PERCENTAGE=0.01, lr=0.002, lr_decay=True, warmup_iters=1000, min_lr=6e-06, weight_decay=0.1, grad_clip=1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass\n",
    "class IDeaLGPTConfig:\n",
    "\n",
    "    # General\n",
    "    batch_size: int = 8 # 16\n",
    "    gradient_accumulation_steps: int = 4\n",
    "    num_iters: int = 10000\n",
    "    eval_iters: int = 3\n",
    "    eval_interval: int = 1000\n",
    "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # device: str = 'cpu'\n",
    "\n",
    "    # Model\n",
    "    sequence_length: int = 256\n",
    "    vocab_size: int = 50257 # gpt2 vocab\n",
    "    num_blocks: int = 8\n",
    "    num_heads: int = 8\n",
    "    embed_dim: int = 512\n",
    "    dropout: float = 0.1\n",
    "    bias: bool = False\n",
    "\n",
    "    # Data\n",
    "    num_workers: int = 8\n",
    "    train_test_split: float = 0.8\n",
    "    SUBSET_PERCENTAGE: float =0.01 # % of OWT to train on, between 0 and 1\n",
    "\n",
    "    # LR scheduler\n",
    "    lr: float = 2e-3\n",
    "    lr_decay: bool = True\n",
    "    warmup_iters: int = 1000\n",
    "    min_lr: float = 6e-6\n",
    "\n",
    "    # optimizer\n",
    "    weight_decay: float = 1e-1\n",
    "    grad_clip: float = 1.0\n",
    "\n",
    "\n",
    "config = IDeaLGPTConfig()\n",
    "device = config.device\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4IkXs4hTQLUZ",
    "outputId": "1bb56acf-d9c3-4420-f94e-8d5db87cad31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective batch size = 32\n"
     ]
    }
   ],
   "source": [
    "print(f'Effective batch size = {config.batch_size * config.gradient_accumulation_steps}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6FXk8H1QLUZ"
   },
   "source": [
    "# Loading Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FF87zNglQLUZ"
   },
   "outputs": [],
   "source": [
    "# hf_dataset = load_dataset(\"Skylion007/openwebtext\", split='train') # only has one split - train\n",
    "# hf_dataset = hf_dataset.with_format(\"torch\")\n",
    "# hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Z-UOmFJFQLUZ"
   },
   "outputs": [],
   "source": [
    "# # data = dataset['train'].shuffle(seed=42).select(range(int(len(dataset['train']) * SUBSET_PERCENTAGE)))\n",
    "# # hf_dataset = hf_dataset.select(range(int(len(hf_dataset) * config.SUBSET_PERCENTAGE)))\n",
    "# hf_dataset = hf_dataset.train_test_split(train_size=config.train_test_split)\n",
    "# hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0DljsEgbQLUZ"
   },
   "outputs": [],
   "source": [
    "# train_hf_dataset, val_hf_dataset = hf_dataset['train'], hf_dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bKU7Y-6QLUZ"
   },
   "source": [
    "## Tokenizer - OpenAI tiktoken (changed to GPT2Tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvwoPFbiQLUZ",
    "outputId": "9752f1ea-9efb-41ca-99ec-76c867ba2dd5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31373, 995]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenizer = tiktoken.get_encoding(\"cl100k_base\") # gpt4 tokenizer - NOTE: need to change vocab_size in config if used\n",
    "#tokenizer = tiktoken.encoding_for_model('gpt-2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.encode('hello world')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "bsUdOVMmjFJ1"
   },
   "outputs": [],
   "source": [
    "tokenizer.model_max_length = config.sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "h_0F5g1T81XC"
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OAqwxz2xzasy",
    "outputId": "dd2b680a-7b13-490f-f283-18e1d720fa34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = tokenizer.vocab_size #same as tiktoken\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "lFDoKw26tevh"
   },
   "outputs": [],
   "source": [
    "# set pad_token_id equal to the eos_token_id if not set\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ZcD3xq9d1PvS"
   },
   "outputs": [],
   "source": [
    "DEFAULT_CHAT_TEMPLATE = \"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + ' '.join(message['content'].split()[:150]) + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\"\n",
    "tokenizer.chat_template = DEFAULT_CHAT_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "642e89fcada04c16a34b469b21bf80c7",
      "66a71622ed53488ebabc61778e624b96",
      "abf72b3336b14d82b59cfc42b91f4f41",
      "067898ad433a455e8deb863494b7a428",
      "2719a96cddd74b32870d18f31f4ad293",
      "b7403d3083e740208a18888a170f975e",
      "64ff9a51f7264cb68d848f111b0e6857",
      "307746d700d34a94b2a5d2612ff2efb0",
      "024d4f026f184760a2f3b4eb2c624a95",
      "e0d25851a01942868ce5d5e4d76ad284",
      "12257421e51e4a7a916880b5fb690d90"
     ]
    },
    "id": "MbRQjaafylLA",
    "outputId": "dbea003d-9430-4b00-be64-2f72ba56189d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c08391040d394647951b439bd1bbddce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template (num_proc=40):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 10. Reducing num_proc to 10 for dataset of size 10.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e303bf8b9d4432974a922ccb5373f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template (num_proc=10):   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7788e8261a24579b1c22eb44f02d332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template (num_proc=40):   0%|          | 0/15434 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def apply_chat_template(example, tokenizer):\n",
    "    messages = example[\"Messages\"]\n",
    "    #\n",
    "    example[\"text\"] = tokenizer.apply_chat_template(messages, tokenize=False, max_length=config.sequence_length, truncation=True)\n",
    "    example[\"tokens\"] = tokenizer.apply_chat_template(messages, tokenize=True, max_length=config.sequence_length, truncation=True)\n",
    "    return example\n",
    "\n",
    "column_names = list(datasets_train.features)\n",
    "datasets_train = datasets_train.map(apply_chat_template,\n",
    "                                num_proc=cpu_count(),\n",
    "                                fn_kwargs={\"tokenizer\": tokenizer},\n",
    "                                remove_columns=column_names,\n",
    "                                desc=\"Applying chat template\")\n",
    "datasets_val = datasets_val.map(apply_chat_template,\n",
    "                                num_proc=cpu_count(),\n",
    "                                fn_kwargs={\"tokenizer\": tokenizer},\n",
    "                                remove_columns=column_names,\n",
    "                                desc=\"Applying chat template\")\n",
    "datasets_test = datasets_test.map(apply_chat_template,\n",
    "                                num_proc=cpu_count(),\n",
    "                                fn_kwargs={\"tokenizer\": tokenizer},\n",
    "                                remove_columns=column_names,\n",
    "                                desc=\"Applying chat template\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "rPgMqZiO4bae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1 of the processed training set:\n",
      "\n",
      "<|system|>\n",
      "<|endoftext|>\n",
      "<|user|>\n",
      "Summarize the following CNN article: A New South Wales company has been forced to settle a tab of more than $10,000 with the ACCC, after it advertised '100 per cent Aussie' beer that was actually made in China. The Independent Liquor Group was hit with an infringement notice by the Australian Competition and Consumer Commission, and had to pay the fine of $10,200 after its green and gold clad beer was falsely advertised. Independent Liquor Group was fined for advertising this Chinese brewed beer as 'Aussie beer' 'Aussie Beer' labelling from March 2014 to August 2014 featured a map of Australia with '100 per cent owned' inside it, and the statement 'Australia's finest malt'. However, contrary to what its packaging suggested, the beer is made in China. The ACCC dished out the penalty in accordance with the Australian Consumer Law. 'Country of origin representations, particularly those designed to grab the<|endoftext|>\n",
      "<|assistant|>\n",
      "Independent Liquor Group fined $10,200 by the ACCC for false advertising .\n",
      "Beer claimed to be '100% Aussie' but is actually brewed in China .\n",
      "'Aussie Beer' with misleading labelling sold from March to August 2014 .\n",
      "Punishment handed out in line with the Australian Consumer Law .<|endoftext|>\n",
      "\n",
      "token: [27, 91, 10057, 91, 29, 198, 50256, 198, 27, 91, 7220, 91, 29, 198, 13065, 3876, 1096, 262, 1708, 8100, 2708, 25, 317, 968, 2520, 11769, 1664, 468, 587, 4137, 284, 12259, 257, 7400, 286, 517, 621, 720, 940, 11, 830, 351, 262, 15859, 34, 11, 706, 340, 23944, 705, 3064, 583, 1247, 317, 43480, 6, 6099, 326, 373, 1682, 925, 287, 2807, 13, 383, 13362, 35515, 273, 4912, 373, 2277, 351, 281, 23059, 4003, 416, 262, 6638, 27348, 290, 18110, 4513, 11, 290, 550, 284, 1414, 262, 3734, 286, 720, 940, 11, 2167, 706, 663, 4077, 290, 3869, 38186, 6099, 373, 24566, 23944, 13, 13362, 35515, 273, 4912, 373, 22643, 329, 8560, 428, 3999, 40163, 6099, 355, 705, 32, 43480, 6099, 6, 705, 32, 43480, 16971, 6, 2248, 9417, 422, 2805, 1946, 284, 2932, 1946, 8096, 257, 3975, 286, 4505, 351, 705, 3064, 583, 1247, 6898, 6, 2641, 340, 11, 290, 262, 2643, 705, 27429, 338, 18822, 26868, 4458, 2102, 11, 10388, 284, 644, 663, 16846, 5220, 11, 262, 6099, 318, 925, 287, 2807, 13, 383, 15859, 34, 595, 704, 503, 262, 7389, 287, 10213, 351, 262, 6638, 18110, 3854, 13, 705, 33921, 286, 8159, 24612, 11, 3573, 883, 3562, 284, 5552, 262, 50256, 198, 27, 91, 562, 10167, 91, 29, 198, 40566, 35515, 273, 4912, 22643, 720, 940, 11, 2167, 416, 262, 15859, 34, 329, 3991, 8560, 764, 198, 49802, 4752, 284, 307, 705, 3064, 4, 317, 43480, 6, 475, 318, 1682, 40163, 287, 2807, 764, 198, 6, 32, 43480, 16971, 6, 351, 15850]\n",
      "sample length: 1271\n",
      "token length:256\n",
      "Sample 0 of the processed training set:\n",
      "\n",
      "<|system|>\n",
      "<|endoftext|>\n",
      "<|user|>\n",
      "Summarize the following CNN article: Texas police are trying to determine the series of events leading up to a 50-year-old running into a gas station Friday morning with a gunshot wound to the face. The incident occurred at a Chevron in Fort Worth about 5.30am. CCTV shows a red Toyota quickly pulling up outside the station, with a man jumping out of the car and bolting inside. Covered in blood and pleading for help, the victim told the gas station clerk to call 911. CCTV: Footage from the Chevron in the 1000 block of Bridgewood Drive in Fort Worth show the victim quickly pulling up in his red Toyota, leaving the car running as he ran inside . 'Help': The man comes running into the gas station, covered in blood, pleading for assistance . Badly injured: The footage shows the man, with an obvious injury around his mouth . 911:<|endoftext|>\n",
      "<|assistant|>\n",
      "Victim, 50, ran into a Chevron in Fort Worth, Texas, at 5.30am Friday .\n",
      "He was covered in blood and asked staff to call 911 .\n",
      "However he refused to cooperate with police .\n",
      "Was taken to hospital with non-life-threatening injuries .\n",
      "Police believe he was shot after an altercation at an apartment complex .<|endoftext|>\n",
      "\n",
      "token: [27, 91, 10057, 91, 29, 198, 50256, 198, 27, 91, 7220, 91, 29, 198, 13065, 3876, 1096, 262, 1708, 8100, 2708, 25, 3936, 1644, 389, 2111, 284, 5004, 262, 2168, 286, 2995, 3756, 510, 284, 257, 2026, 12, 1941, 12, 727, 2491, 656, 257, 3623, 4429, 3217, 3329, 351, 257, 29444, 11699, 284, 262, 1986, 13, 383, 4519, 5091, 379, 257, 50083, 287, 6401, 22301, 546, 642, 13, 1270, 321, 13, 36983, 2523, 257, 2266, 20182, 2952, 10427, 510, 2354, 262, 4429, 11, 351, 257, 582, 14284, 503, 286, 262, 1097, 290, 11572, 889, 2641, 13, 327, 2557, 287, 2910, 290, 30279, 329, 1037, 11, 262, 3117, 1297, 262, 3623, 4429, 21120, 284, 869, 16679, 13, 36983, 25, 7870, 496, 422, 262, 50083, 287, 262, 8576, 2512, 286, 28320, 39909, 702, 9974, 287, 6401, 22301, 905, 262, 3117, 2952, 10427, 510, 287, 465, 2266, 20182, 11, 4305, 262, 1097, 2491, 355, 339, 4966, 2641, 764, 705, 22087, 10354, 383, 582, 2058, 2491, 656, 262, 3623, 4429, 11, 5017, 287, 2910, 11, 30279, 329, 6829, 764, 7772, 306, 6686, 25, 383, 9640, 2523, 262, 582, 11, 351, 281, 3489, 5095, 1088, 465, 5422, 764, 16679, 25, 50256, 198, 27, 91, 562, 10167, 91, 29, 198, 21944, 320, 11, 2026, 11, 4966, 656, 257, 50083, 287, 6401, 22301, 11, 3936, 11, 379, 642, 13, 1270, 321, 3217, 764, 198, 1544, 373, 5017, 287, 2910, 290, 1965, 3085, 284, 869, 16679, 764, 198, 4864, 339, 6520, 284, 21270, 351, 1644, 764, 198, 16973, 2077, 284, 4436, 351, 1729, 12]\n",
      "sample length: 1215\n",
      "token length:256\n"
     ]
    }
   ],
   "source": [
    "# what's in datasets now\n",
    "# datasets_train : [{'text':'abcd','tokens':[1,2,3]},{'text':'bcd','tokens':[2,3]},...]\n",
    "for index in random.sample(range(len(datasets_val)), 2):\n",
    "    print(f\"Sample {index} of the processed training set:\\n\\n{datasets_val[index]['text']}\")\n",
    "    print(f\"token: {datasets_val[index]['tokens']}\")\n",
    "    print(f\"sample length: {len(datasets_val[index]['text'])}\") \n",
    "    print(f\"token length:{len(datasets_val[index]['tokens'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (273 > 256). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 100/100 [00:00<00:00, 348.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average token length: 255.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_token_length = 0\n",
    "sample_count = len(datasets_train)\n",
    "\n",
    "# Calculate total token length across all samples\n",
    "for data in tqdm(datasets_train):\n",
    "    encoded_length = len(tokenizer.encode(data['text']))\n",
    "    total_token_length += encoded_length\n",
    "\n",
    "# Compute the average token length\n",
    "average_token_length = total_token_length / sample_count\n",
    "\n",
    "print(f\"Average token length: {average_token_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "jg0MOKomarrU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "hrfc-IpwOrFY"
   },
   "outputs": [],
   "source": [
    "# save dataset\n",
    "\n",
    "def save_dataset(dataset, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(dataset, f)\n",
    "save_dataset(datasets_train, 'data/finetune/train.bin')\n",
    "save_dataset(datasets_val, 'data/finetune/val.bin')\n",
    "save_dataset(datasets_test, 'data/finetune/test.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AghJe4bCQLUa"
   },
   "source": [
    "## Pytorch Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFzA_Ake41t5"
   },
   "source": [
    "For long texts, the current approach randomly selects segments of text that are equal to config.sequence_length. However, methods such as sliding windows could also be explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "sTYPPcyx6OtP"
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, root_dir, split):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Dataset root directory containing the data files.\n",
    "        \"\"\"\n",
    "        file_path = os.path.join(root_dir, \"train.bin\") if split == 'train' else os.path.join(root_dir, \"val.bin\")\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        tokens = sample['tokens']\n",
    "        # if the number of tokens is more than the sequence_length, randomly choose a segment\n",
    "        # if len(tokens) > config.sequence_length + 1:\n",
    "        #     num_possible_starts = len(tokens) - config.sequence_length\n",
    "        #     start = random.randint(0, num_possible_starts - 1)\n",
    "        #     segment = tokens[start:start + self.sequence_length + 1]\n",
    "        # else:\n",
    "        #     segment = tokens\n",
    "\n",
    "        if len(tokens) < config.sequence_length + 1:\n",
    "            padded_tokens = np.pad(tokens, (0, config.sequence_length + 1 - len(tokens)), 'constant', constant_values=tokenizer.pad_token_id)\n",
    "        else:\n",
    "            padded_tokens = tokens[:config.sequence_length + 1]\n",
    "\n",
    "        xb = torch.tensor(padded_tokens[:-1], dtype=torch.int64)\n",
    "        yb = torch.tensor(padded_tokens[1:], dtype=torch.int64)\n",
    "        return xb, yb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "XQJEY7Ye_v9t",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# class TestDataset(Dataset):\n",
    "#     def __init__(self, root_dir):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             root_dir (str): Dataset root directory containing the data files.\n",
    "#         \"\"\"\n",
    "#         file_path = os.path.join(root_dir, \"test.bin\")\n",
    "#         with open(file_path, 'rb') as f:\n",
    "#             data = pickle.load(f)\n",
    "#         self.data = data\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         sample = self.data[idx]\n",
    "#         tokens = sample['tokens']\n",
    "#         # if len(tokens) > config.sequence_length + 1:\n",
    "#         #     num_possible_starts = len(tokens) - config.sequence_length\n",
    "#         #     start = random.randint(0, num_possible_starts - 1)\n",
    "#         #     segment = tokens[start:start + config.sequence_length + 1]\n",
    "#         # else:\n",
    "#         #     segment = tokens\n",
    "#         if len(tokens) < config.sequence_length + 1:\n",
    "#             padded_tokens = np.pad(tokens, (0, config.sequence_length + 1 - len(tokens)), 'constant', constant_values=tokenizer.pad_token_id)\n",
    "#         else:\n",
    "#             padded_tokens = tokens[:config.sequence_length + 1]\n",
    "\n",
    "#         xb = torch.tensor(padded_tokens[:-1], dtype=torch.int64)\n",
    "#         return xb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3HIbJmBQLUa"
   },
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "y8HvMPG8QLUa"
   },
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=1)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zI90SEqFQLUb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for x, y in train_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5oYgzrkQLUb"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# poor man's dataloader\n",
    "# but actual motivation is - im too lazy to write and deal with pad tokens in above method to read data\n",
    "# since there are documents which are less than sequence length and they mess up the batch\n",
    "# this method is cleaner, i get to learn something new (np.memmap!) and it's fun!\n",
    "\n",
    "data_dir = os.path.join('data', 'owt')\n",
    "\n",
    "def get_batch(split):\n",
    "    file_path = os.path.join(data_dir, 'val' if split == 'val.bin' else 'train.bin')\n",
    "    # memmap allows to read huge .bin files without loading entire thing. magic?\n",
    "    data = np.memmap(file_path, mode='r', dtype=np.uint16) # fp16?\n",
    "    idx = torch.randint(len(data) - config.sequence_length, (config.batch_size, ))\n",
    "    xb = torch.stack([torch.from_numpy(data[i:i+config.sequence_length].astype(np.int64)) for i in idx], dim=0)\n",
    "    yb = torch.stack([torch.from_numpy(data[i+1:i+config.sequence_length+1].astype(np.int64)) for i in idx], dim=0)\n",
    "    if device == 'cuda':\n",
    "        # pin_memory is an optimization to reserve some space in cpu mem which is used for moving to gpu\n",
    "        # reduces overhead -> increases perf\n",
    "        # non_blocking = True is async data transfer\n",
    "        xb, yb = xb.pin_memory().to(device, non_blocking=True), yb.pin_memory().to(device, non_blocking=True)\n",
    "    return xb, yb\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "DXmyEb8b9PyQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "DATA_DIR        = 'data/finetune'\n",
    "\n",
    "train_dataset   = TrainDataset(\n",
    "    root_dir    = DATA_DIR,\n",
    "    split   = \"train\"\n",
    ")\n",
    "\n",
    "val_dataset     = TrainDataset(\n",
    "    root_dir    = DATA_DIR,\n",
    "    split   = \"val\"\n",
    ")\n",
    "\n",
    "# test_dataset    = TestDataset(\n",
    "#     root_dir    = DATA_DIR\n",
    "# )\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256]), torch.Size([256]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = train_dataset[0]\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "1itLTzKtB7e-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size           :  8\n",
      "Train Batches        :  13\n",
      "Val Batches          :  2\n"
     ]
    }
   ],
   "source": [
    "train_loader    = torch.utils.data.DataLoader(\n",
    "    dataset     = train_dataset,\n",
    "    batch_size  = config.batch_size,\n",
    "    shuffle     = True,\n",
    "    num_workers = 2,\n",
    "    pin_memory  = True\n",
    ")\n",
    "\n",
    "val_loader      = torch.utils.data.DataLoader(\n",
    "    dataset     = val_dataset,\n",
    "    batch_size  = config.batch_size,\n",
    "    shuffle     = False,\n",
    "    num_workers = 1,\n",
    "    pin_memory  = True\n",
    ")\n",
    "\n",
    "# test_loader     = torch.utils.data.DataLoader(\n",
    "#     dataset     = test_dataset,\n",
    "#     batch_size  = config.batch_size,\n",
    "#     shuffle     = False,\n",
    "#     num_workers = 1,\n",
    "#     pin_memory  = True\n",
    "# )\n",
    "\n",
    "print(\"Batch Size           : \", config.batch_size)\n",
    "print(\"Train Batches        : \", train_loader.__len__())\n",
    "print(\"Val Batches          : \", val_loader.__len__())\n",
    "# print(\"Test Batches         : \", test_loader.__len__())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "VIYb0gtYFenJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Shapes of the Data --\n",
      "\n",
      "xb shape:\t\ttorch.Size([8, 256])\n",
      "yb shape:\t\ttorch.Size([8, 256])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' Sanity Check '''\n",
    "\n",
    "print(\"Checking the Shapes of the Data --\\n\")\n",
    "\n",
    "for batch in train_loader:\n",
    "    xb, yb = batch\n",
    "\n",
    "    print(f\"xb shape:\\t\\t{xb.shape}\")\n",
    "    print(f\"yb shape:\\t\\t{yb.shape}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1mmd9hflKQjF"
   },
   "outputs": [],
   "source": [
    "# I tried it, but failed.QAQ. It seems that using np.memmap requires synchronously recording the length of each data entry, which makes padding inconvenient.\n",
    "'''\n",
    "data_dir = '/content/hw5/'\n",
    "def get_batch(split):\n",
    "    file_path = os.path.join(data_dir, 'val.bin' if split == 'val' else 'train.bin')\n",
    "\n",
    "\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    xb = torch.empty((config.batch_size, config.sequence_length), dtype=torch.int64)\n",
    "    yb = torch.empty((config.batch_size, config.sequence_length), dtype=torch.int64)\n",
    "\n",
    "    for b in range(config.batch_size):\n",
    "        tokens = data[b]['tokens']\n",
    "        if len(tokens) < config.sequence_length:\n",
    "            padded_tokens = np.pad(tokens, (0, config.sequence_length - len(tokens)), 'constant', constant_values=tokenizer.pad_token_id)\n",
    "        else:\n",
    "            padded_tokens = tokens[:config.sequence_length]\n",
    "\n",
    "\n",
    "        xb[b] = torch.tensor(padded_tokens[:-1], dtype=torch.int64)\n",
    "        yb[b] = torch.tensor(padded_tokens[1:], dtype=torch.int64)\n",
    "\n",
    "    if device == 'cuda':\n",
    "        xb, yb = xb.pin_memory().to(device, non_blocking=True), yb.pin_memory().to(device, non_blocking=True)\n",
    "\n",
    "    return xb, yb\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQ3b6b23QLUb"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "FsZa23FJQLUb"
   },
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    # def __init__(self, embed_dim, head_size, sequence_length, dropout):\n",
    "    def __init__(self, config, interim_head_size):\n",
    "        super().__init__()\n",
    "        self.embed_dim = config.embed_dim\n",
    "        self.interim_head_size = interim_head_size # say embed_dim = 32 -> broken into say 4 heads, so this will be 8, to be concated back to 32\n",
    "        self.key = nn.Linear(config.embed_dim, interim_head_size, bias=config.bias)\n",
    "        self.query = nn.Linear(config.embed_dim, interim_head_size, bias=config.bias)\n",
    "        self.value = nn.Linear(config.embed_dim, interim_head_size, bias=config.bias)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones((config.sequence_length, config.sequence_length))))\n",
    "\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x) # (b,t,c) -> (b,t,h)\n",
    "        q = self.query(x) # (b,t,c) -> (b,t,h)\n",
    "        v = self.value(x) # (b,t,c) -> (b,t,h)\n",
    "        wei = k @ q.transpose(-2, -1) * self.embed_dim**(-0.5) # (b,t,h) @ (b,h,t) -> (b,t,t)\n",
    "\n",
    "        wei = wei.masked_fill((self.tril[:T, :T] == 0.), -torch.inf) # type: ignore\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        xbow = wei @ v # (b,t,t) @ (b,t,h) -> (b,t,h)\n",
    "        return xbow\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    # def __init__(self, num_heads, embed_dim, head_size, sequence_length, dropout):\n",
    "    def __init__(self, config, interim_head_size):\n",
    "        super().__init__()\n",
    "        self.head_list = nn.ModuleList([Head(config, interim_head_size) for _ in range(config.num_heads)])\n",
    "        self.proj = nn.Linear(config.embed_dim, config.embed_dim)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.head_list], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(config.embed_dim, 4*config.embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4*config.embed_dim, config.embed_dim),\n",
    "            nn.Dropout(config.dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    # def __init__(self, num_heads, embed_dim, sequence_length, dropout):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.interim_head_size = config.embed_dim // config.num_heads\n",
    "        self.sa = MultiHeadAttention(config, self.interim_head_size)\n",
    "        self.ff = FeedForward(config)\n",
    "        self.ln1 = nn.LayerNorm(config.embed_dim)\n",
    "        self.ln2 = nn.LayerNorm(config.embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x)) # communication\n",
    "        x = x + self.ff(self.ln2(x)) # computation\n",
    "        return x\n",
    "\n",
    "\n",
    "class Transformer(torch.nn.Module):\n",
    "    # def __init__(self, embed_dim, vocab_size, sequence_length, num_heads, num_blocks, dropout):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.sequence_length = config.sequence_length\n",
    "        self.token_embeddings = torch.nn.Embedding(config.vocab_size, config.embed_dim)\n",
    "        self.position_embeddings = nn.Embedding(config.sequence_length, config.embed_dim)\n",
    "        self.block_list = nn.Sequential(*[Block(config)\n",
    "                                          for _ in range(config.num_blocks)])\n",
    "        self.final_ln = nn.LayerNorm(config.embed_dim)\n",
    "        self.lm_head = nn.Linear(config.embed_dim, config.vocab_size)\n",
    "\n",
    "    def forward(self, ixs, targets=None):\n",
    "        # ixs: (b,t)\n",
    "        # targets: (b,t)\n",
    "        B, T = ixs.shape\n",
    "        x = self.token_embeddings(ixs) # (b,t,c=embed_dim)\n",
    "        pos_embeds = self.position_embeddings(torch.arange(T, device=device)) # (t,c=embed_dim)\n",
    "        x += pos_embeds\n",
    "        x = self.block_list(x)\n",
    "        x = self.final_ln(x)\n",
    "        logits = self.lm_head(x) # (b,t,c=vocab_size)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            mask = (ixs != tokenizer.pad_token_id)  # (b,t), True where not a pad token\n",
    "            logits = logits.permute(0, 2, 1)  # (b,c,t)\n",
    "    \n",
    "            # Use the mask to filter out loss on padding positions\n",
    "            # logits are now (b, c, t), targets are (b, t), mask is (b, t)\n",
    "            # Utilizing .masked_fill to turn pad positions to a very large negative value to ignore them in softmax\n",
    "            loss = F.cross_entropy(logits, targets, reduction='none')  # (b, t) get loss per token\n",
    "            loss = (loss * mask).sum() / mask.sum()  # average loss only over non-pad tokens\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, ixs, max_len):\n",
    "        \"\"\"\n",
    "        ixs: (b,t) - input sequence to start generating from\n",
    "        max_len: int - maximum length of the generated sequence\n",
    "        \"\"\"\n",
    "        b, t = ixs.shape\n",
    "        for _ in range(max_len):\n",
    "            # generation (b, ) next tokens in parallel\n",
    "            ixs_cond = ixs[:, -self.sequence_length:] # consider only the last sequence_length tokens\n",
    "            logits, loss = self.forward(ixs_cond) # logits=(b,t,c), loss is ignored\n",
    "            # get juse the final timestep\n",
    "            last_logits = logits[:, -1, :] # (b,c)\n",
    "            # normalize\n",
    "            last_probs = F.softmax(last_logits, dim=-1) # across c\n",
    "            next_tokens = torch.multinomial(last_probs, 1) # (b,c) -> (b)\n",
    "            ixs = torch.cat((ixs, next_tokens), dim=1) # across t so (b,t) -> (b, t+1)\n",
    "        return ixs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mlj4sY57QLUb"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "uM9xrNVCQLUb"
   },
   "outputs": [],
   "source": [
    "# model = Transformer(embed_dim, vocab_size, sequence_length, num_heads, num_blocks, dropout).to(device)\n",
    "model = Transformer(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "RXZIOVpRQLUc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================\n",
      "                                                 Kernel Shape  \\\n",
      "Layer                                                           \n",
      "0_token_embeddings                               [512, 50257]   \n",
      "1_position_embeddings                              [512, 256]   \n",
      "2_block_list.0.LayerNorm_ln1                            [512]   \n",
      "3_block_list.0.sa.head_list.0.Linear_key            [512, 64]   \n",
      "4_block_list.0.sa.head_list.0.Linear_query          [512, 64]   \n",
      "5_block_list.0.sa.head_list.0.Linear_value          [512, 64]   \n",
      "6_block_list.0.sa.head_list.0.Dropout_dropout               -   \n",
      "7_block_list.0.sa.head_list.1.Linear_key            [512, 64]   \n",
      "8_block_list.0.sa.head_list.1.Linear_query          [512, 64]   \n",
      "9_block_list.0.sa.head_list.1.Linear_value          [512, 64]   \n",
      "10_block_list.0.sa.head_list.1.Dropout_dropout              -   \n",
      "11_block_list.0.sa.head_list.2.Linear_key           [512, 64]   \n",
      "12_block_list.0.sa.head_list.2.Linear_query         [512, 64]   \n",
      "13_block_list.0.sa.head_list.2.Linear_value         [512, 64]   \n",
      "14_block_list.0.sa.head_list.2.Dropout_dropout              -   \n",
      "15_block_list.0.sa.head_list.3.Linear_key           [512, 64]   \n",
      "16_block_list.0.sa.head_list.3.Linear_query         [512, 64]   \n",
      "17_block_list.0.sa.head_list.3.Linear_value         [512, 64]   \n",
      "18_block_list.0.sa.head_list.3.Dropout_dropout              -   \n",
      "19_block_list.0.sa.head_list.4.Linear_key           [512, 64]   \n",
      "20_block_list.0.sa.head_list.4.Linear_query         [512, 64]   \n",
      "21_block_list.0.sa.head_list.4.Linear_value         [512, 64]   \n",
      "22_block_list.0.sa.head_list.4.Dropout_dropout              -   \n",
      "23_block_list.0.sa.head_list.5.Linear_key           [512, 64]   \n",
      "24_block_list.0.sa.head_list.5.Linear_query         [512, 64]   \n",
      "25_block_list.0.sa.head_list.5.Linear_value         [512, 64]   \n",
      "26_block_list.0.sa.head_list.5.Dropout_dropout              -   \n",
      "27_block_list.0.sa.head_list.6.Linear_key           [512, 64]   \n",
      "28_block_list.0.sa.head_list.6.Linear_query         [512, 64]   \n",
      "29_block_list.0.sa.head_list.6.Linear_value         [512, 64]   \n",
      "30_block_list.0.sa.head_list.6.Dropout_dropout              -   \n",
      "31_block_list.0.sa.head_list.7.Linear_key           [512, 64]   \n",
      "32_block_list.0.sa.head_list.7.Linear_query         [512, 64]   \n",
      "33_block_list.0.sa.head_list.7.Linear_value         [512, 64]   \n",
      "34_block_list.0.sa.head_list.7.Dropout_dropout              -   \n",
      "35_block_list.0.sa.Linear_proj                     [512, 512]   \n",
      "36_block_list.0.sa.Dropout_dropout                          -   \n",
      "37_block_list.0.LayerNorm_ln2                           [512]   \n",
      "38_block_list.0.ff.layers.Linear_0                [512, 2048]   \n",
      "39_block_list.0.ff.layers.GELU_1                            -   \n",
      "40_block_list.0.ff.layers.Linear_2                [2048, 512]   \n",
      "41_block_list.0.ff.layers.Dropout_3                         -   \n",
      "42_block_list.1.LayerNorm_ln1                           [512]   \n",
      "43_block_list.1.sa.head_list.0.Linear_key           [512, 64]   \n",
      "44_block_list.1.sa.head_list.0.Linear_query         [512, 64]   \n",
      "45_block_list.1.sa.head_list.0.Linear_value         [512, 64]   \n",
      "46_block_list.1.sa.head_list.0.Dropout_dropout              -   \n",
      "47_block_list.1.sa.head_list.1.Linear_key           [512, 64]   \n",
      "48_block_list.1.sa.head_list.1.Linear_query         [512, 64]   \n",
      "49_block_list.1.sa.head_list.1.Linear_value         [512, 64]   \n",
      "50_block_list.1.sa.head_list.1.Dropout_dropout              -   \n",
      "51_block_list.1.sa.head_list.2.Linear_key           [512, 64]   \n",
      "52_block_list.1.sa.head_list.2.Linear_query         [512, 64]   \n",
      "53_block_list.1.sa.head_list.2.Linear_value         [512, 64]   \n",
      "54_block_list.1.sa.head_list.2.Dropout_dropout              -   \n",
      "55_block_list.1.sa.head_list.3.Linear_key           [512, 64]   \n",
      "56_block_list.1.sa.head_list.3.Linear_query         [512, 64]   \n",
      "57_block_list.1.sa.head_list.3.Linear_value         [512, 64]   \n",
      "58_block_list.1.sa.head_list.3.Dropout_dropout              -   \n",
      "59_block_list.1.sa.head_list.4.Linear_key           [512, 64]   \n",
      "60_block_list.1.sa.head_list.4.Linear_query         [512, 64]   \n",
      "61_block_list.1.sa.head_list.4.Linear_value         [512, 64]   \n",
      "62_block_list.1.sa.head_list.4.Dropout_dropout              -   \n",
      "63_block_list.1.sa.head_list.5.Linear_key           [512, 64]   \n",
      "64_block_list.1.sa.head_list.5.Linear_query         [512, 64]   \n",
      "65_block_list.1.sa.head_list.5.Linear_value         [512, 64]   \n",
      "66_block_list.1.sa.head_list.5.Dropout_dropout              -   \n",
      "67_block_list.1.sa.head_list.6.Linear_key           [512, 64]   \n",
      "68_block_list.1.sa.head_list.6.Linear_query         [512, 64]   \n",
      "69_block_list.1.sa.head_list.6.Linear_value         [512, 64]   \n",
      "70_block_list.1.sa.head_list.6.Dropout_dropout              -   \n",
      "71_block_list.1.sa.head_list.7.Linear_key           [512, 64]   \n",
      "72_block_list.1.sa.head_list.7.Linear_query         [512, 64]   \n",
      "73_block_list.1.sa.head_list.7.Linear_value         [512, 64]   \n",
      "74_block_list.1.sa.head_list.7.Dropout_dropout              -   \n",
      "75_block_list.1.sa.Linear_proj                     [512, 512]   \n",
      "76_block_list.1.sa.Dropout_dropout                          -   \n",
      "77_block_list.1.LayerNorm_ln2                           [512]   \n",
      "78_block_list.1.ff.layers.Linear_0                [512, 2048]   \n",
      "79_block_list.1.ff.layers.GELU_1                            -   \n",
      "80_block_list.1.ff.layers.Linear_2                [2048, 512]   \n",
      "81_block_list.1.ff.layers.Dropout_3                         -   \n",
      "82_block_list.2.LayerNorm_ln1                           [512]   \n",
      "83_block_list.2.sa.head_list.0.Linear_key           [512, 64]   \n",
      "84_block_list.2.sa.head_list.0.Linear_query         [512, 64]   \n",
      "85_block_list.2.sa.head_list.0.Linear_value         [512, 64]   \n",
      "86_block_list.2.sa.head_list.0.Dropout_dropout              -   \n",
      "87_block_list.2.sa.head_list.1.Linear_key           [512, 64]   \n",
      "88_block_list.2.sa.head_list.1.Linear_query         [512, 64]   \n",
      "89_block_list.2.sa.head_list.1.Linear_value         [512, 64]   \n",
      "90_block_list.2.sa.head_list.1.Dropout_dropout              -   \n",
      "91_block_list.2.sa.head_list.2.Linear_key           [512, 64]   \n",
      "92_block_list.2.sa.head_list.2.Linear_query         [512, 64]   \n",
      "93_block_list.2.sa.head_list.2.Linear_value         [512, 64]   \n",
      "94_block_list.2.sa.head_list.2.Dropout_dropout              -   \n",
      "95_block_list.2.sa.head_list.3.Linear_key           [512, 64]   \n",
      "96_block_list.2.sa.head_list.3.Linear_query         [512, 64]   \n",
      "97_block_list.2.sa.head_list.3.Linear_value         [512, 64]   \n",
      "98_block_list.2.sa.head_list.3.Dropout_dropout              -   \n",
      "99_block_list.2.sa.head_list.4.Linear_key           [512, 64]   \n",
      "100_block_list.2.sa.head_list.4.Linear_query        [512, 64]   \n",
      "101_block_list.2.sa.head_list.4.Linear_value        [512, 64]   \n",
      "102_block_list.2.sa.head_list.4.Dropout_dropout             -   \n",
      "103_block_list.2.sa.head_list.5.Linear_key          [512, 64]   \n",
      "104_block_list.2.sa.head_list.5.Linear_query        [512, 64]   \n",
      "105_block_list.2.sa.head_list.5.Linear_value        [512, 64]   \n",
      "106_block_list.2.sa.head_list.5.Dropout_dropout             -   \n",
      "107_block_list.2.sa.head_list.6.Linear_key          [512, 64]   \n",
      "108_block_list.2.sa.head_list.6.Linear_query        [512, 64]   \n",
      "109_block_list.2.sa.head_list.6.Linear_value        [512, 64]   \n",
      "110_block_list.2.sa.head_list.6.Dropout_dropout             -   \n",
      "111_block_list.2.sa.head_list.7.Linear_key          [512, 64]   \n",
      "112_block_list.2.sa.head_list.7.Linear_query        [512, 64]   \n",
      "113_block_list.2.sa.head_list.7.Linear_value        [512, 64]   \n",
      "114_block_list.2.sa.head_list.7.Dropout_dropout             -   \n",
      "115_block_list.2.sa.Linear_proj                    [512, 512]   \n",
      "116_block_list.2.sa.Dropout_dropout                         -   \n",
      "117_block_list.2.LayerNorm_ln2                          [512]   \n",
      "118_block_list.2.ff.layers.Linear_0               [512, 2048]   \n",
      "119_block_list.2.ff.layers.GELU_1                           -   \n",
      "120_block_list.2.ff.layers.Linear_2               [2048, 512]   \n",
      "121_block_list.2.ff.layers.Dropout_3                        -   \n",
      "122_block_list.3.LayerNorm_ln1                          [512]   \n",
      "123_block_list.3.sa.head_list.0.Linear_key          [512, 64]   \n",
      "124_block_list.3.sa.head_list.0.Linear_query        [512, 64]   \n",
      "125_block_list.3.sa.head_list.0.Linear_value        [512, 64]   \n",
      "126_block_list.3.sa.head_list.0.Dropout_dropout             -   \n",
      "127_block_list.3.sa.head_list.1.Linear_key          [512, 64]   \n",
      "128_block_list.3.sa.head_list.1.Linear_query        [512, 64]   \n",
      "129_block_list.3.sa.head_list.1.Linear_value        [512, 64]   \n",
      "130_block_list.3.sa.head_list.1.Dropout_dropout             -   \n",
      "131_block_list.3.sa.head_list.2.Linear_key          [512, 64]   \n",
      "132_block_list.3.sa.head_list.2.Linear_query        [512, 64]   \n",
      "133_block_list.3.sa.head_list.2.Linear_value        [512, 64]   \n",
      "134_block_list.3.sa.head_list.2.Dropout_dropout             -   \n",
      "135_block_list.3.sa.head_list.3.Linear_key          [512, 64]   \n",
      "136_block_list.3.sa.head_list.3.Linear_query        [512, 64]   \n",
      "137_block_list.3.sa.head_list.3.Linear_value        [512, 64]   \n",
      "138_block_list.3.sa.head_list.3.Dropout_dropout             -   \n",
      "139_block_list.3.sa.head_list.4.Linear_key          [512, 64]   \n",
      "140_block_list.3.sa.head_list.4.Linear_query        [512, 64]   \n",
      "141_block_list.3.sa.head_list.4.Linear_value        [512, 64]   \n",
      "142_block_list.3.sa.head_list.4.Dropout_dropout             -   \n",
      "143_block_list.3.sa.head_list.5.Linear_key          [512, 64]   \n",
      "144_block_list.3.sa.head_list.5.Linear_query        [512, 64]   \n",
      "145_block_list.3.sa.head_list.5.Linear_value        [512, 64]   \n",
      "146_block_list.3.sa.head_list.5.Dropout_dropout             -   \n",
      "147_block_list.3.sa.head_list.6.Linear_key          [512, 64]   \n",
      "148_block_list.3.sa.head_list.6.Linear_query        [512, 64]   \n",
      "149_block_list.3.sa.head_list.6.Linear_value        [512, 64]   \n",
      "150_block_list.3.sa.head_list.6.Dropout_dropout             -   \n",
      "151_block_list.3.sa.head_list.7.Linear_key          [512, 64]   \n",
      "152_block_list.3.sa.head_list.7.Linear_query        [512, 64]   \n",
      "153_block_list.3.sa.head_list.7.Linear_value        [512, 64]   \n",
      "154_block_list.3.sa.head_list.7.Dropout_dropout             -   \n",
      "155_block_list.3.sa.Linear_proj                    [512, 512]   \n",
      "156_block_list.3.sa.Dropout_dropout                         -   \n",
      "157_block_list.3.LayerNorm_ln2                          [512]   \n",
      "158_block_list.3.ff.layers.Linear_0               [512, 2048]   \n",
      "159_block_list.3.ff.layers.GELU_1                           -   \n",
      "160_block_list.3.ff.layers.Linear_2               [2048, 512]   \n",
      "161_block_list.3.ff.layers.Dropout_3                        -   \n",
      "162_block_list.4.LayerNorm_ln1                          [512]   \n",
      "163_block_list.4.sa.head_list.0.Linear_key          [512, 64]   \n",
      "164_block_list.4.sa.head_list.0.Linear_query        [512, 64]   \n",
      "165_block_list.4.sa.head_list.0.Linear_value        [512, 64]   \n",
      "166_block_list.4.sa.head_list.0.Dropout_dropout             -   \n",
      "167_block_list.4.sa.head_list.1.Linear_key          [512, 64]   \n",
      "168_block_list.4.sa.head_list.1.Linear_query        [512, 64]   \n",
      "169_block_list.4.sa.head_list.1.Linear_value        [512, 64]   \n",
      "170_block_list.4.sa.head_list.1.Dropout_dropout             -   \n",
      "171_block_list.4.sa.head_list.2.Linear_key          [512, 64]   \n",
      "172_block_list.4.sa.head_list.2.Linear_query        [512, 64]   \n",
      "173_block_list.4.sa.head_list.2.Linear_value        [512, 64]   \n",
      "174_block_list.4.sa.head_list.2.Dropout_dropout             -   \n",
      "175_block_list.4.sa.head_list.3.Linear_key          [512, 64]   \n",
      "176_block_list.4.sa.head_list.3.Linear_query        [512, 64]   \n",
      "177_block_list.4.sa.head_list.3.Linear_value        [512, 64]   \n",
      "178_block_list.4.sa.head_list.3.Dropout_dropout             -   \n",
      "179_block_list.4.sa.head_list.4.Linear_key          [512, 64]   \n",
      "180_block_list.4.sa.head_list.4.Linear_query        [512, 64]   \n",
      "181_block_list.4.sa.head_list.4.Linear_value        [512, 64]   \n",
      "182_block_list.4.sa.head_list.4.Dropout_dropout             -   \n",
      "183_block_list.4.sa.head_list.5.Linear_key          [512, 64]   \n",
      "184_block_list.4.sa.head_list.5.Linear_query        [512, 64]   \n",
      "185_block_list.4.sa.head_list.5.Linear_value        [512, 64]   \n",
      "186_block_list.4.sa.head_list.5.Dropout_dropout             -   \n",
      "187_block_list.4.sa.head_list.6.Linear_key          [512, 64]   \n",
      "188_block_list.4.sa.head_list.6.Linear_query        [512, 64]   \n",
      "189_block_list.4.sa.head_list.6.Linear_value        [512, 64]   \n",
      "190_block_list.4.sa.head_list.6.Dropout_dropout             -   \n",
      "191_block_list.4.sa.head_list.7.Linear_key          [512, 64]   \n",
      "192_block_list.4.sa.head_list.7.Linear_query        [512, 64]   \n",
      "193_block_list.4.sa.head_list.7.Linear_value        [512, 64]   \n",
      "194_block_list.4.sa.head_list.7.Dropout_dropout             -   \n",
      "195_block_list.4.sa.Linear_proj                    [512, 512]   \n",
      "196_block_list.4.sa.Dropout_dropout                         -   \n",
      "197_block_list.4.LayerNorm_ln2                          [512]   \n",
      "198_block_list.4.ff.layers.Linear_0               [512, 2048]   \n",
      "199_block_list.4.ff.layers.GELU_1                           -   \n",
      "200_block_list.4.ff.layers.Linear_2               [2048, 512]   \n",
      "201_block_list.4.ff.layers.Dropout_3                        -   \n",
      "202_block_list.5.LayerNorm_ln1                          [512]   \n",
      "203_block_list.5.sa.head_list.0.Linear_key          [512, 64]   \n",
      "204_block_list.5.sa.head_list.0.Linear_query        [512, 64]   \n",
      "205_block_list.5.sa.head_list.0.Linear_value        [512, 64]   \n",
      "206_block_list.5.sa.head_list.0.Dropout_dropout             -   \n",
      "207_block_list.5.sa.head_list.1.Linear_key          [512, 64]   \n",
      "208_block_list.5.sa.head_list.1.Linear_query        [512, 64]   \n",
      "209_block_list.5.sa.head_list.1.Linear_value        [512, 64]   \n",
      "210_block_list.5.sa.head_list.1.Dropout_dropout             -   \n",
      "211_block_list.5.sa.head_list.2.Linear_key          [512, 64]   \n",
      "212_block_list.5.sa.head_list.2.Linear_query        [512, 64]   \n",
      "213_block_list.5.sa.head_list.2.Linear_value        [512, 64]   \n",
      "214_block_list.5.sa.head_list.2.Dropout_dropout             -   \n",
      "215_block_list.5.sa.head_list.3.Linear_key          [512, 64]   \n",
      "216_block_list.5.sa.head_list.3.Linear_query        [512, 64]   \n",
      "217_block_list.5.sa.head_list.3.Linear_value        [512, 64]   \n",
      "218_block_list.5.sa.head_list.3.Dropout_dropout             -   \n",
      "219_block_list.5.sa.head_list.4.Linear_key          [512, 64]   \n",
      "220_block_list.5.sa.head_list.4.Linear_query        [512, 64]   \n",
      "221_block_list.5.sa.head_list.4.Linear_value        [512, 64]   \n",
      "222_block_list.5.sa.head_list.4.Dropout_dropout             -   \n",
      "223_block_list.5.sa.head_list.5.Linear_key          [512, 64]   \n",
      "224_block_list.5.sa.head_list.5.Linear_query        [512, 64]   \n",
      "225_block_list.5.sa.head_list.5.Linear_value        [512, 64]   \n",
      "226_block_list.5.sa.head_list.5.Dropout_dropout             -   \n",
      "227_block_list.5.sa.head_list.6.Linear_key          [512, 64]   \n",
      "228_block_list.5.sa.head_list.6.Linear_query        [512, 64]   \n",
      "229_block_list.5.sa.head_list.6.Linear_value        [512, 64]   \n",
      "230_block_list.5.sa.head_list.6.Dropout_dropout             -   \n",
      "231_block_list.5.sa.head_list.7.Linear_key          [512, 64]   \n",
      "232_block_list.5.sa.head_list.7.Linear_query        [512, 64]   \n",
      "233_block_list.5.sa.head_list.7.Linear_value        [512, 64]   \n",
      "234_block_list.5.sa.head_list.7.Dropout_dropout             -   \n",
      "235_block_list.5.sa.Linear_proj                    [512, 512]   \n",
      "236_block_list.5.sa.Dropout_dropout                         -   \n",
      "237_block_list.5.LayerNorm_ln2                          [512]   \n",
      "238_block_list.5.ff.layers.Linear_0               [512, 2048]   \n",
      "239_block_list.5.ff.layers.GELU_1                           -   \n",
      "240_block_list.5.ff.layers.Linear_2               [2048, 512]   \n",
      "241_block_list.5.ff.layers.Dropout_3                        -   \n",
      "242_block_list.6.LayerNorm_ln1                          [512]   \n",
      "243_block_list.6.sa.head_list.0.Linear_key          [512, 64]   \n",
      "244_block_list.6.sa.head_list.0.Linear_query        [512, 64]   \n",
      "245_block_list.6.sa.head_list.0.Linear_value        [512, 64]   \n",
      "246_block_list.6.sa.head_list.0.Dropout_dropout             -   \n",
      "247_block_list.6.sa.head_list.1.Linear_key          [512, 64]   \n",
      "248_block_list.6.sa.head_list.1.Linear_query        [512, 64]   \n",
      "249_block_list.6.sa.head_list.1.Linear_value        [512, 64]   \n",
      "250_block_list.6.sa.head_list.1.Dropout_dropout             -   \n",
      "251_block_list.6.sa.head_list.2.Linear_key          [512, 64]   \n",
      "252_block_list.6.sa.head_list.2.Linear_query        [512, 64]   \n",
      "253_block_list.6.sa.head_list.2.Linear_value        [512, 64]   \n",
      "254_block_list.6.sa.head_list.2.Dropout_dropout             -   \n",
      "255_block_list.6.sa.head_list.3.Linear_key          [512, 64]   \n",
      "256_block_list.6.sa.head_list.3.Linear_query        [512, 64]   \n",
      "257_block_list.6.sa.head_list.3.Linear_value        [512, 64]   \n",
      "258_block_list.6.sa.head_list.3.Dropout_dropout             -   \n",
      "259_block_list.6.sa.head_list.4.Linear_key          [512, 64]   \n",
      "260_block_list.6.sa.head_list.4.Linear_query        [512, 64]   \n",
      "261_block_list.6.sa.head_list.4.Linear_value        [512, 64]   \n",
      "262_block_list.6.sa.head_list.4.Dropout_dropout             -   \n",
      "263_block_list.6.sa.head_list.5.Linear_key          [512, 64]   \n",
      "264_block_list.6.sa.head_list.5.Linear_query        [512, 64]   \n",
      "265_block_list.6.sa.head_list.5.Linear_value        [512, 64]   \n",
      "266_block_list.6.sa.head_list.5.Dropout_dropout             -   \n",
      "267_block_list.6.sa.head_list.6.Linear_key          [512, 64]   \n",
      "268_block_list.6.sa.head_list.6.Linear_query        [512, 64]   \n",
      "269_block_list.6.sa.head_list.6.Linear_value        [512, 64]   \n",
      "270_block_list.6.sa.head_list.6.Dropout_dropout             -   \n",
      "271_block_list.6.sa.head_list.7.Linear_key          [512, 64]   \n",
      "272_block_list.6.sa.head_list.7.Linear_query        [512, 64]   \n",
      "273_block_list.6.sa.head_list.7.Linear_value        [512, 64]   \n",
      "274_block_list.6.sa.head_list.7.Dropout_dropout             -   \n",
      "275_block_list.6.sa.Linear_proj                    [512, 512]   \n",
      "276_block_list.6.sa.Dropout_dropout                         -   \n",
      "277_block_list.6.LayerNorm_ln2                          [512]   \n",
      "278_block_list.6.ff.layers.Linear_0               [512, 2048]   \n",
      "279_block_list.6.ff.layers.GELU_1                           -   \n",
      "280_block_list.6.ff.layers.Linear_2               [2048, 512]   \n",
      "281_block_list.6.ff.layers.Dropout_3                        -   \n",
      "282_block_list.7.LayerNorm_ln1                          [512]   \n",
      "283_block_list.7.sa.head_list.0.Linear_key          [512, 64]   \n",
      "284_block_list.7.sa.head_list.0.Linear_query        [512, 64]   \n",
      "285_block_list.7.sa.head_list.0.Linear_value        [512, 64]   \n",
      "286_block_list.7.sa.head_list.0.Dropout_dropout             -   \n",
      "287_block_list.7.sa.head_list.1.Linear_key          [512, 64]   \n",
      "288_block_list.7.sa.head_list.1.Linear_query        [512, 64]   \n",
      "289_block_list.7.sa.head_list.1.Linear_value        [512, 64]   \n",
      "290_block_list.7.sa.head_list.1.Dropout_dropout             -   \n",
      "291_block_list.7.sa.head_list.2.Linear_key          [512, 64]   \n",
      "292_block_list.7.sa.head_list.2.Linear_query        [512, 64]   \n",
      "293_block_list.7.sa.head_list.2.Linear_value        [512, 64]   \n",
      "294_block_list.7.sa.head_list.2.Dropout_dropout             -   \n",
      "295_block_list.7.sa.head_list.3.Linear_key          [512, 64]   \n",
      "296_block_list.7.sa.head_list.3.Linear_query        [512, 64]   \n",
      "297_block_list.7.sa.head_list.3.Linear_value        [512, 64]   \n",
      "298_block_list.7.sa.head_list.3.Dropout_dropout             -   \n",
      "299_block_list.7.sa.head_list.4.Linear_key          [512, 64]   \n",
      "300_block_list.7.sa.head_list.4.Linear_query        [512, 64]   \n",
      "301_block_list.7.sa.head_list.4.Linear_value        [512, 64]   \n",
      "302_block_list.7.sa.head_list.4.Dropout_dropout             -   \n",
      "303_block_list.7.sa.head_list.5.Linear_key          [512, 64]   \n",
      "304_block_list.7.sa.head_list.5.Linear_query        [512, 64]   \n",
      "305_block_list.7.sa.head_list.5.Linear_value        [512, 64]   \n",
      "306_block_list.7.sa.head_list.5.Dropout_dropout             -   \n",
      "307_block_list.7.sa.head_list.6.Linear_key          [512, 64]   \n",
      "308_block_list.7.sa.head_list.6.Linear_query        [512, 64]   \n",
      "309_block_list.7.sa.head_list.6.Linear_value        [512, 64]   \n",
      "310_block_list.7.sa.head_list.6.Dropout_dropout             -   \n",
      "311_block_list.7.sa.head_list.7.Linear_key          [512, 64]   \n",
      "312_block_list.7.sa.head_list.7.Linear_query        [512, 64]   \n",
      "313_block_list.7.sa.head_list.7.Linear_value        [512, 64]   \n",
      "314_block_list.7.sa.head_list.7.Dropout_dropout             -   \n",
      "315_block_list.7.sa.Linear_proj                    [512, 512]   \n",
      "316_block_list.7.sa.Dropout_dropout                         -   \n",
      "317_block_list.7.LayerNorm_ln2                          [512]   \n",
      "318_block_list.7.ff.layers.Linear_0               [512, 2048]   \n",
      "319_block_list.7.ff.layers.GELU_1                           -   \n",
      "320_block_list.7.ff.layers.Linear_2               [2048, 512]   \n",
      "321_block_list.7.ff.layers.Dropout_3                        -   \n",
      "322_final_ln                                            [512]   \n",
      "323_lm_head                                      [512, 50257]   \n",
      "\n",
      "                                                    Output Shape      Params  \\\n",
      "Layer                                                                          \n",
      "0_token_embeddings                                 [8, 256, 512]  25.731584M   \n",
      "1_position_embeddings                                 [256, 512]    131.072k   \n",
      "2_block_list.0.LayerNorm_ln1                       [8, 256, 512]      1.024k   \n",
      "3_block_list.0.sa.head_list.0.Linear_key            [8, 256, 64]     32.768k   \n",
      "4_block_list.0.sa.head_list.0.Linear_query          [8, 256, 64]     32.768k   \n",
      "5_block_list.0.sa.head_list.0.Linear_value          [8, 256, 64]     32.768k   \n",
      "6_block_list.0.sa.head_list.0.Dropout_dropout      [8, 256, 256]           -   \n",
      "7_block_list.0.sa.head_list.1.Linear_key            [8, 256, 64]     32.768k   \n",
      "8_block_list.0.sa.head_list.1.Linear_query          [8, 256, 64]     32.768k   \n",
      "9_block_list.0.sa.head_list.1.Linear_value          [8, 256, 64]     32.768k   \n",
      "10_block_list.0.sa.head_list.1.Dropout_dropout     [8, 256, 256]           -   \n",
      "11_block_list.0.sa.head_list.2.Linear_key           [8, 256, 64]     32.768k   \n",
      "12_block_list.0.sa.head_list.2.Linear_query         [8, 256, 64]     32.768k   \n",
      "13_block_list.0.sa.head_list.2.Linear_value         [8, 256, 64]     32.768k   \n",
      "14_block_list.0.sa.head_list.2.Dropout_dropout     [8, 256, 256]           -   \n",
      "15_block_list.0.sa.head_list.3.Linear_key           [8, 256, 64]     32.768k   \n",
      "16_block_list.0.sa.head_list.3.Linear_query         [8, 256, 64]     32.768k   \n",
      "17_block_list.0.sa.head_list.3.Linear_value         [8, 256, 64]     32.768k   \n",
      "18_block_list.0.sa.head_list.3.Dropout_dropout     [8, 256, 256]           -   \n",
      "19_block_list.0.sa.head_list.4.Linear_key           [8, 256, 64]     32.768k   \n",
      "20_block_list.0.sa.head_list.4.Linear_query         [8, 256, 64]     32.768k   \n",
      "21_block_list.0.sa.head_list.4.Linear_value         [8, 256, 64]     32.768k   \n",
      "22_block_list.0.sa.head_list.4.Dropout_dropout     [8, 256, 256]           -   \n",
      "23_block_list.0.sa.head_list.5.Linear_key           [8, 256, 64]     32.768k   \n",
      "24_block_list.0.sa.head_list.5.Linear_query         [8, 256, 64]     32.768k   \n",
      "25_block_list.0.sa.head_list.5.Linear_value         [8, 256, 64]     32.768k   \n",
      "26_block_list.0.sa.head_list.5.Dropout_dropout     [8, 256, 256]           -   \n",
      "27_block_list.0.sa.head_list.6.Linear_key           [8, 256, 64]     32.768k   \n",
      "28_block_list.0.sa.head_list.6.Linear_query         [8, 256, 64]     32.768k   \n",
      "29_block_list.0.sa.head_list.6.Linear_value         [8, 256, 64]     32.768k   \n",
      "30_block_list.0.sa.head_list.6.Dropout_dropout     [8, 256, 256]           -   \n",
      "31_block_list.0.sa.head_list.7.Linear_key           [8, 256, 64]     32.768k   \n",
      "32_block_list.0.sa.head_list.7.Linear_query         [8, 256, 64]     32.768k   \n",
      "33_block_list.0.sa.head_list.7.Linear_value         [8, 256, 64]     32.768k   \n",
      "34_block_list.0.sa.head_list.7.Dropout_dropout     [8, 256, 256]           -   \n",
      "35_block_list.0.sa.Linear_proj                     [8, 256, 512]    262.656k   \n",
      "36_block_list.0.sa.Dropout_dropout                 [8, 256, 512]           -   \n",
      "37_block_list.0.LayerNorm_ln2                      [8, 256, 512]      1.024k   \n",
      "38_block_list.0.ff.layers.Linear_0                [8, 256, 2048]   1.050624M   \n",
      "39_block_list.0.ff.layers.GELU_1                  [8, 256, 2048]           -   \n",
      "40_block_list.0.ff.layers.Linear_2                 [8, 256, 512]   1.049088M   \n",
      "41_block_list.0.ff.layers.Dropout_3                [8, 256, 512]           -   \n",
      "42_block_list.1.LayerNorm_ln1                      [8, 256, 512]      1.024k   \n",
      "43_block_list.1.sa.head_list.0.Linear_key           [8, 256, 64]     32.768k   \n",
      "44_block_list.1.sa.head_list.0.Linear_query         [8, 256, 64]     32.768k   \n",
      "45_block_list.1.sa.head_list.0.Linear_value         [8, 256, 64]     32.768k   \n",
      "46_block_list.1.sa.head_list.0.Dropout_dropout     [8, 256, 256]           -   \n",
      "47_block_list.1.sa.head_list.1.Linear_key           [8, 256, 64]     32.768k   \n",
      "48_block_list.1.sa.head_list.1.Linear_query         [8, 256, 64]     32.768k   \n",
      "49_block_list.1.sa.head_list.1.Linear_value         [8, 256, 64]     32.768k   \n",
      "50_block_list.1.sa.head_list.1.Dropout_dropout     [8, 256, 256]           -   \n",
      "51_block_list.1.sa.head_list.2.Linear_key           [8, 256, 64]     32.768k   \n",
      "52_block_list.1.sa.head_list.2.Linear_query         [8, 256, 64]     32.768k   \n",
      "53_block_list.1.sa.head_list.2.Linear_value         [8, 256, 64]     32.768k   \n",
      "54_block_list.1.sa.head_list.2.Dropout_dropout     [8, 256, 256]           -   \n",
      "55_block_list.1.sa.head_list.3.Linear_key           [8, 256, 64]     32.768k   \n",
      "56_block_list.1.sa.head_list.3.Linear_query         [8, 256, 64]     32.768k   \n",
      "57_block_list.1.sa.head_list.3.Linear_value         [8, 256, 64]     32.768k   \n",
      "58_block_list.1.sa.head_list.3.Dropout_dropout     [8, 256, 256]           -   \n",
      "59_block_list.1.sa.head_list.4.Linear_key           [8, 256, 64]     32.768k   \n",
      "60_block_list.1.sa.head_list.4.Linear_query         [8, 256, 64]     32.768k   \n",
      "61_block_list.1.sa.head_list.4.Linear_value         [8, 256, 64]     32.768k   \n",
      "62_block_list.1.sa.head_list.4.Dropout_dropout     [8, 256, 256]           -   \n",
      "63_block_list.1.sa.head_list.5.Linear_key           [8, 256, 64]     32.768k   \n",
      "64_block_list.1.sa.head_list.5.Linear_query         [8, 256, 64]     32.768k   \n",
      "65_block_list.1.sa.head_list.5.Linear_value         [8, 256, 64]     32.768k   \n",
      "66_block_list.1.sa.head_list.5.Dropout_dropout     [8, 256, 256]           -   \n",
      "67_block_list.1.sa.head_list.6.Linear_key           [8, 256, 64]     32.768k   \n",
      "68_block_list.1.sa.head_list.6.Linear_query         [8, 256, 64]     32.768k   \n",
      "69_block_list.1.sa.head_list.6.Linear_value         [8, 256, 64]     32.768k   \n",
      "70_block_list.1.sa.head_list.6.Dropout_dropout     [8, 256, 256]           -   \n",
      "71_block_list.1.sa.head_list.7.Linear_key           [8, 256, 64]     32.768k   \n",
      "72_block_list.1.sa.head_list.7.Linear_query         [8, 256, 64]     32.768k   \n",
      "73_block_list.1.sa.head_list.7.Linear_value         [8, 256, 64]     32.768k   \n",
      "74_block_list.1.sa.head_list.7.Dropout_dropout     [8, 256, 256]           -   \n",
      "75_block_list.1.sa.Linear_proj                     [8, 256, 512]    262.656k   \n",
      "76_block_list.1.sa.Dropout_dropout                 [8, 256, 512]           -   \n",
      "77_block_list.1.LayerNorm_ln2                      [8, 256, 512]      1.024k   \n",
      "78_block_list.1.ff.layers.Linear_0                [8, 256, 2048]   1.050624M   \n",
      "79_block_list.1.ff.layers.GELU_1                  [8, 256, 2048]           -   \n",
      "80_block_list.1.ff.layers.Linear_2                 [8, 256, 512]   1.049088M   \n",
      "81_block_list.1.ff.layers.Dropout_3                [8, 256, 512]           -   \n",
      "82_block_list.2.LayerNorm_ln1                      [8, 256, 512]      1.024k   \n",
      "83_block_list.2.sa.head_list.0.Linear_key           [8, 256, 64]     32.768k   \n",
      "84_block_list.2.sa.head_list.0.Linear_query         [8, 256, 64]     32.768k   \n",
      "85_block_list.2.sa.head_list.0.Linear_value         [8, 256, 64]     32.768k   \n",
      "86_block_list.2.sa.head_list.0.Dropout_dropout     [8, 256, 256]           -   \n",
      "87_block_list.2.sa.head_list.1.Linear_key           [8, 256, 64]     32.768k   \n",
      "88_block_list.2.sa.head_list.1.Linear_query         [8, 256, 64]     32.768k   \n",
      "89_block_list.2.sa.head_list.1.Linear_value         [8, 256, 64]     32.768k   \n",
      "90_block_list.2.sa.head_list.1.Dropout_dropout     [8, 256, 256]           -   \n",
      "91_block_list.2.sa.head_list.2.Linear_key           [8, 256, 64]     32.768k   \n",
      "92_block_list.2.sa.head_list.2.Linear_query         [8, 256, 64]     32.768k   \n",
      "93_block_list.2.sa.head_list.2.Linear_value         [8, 256, 64]     32.768k   \n",
      "94_block_list.2.sa.head_list.2.Dropout_dropout     [8, 256, 256]           -   \n",
      "95_block_list.2.sa.head_list.3.Linear_key           [8, 256, 64]     32.768k   \n",
      "96_block_list.2.sa.head_list.3.Linear_query         [8, 256, 64]     32.768k   \n",
      "97_block_list.2.sa.head_list.3.Linear_value         [8, 256, 64]     32.768k   \n",
      "98_block_list.2.sa.head_list.3.Dropout_dropout     [8, 256, 256]           -   \n",
      "99_block_list.2.sa.head_list.4.Linear_key           [8, 256, 64]     32.768k   \n",
      "100_block_list.2.sa.head_list.4.Linear_query        [8, 256, 64]     32.768k   \n",
      "101_block_list.2.sa.head_list.4.Linear_value        [8, 256, 64]     32.768k   \n",
      "102_block_list.2.sa.head_list.4.Dropout_dropout    [8, 256, 256]           -   \n",
      "103_block_list.2.sa.head_list.5.Linear_key          [8, 256, 64]     32.768k   \n",
      "104_block_list.2.sa.head_list.5.Linear_query        [8, 256, 64]     32.768k   \n",
      "105_block_list.2.sa.head_list.5.Linear_value        [8, 256, 64]     32.768k   \n",
      "106_block_list.2.sa.head_list.5.Dropout_dropout    [8, 256, 256]           -   \n",
      "107_block_list.2.sa.head_list.6.Linear_key          [8, 256, 64]     32.768k   \n",
      "108_block_list.2.sa.head_list.6.Linear_query        [8, 256, 64]     32.768k   \n",
      "109_block_list.2.sa.head_list.6.Linear_value        [8, 256, 64]     32.768k   \n",
      "110_block_list.2.sa.head_list.6.Dropout_dropout    [8, 256, 256]           -   \n",
      "111_block_list.2.sa.head_list.7.Linear_key          [8, 256, 64]     32.768k   \n",
      "112_block_list.2.sa.head_list.7.Linear_query        [8, 256, 64]     32.768k   \n",
      "113_block_list.2.sa.head_list.7.Linear_value        [8, 256, 64]     32.768k   \n",
      "114_block_list.2.sa.head_list.7.Dropout_dropout    [8, 256, 256]           -   \n",
      "115_block_list.2.sa.Linear_proj                    [8, 256, 512]    262.656k   \n",
      "116_block_list.2.sa.Dropout_dropout                [8, 256, 512]           -   \n",
      "117_block_list.2.LayerNorm_ln2                     [8, 256, 512]      1.024k   \n",
      "118_block_list.2.ff.layers.Linear_0               [8, 256, 2048]   1.050624M   \n",
      "119_block_list.2.ff.layers.GELU_1                 [8, 256, 2048]           -   \n",
      "120_block_list.2.ff.layers.Linear_2                [8, 256, 512]   1.049088M   \n",
      "121_block_list.2.ff.layers.Dropout_3               [8, 256, 512]           -   \n",
      "122_block_list.3.LayerNorm_ln1                     [8, 256, 512]      1.024k   \n",
      "123_block_list.3.sa.head_list.0.Linear_key          [8, 256, 64]     32.768k   \n",
      "124_block_list.3.sa.head_list.0.Linear_query        [8, 256, 64]     32.768k   \n",
      "125_block_list.3.sa.head_list.0.Linear_value        [8, 256, 64]     32.768k   \n",
      "126_block_list.3.sa.head_list.0.Dropout_dropout    [8, 256, 256]           -   \n",
      "127_block_list.3.sa.head_list.1.Linear_key          [8, 256, 64]     32.768k   \n",
      "128_block_list.3.sa.head_list.1.Linear_query        [8, 256, 64]     32.768k   \n",
      "129_block_list.3.sa.head_list.1.Linear_value        [8, 256, 64]     32.768k   \n",
      "130_block_list.3.sa.head_list.1.Dropout_dropout    [8, 256, 256]           -   \n",
      "131_block_list.3.sa.head_list.2.Linear_key          [8, 256, 64]     32.768k   \n",
      "132_block_list.3.sa.head_list.2.Linear_query        [8, 256, 64]     32.768k   \n",
      "133_block_list.3.sa.head_list.2.Linear_value        [8, 256, 64]     32.768k   \n",
      "134_block_list.3.sa.head_list.2.Dropout_dropout    [8, 256, 256]           -   \n",
      "135_block_list.3.sa.head_list.3.Linear_key          [8, 256, 64]     32.768k   \n",
      "136_block_list.3.sa.head_list.3.Linear_query        [8, 256, 64]     32.768k   \n",
      "137_block_list.3.sa.head_list.3.Linear_value        [8, 256, 64]     32.768k   \n",
      "138_block_list.3.sa.head_list.3.Dropout_dropout    [8, 256, 256]           -   \n",
      "139_block_list.3.sa.head_list.4.Linear_key          [8, 256, 64]     32.768k   \n",
      "140_block_list.3.sa.head_list.4.Linear_query        [8, 256, 64]     32.768k   \n",
      "141_block_list.3.sa.head_list.4.Linear_value        [8, 256, 64]     32.768k   \n",
      "142_block_list.3.sa.head_list.4.Dropout_dropout    [8, 256, 256]           -   \n",
      "143_block_list.3.sa.head_list.5.Linear_key          [8, 256, 64]     32.768k   \n",
      "144_block_list.3.sa.head_list.5.Linear_query        [8, 256, 64]     32.768k   \n",
      "145_block_list.3.sa.head_list.5.Linear_value        [8, 256, 64]     32.768k   \n",
      "146_block_list.3.sa.head_list.5.Dropout_dropout    [8, 256, 256]           -   \n",
      "147_block_list.3.sa.head_list.6.Linear_key          [8, 256, 64]     32.768k   \n",
      "148_block_list.3.sa.head_list.6.Linear_query        [8, 256, 64]     32.768k   \n",
      "149_block_list.3.sa.head_list.6.Linear_value        [8, 256, 64]     32.768k   \n",
      "150_block_list.3.sa.head_list.6.Dropout_dropout    [8, 256, 256]           -   \n",
      "151_block_list.3.sa.head_list.7.Linear_key          [8, 256, 64]     32.768k   \n",
      "152_block_list.3.sa.head_list.7.Linear_query        [8, 256, 64]     32.768k   \n",
      "153_block_list.3.sa.head_list.7.Linear_value        [8, 256, 64]     32.768k   \n",
      "154_block_list.3.sa.head_list.7.Dropout_dropout    [8, 256, 256]           -   \n",
      "155_block_list.3.sa.Linear_proj                    [8, 256, 512]    262.656k   \n",
      "156_block_list.3.sa.Dropout_dropout                [8, 256, 512]           -   \n",
      "157_block_list.3.LayerNorm_ln2                     [8, 256, 512]      1.024k   \n",
      "158_block_list.3.ff.layers.Linear_0               [8, 256, 2048]   1.050624M   \n",
      "159_block_list.3.ff.layers.GELU_1                 [8, 256, 2048]           -   \n",
      "160_block_list.3.ff.layers.Linear_2                [8, 256, 512]   1.049088M   \n",
      "161_block_list.3.ff.layers.Dropout_3               [8, 256, 512]           -   \n",
      "162_block_list.4.LayerNorm_ln1                     [8, 256, 512]      1.024k   \n",
      "163_block_list.4.sa.head_list.0.Linear_key          [8, 256, 64]     32.768k   \n",
      "164_block_list.4.sa.head_list.0.Linear_query        [8, 256, 64]     32.768k   \n",
      "165_block_list.4.sa.head_list.0.Linear_value        [8, 256, 64]     32.768k   \n",
      "166_block_list.4.sa.head_list.0.Dropout_dropout    [8, 256, 256]           -   \n",
      "167_block_list.4.sa.head_list.1.Linear_key          [8, 256, 64]     32.768k   \n",
      "168_block_list.4.sa.head_list.1.Linear_query        [8, 256, 64]     32.768k   \n",
      "169_block_list.4.sa.head_list.1.Linear_value        [8, 256, 64]     32.768k   \n",
      "170_block_list.4.sa.head_list.1.Dropout_dropout    [8, 256, 256]           -   \n",
      "171_block_list.4.sa.head_list.2.Linear_key          [8, 256, 64]     32.768k   \n",
      "172_block_list.4.sa.head_list.2.Linear_query        [8, 256, 64]     32.768k   \n",
      "173_block_list.4.sa.head_list.2.Linear_value        [8, 256, 64]     32.768k   \n",
      "174_block_list.4.sa.head_list.2.Dropout_dropout    [8, 256, 256]           -   \n",
      "175_block_list.4.sa.head_list.3.Linear_key          [8, 256, 64]     32.768k   \n",
      "176_block_list.4.sa.head_list.3.Linear_query        [8, 256, 64]     32.768k   \n",
      "177_block_list.4.sa.head_list.3.Linear_value        [8, 256, 64]     32.768k   \n",
      "178_block_list.4.sa.head_list.3.Dropout_dropout    [8, 256, 256]           -   \n",
      "179_block_list.4.sa.head_list.4.Linear_key          [8, 256, 64]     32.768k   \n",
      "180_block_list.4.sa.head_list.4.Linear_query        [8, 256, 64]     32.768k   \n",
      "181_block_list.4.sa.head_list.4.Linear_value        [8, 256, 64]     32.768k   \n",
      "182_block_list.4.sa.head_list.4.Dropout_dropout    [8, 256, 256]           -   \n",
      "183_block_list.4.sa.head_list.5.Linear_key          [8, 256, 64]     32.768k   \n",
      "184_block_list.4.sa.head_list.5.Linear_query        [8, 256, 64]     32.768k   \n",
      "185_block_list.4.sa.head_list.5.Linear_value        [8, 256, 64]     32.768k   \n",
      "186_block_list.4.sa.head_list.5.Dropout_dropout    [8, 256, 256]           -   \n",
      "187_block_list.4.sa.head_list.6.Linear_key          [8, 256, 64]     32.768k   \n",
      "188_block_list.4.sa.head_list.6.Linear_query        [8, 256, 64]     32.768k   \n",
      "189_block_list.4.sa.head_list.6.Linear_value        [8, 256, 64]     32.768k   \n",
      "190_block_list.4.sa.head_list.6.Dropout_dropout    [8, 256, 256]           -   \n",
      "191_block_list.4.sa.head_list.7.Linear_key          [8, 256, 64]     32.768k   \n",
      "192_block_list.4.sa.head_list.7.Linear_query        [8, 256, 64]     32.768k   \n",
      "193_block_list.4.sa.head_list.7.Linear_value        [8, 256, 64]     32.768k   \n",
      "194_block_list.4.sa.head_list.7.Dropout_dropout    [8, 256, 256]           -   \n",
      "195_block_list.4.sa.Linear_proj                    [8, 256, 512]    262.656k   \n",
      "196_block_list.4.sa.Dropout_dropout                [8, 256, 512]           -   \n",
      "197_block_list.4.LayerNorm_ln2                     [8, 256, 512]      1.024k   \n",
      "198_block_list.4.ff.layers.Linear_0               [8, 256, 2048]   1.050624M   \n",
      "199_block_list.4.ff.layers.GELU_1                 [8, 256, 2048]           -   \n",
      "200_block_list.4.ff.layers.Linear_2                [8, 256, 512]   1.049088M   \n",
      "201_block_list.4.ff.layers.Dropout_3               [8, 256, 512]           -   \n",
      "202_block_list.5.LayerNorm_ln1                     [8, 256, 512]      1.024k   \n",
      "203_block_list.5.sa.head_list.0.Linear_key          [8, 256, 64]     32.768k   \n",
      "204_block_list.5.sa.head_list.0.Linear_query        [8, 256, 64]     32.768k   \n",
      "205_block_list.5.sa.head_list.0.Linear_value        [8, 256, 64]     32.768k   \n",
      "206_block_list.5.sa.head_list.0.Dropout_dropout    [8, 256, 256]           -   \n",
      "207_block_list.5.sa.head_list.1.Linear_key          [8, 256, 64]     32.768k   \n",
      "208_block_list.5.sa.head_list.1.Linear_query        [8, 256, 64]     32.768k   \n",
      "209_block_list.5.sa.head_list.1.Linear_value        [8, 256, 64]     32.768k   \n",
      "210_block_list.5.sa.head_list.1.Dropout_dropout    [8, 256, 256]           -   \n",
      "211_block_list.5.sa.head_list.2.Linear_key          [8, 256, 64]     32.768k   \n",
      "212_block_list.5.sa.head_list.2.Linear_query        [8, 256, 64]     32.768k   \n",
      "213_block_list.5.sa.head_list.2.Linear_value        [8, 256, 64]     32.768k   \n",
      "214_block_list.5.sa.head_list.2.Dropout_dropout    [8, 256, 256]           -   \n",
      "215_block_list.5.sa.head_list.3.Linear_key          [8, 256, 64]     32.768k   \n",
      "216_block_list.5.sa.head_list.3.Linear_query        [8, 256, 64]     32.768k   \n",
      "217_block_list.5.sa.head_list.3.Linear_value        [8, 256, 64]     32.768k   \n",
      "218_block_list.5.sa.head_list.3.Dropout_dropout    [8, 256, 256]           -   \n",
      "219_block_list.5.sa.head_list.4.Linear_key          [8, 256, 64]     32.768k   \n",
      "220_block_list.5.sa.head_list.4.Linear_query        [8, 256, 64]     32.768k   \n",
      "221_block_list.5.sa.head_list.4.Linear_value        [8, 256, 64]     32.768k   \n",
      "222_block_list.5.sa.head_list.4.Dropout_dropout    [8, 256, 256]           -   \n",
      "223_block_list.5.sa.head_list.5.Linear_key          [8, 256, 64]     32.768k   \n",
      "224_block_list.5.sa.head_list.5.Linear_query        [8, 256, 64]     32.768k   \n",
      "225_block_list.5.sa.head_list.5.Linear_value        [8, 256, 64]     32.768k   \n",
      "226_block_list.5.sa.head_list.5.Dropout_dropout    [8, 256, 256]           -   \n",
      "227_block_list.5.sa.head_list.6.Linear_key          [8, 256, 64]     32.768k   \n",
      "228_block_list.5.sa.head_list.6.Linear_query        [8, 256, 64]     32.768k   \n",
      "229_block_list.5.sa.head_list.6.Linear_value        [8, 256, 64]     32.768k   \n",
      "230_block_list.5.sa.head_list.6.Dropout_dropout    [8, 256, 256]           -   \n",
      "231_block_list.5.sa.head_list.7.Linear_key          [8, 256, 64]     32.768k   \n",
      "232_block_list.5.sa.head_list.7.Linear_query        [8, 256, 64]     32.768k   \n",
      "233_block_list.5.sa.head_list.7.Linear_value        [8, 256, 64]     32.768k   \n",
      "234_block_list.5.sa.head_list.7.Dropout_dropout    [8, 256, 256]           -   \n",
      "235_block_list.5.sa.Linear_proj                    [8, 256, 512]    262.656k   \n",
      "236_block_list.5.sa.Dropout_dropout                [8, 256, 512]           -   \n",
      "237_block_list.5.LayerNorm_ln2                     [8, 256, 512]      1.024k   \n",
      "238_block_list.5.ff.layers.Linear_0               [8, 256, 2048]   1.050624M   \n",
      "239_block_list.5.ff.layers.GELU_1                 [8, 256, 2048]           -   \n",
      "240_block_list.5.ff.layers.Linear_2                [8, 256, 512]   1.049088M   \n",
      "241_block_list.5.ff.layers.Dropout_3               [8, 256, 512]           -   \n",
      "242_block_list.6.LayerNorm_ln1                     [8, 256, 512]      1.024k   \n",
      "243_block_list.6.sa.head_list.0.Linear_key          [8, 256, 64]     32.768k   \n",
      "244_block_list.6.sa.head_list.0.Linear_query        [8, 256, 64]     32.768k   \n",
      "245_block_list.6.sa.head_list.0.Linear_value        [8, 256, 64]     32.768k   \n",
      "246_block_list.6.sa.head_list.0.Dropout_dropout    [8, 256, 256]           -   \n",
      "247_block_list.6.sa.head_list.1.Linear_key          [8, 256, 64]     32.768k   \n",
      "248_block_list.6.sa.head_list.1.Linear_query        [8, 256, 64]     32.768k   \n",
      "249_block_list.6.sa.head_list.1.Linear_value        [8, 256, 64]     32.768k   \n",
      "250_block_list.6.sa.head_list.1.Dropout_dropout    [8, 256, 256]           -   \n",
      "251_block_list.6.sa.head_list.2.Linear_key          [8, 256, 64]     32.768k   \n",
      "252_block_list.6.sa.head_list.2.Linear_query        [8, 256, 64]     32.768k   \n",
      "253_block_list.6.sa.head_list.2.Linear_value        [8, 256, 64]     32.768k   \n",
      "254_block_list.6.sa.head_list.2.Dropout_dropout    [8, 256, 256]           -   \n",
      "255_block_list.6.sa.head_list.3.Linear_key          [8, 256, 64]     32.768k   \n",
      "256_block_list.6.sa.head_list.3.Linear_query        [8, 256, 64]     32.768k   \n",
      "257_block_list.6.sa.head_list.3.Linear_value        [8, 256, 64]     32.768k   \n",
      "258_block_list.6.sa.head_list.3.Dropout_dropout    [8, 256, 256]           -   \n",
      "259_block_list.6.sa.head_list.4.Linear_key          [8, 256, 64]     32.768k   \n",
      "260_block_list.6.sa.head_list.4.Linear_query        [8, 256, 64]     32.768k   \n",
      "261_block_list.6.sa.head_list.4.Linear_value        [8, 256, 64]     32.768k   \n",
      "262_block_list.6.sa.head_list.4.Dropout_dropout    [8, 256, 256]           -   \n",
      "263_block_list.6.sa.head_list.5.Linear_key          [8, 256, 64]     32.768k   \n",
      "264_block_list.6.sa.head_list.5.Linear_query        [8, 256, 64]     32.768k   \n",
      "265_block_list.6.sa.head_list.5.Linear_value        [8, 256, 64]     32.768k   \n",
      "266_block_list.6.sa.head_list.5.Dropout_dropout    [8, 256, 256]           -   \n",
      "267_block_list.6.sa.head_list.6.Linear_key          [8, 256, 64]     32.768k   \n",
      "268_block_list.6.sa.head_list.6.Linear_query        [8, 256, 64]     32.768k   \n",
      "269_block_list.6.sa.head_list.6.Linear_value        [8, 256, 64]     32.768k   \n",
      "270_block_list.6.sa.head_list.6.Dropout_dropout    [8, 256, 256]           -   \n",
      "271_block_list.6.sa.head_list.7.Linear_key          [8, 256, 64]     32.768k   \n",
      "272_block_list.6.sa.head_list.7.Linear_query        [8, 256, 64]     32.768k   \n",
      "273_block_list.6.sa.head_list.7.Linear_value        [8, 256, 64]     32.768k   \n",
      "274_block_list.6.sa.head_list.7.Dropout_dropout    [8, 256, 256]           -   \n",
      "275_block_list.6.sa.Linear_proj                    [8, 256, 512]    262.656k   \n",
      "276_block_list.6.sa.Dropout_dropout                [8, 256, 512]           -   \n",
      "277_block_list.6.LayerNorm_ln2                     [8, 256, 512]      1.024k   \n",
      "278_block_list.6.ff.layers.Linear_0               [8, 256, 2048]   1.050624M   \n",
      "279_block_list.6.ff.layers.GELU_1                 [8, 256, 2048]           -   \n",
      "280_block_list.6.ff.layers.Linear_2                [8, 256, 512]   1.049088M   \n",
      "281_block_list.6.ff.layers.Dropout_3               [8, 256, 512]           -   \n",
      "282_block_list.7.LayerNorm_ln1                     [8, 256, 512]      1.024k   \n",
      "283_block_list.7.sa.head_list.0.Linear_key          [8, 256, 64]     32.768k   \n",
      "284_block_list.7.sa.head_list.0.Linear_query        [8, 256, 64]     32.768k   \n",
      "285_block_list.7.sa.head_list.0.Linear_value        [8, 256, 64]     32.768k   \n",
      "286_block_list.7.sa.head_list.0.Dropout_dropout    [8, 256, 256]           -   \n",
      "287_block_list.7.sa.head_list.1.Linear_key          [8, 256, 64]     32.768k   \n",
      "288_block_list.7.sa.head_list.1.Linear_query        [8, 256, 64]     32.768k   \n",
      "289_block_list.7.sa.head_list.1.Linear_value        [8, 256, 64]     32.768k   \n",
      "290_block_list.7.sa.head_list.1.Dropout_dropout    [8, 256, 256]           -   \n",
      "291_block_list.7.sa.head_list.2.Linear_key          [8, 256, 64]     32.768k   \n",
      "292_block_list.7.sa.head_list.2.Linear_query        [8, 256, 64]     32.768k   \n",
      "293_block_list.7.sa.head_list.2.Linear_value        [8, 256, 64]     32.768k   \n",
      "294_block_list.7.sa.head_list.2.Dropout_dropout    [8, 256, 256]           -   \n",
      "295_block_list.7.sa.head_list.3.Linear_key          [8, 256, 64]     32.768k   \n",
      "296_block_list.7.sa.head_list.3.Linear_query        [8, 256, 64]     32.768k   \n",
      "297_block_list.7.sa.head_list.3.Linear_value        [8, 256, 64]     32.768k   \n",
      "298_block_list.7.sa.head_list.3.Dropout_dropout    [8, 256, 256]           -   \n",
      "299_block_list.7.sa.head_list.4.Linear_key          [8, 256, 64]     32.768k   \n",
      "300_block_list.7.sa.head_list.4.Linear_query        [8, 256, 64]     32.768k   \n",
      "301_block_list.7.sa.head_list.4.Linear_value        [8, 256, 64]     32.768k   \n",
      "302_block_list.7.sa.head_list.4.Dropout_dropout    [8, 256, 256]           -   \n",
      "303_block_list.7.sa.head_list.5.Linear_key          [8, 256, 64]     32.768k   \n",
      "304_block_list.7.sa.head_list.5.Linear_query        [8, 256, 64]     32.768k   \n",
      "305_block_list.7.sa.head_list.5.Linear_value        [8, 256, 64]     32.768k   \n",
      "306_block_list.7.sa.head_list.5.Dropout_dropout    [8, 256, 256]           -   \n",
      "307_block_list.7.sa.head_list.6.Linear_key          [8, 256, 64]     32.768k   \n",
      "308_block_list.7.sa.head_list.6.Linear_query        [8, 256, 64]     32.768k   \n",
      "309_block_list.7.sa.head_list.6.Linear_value        [8, 256, 64]     32.768k   \n",
      "310_block_list.7.sa.head_list.6.Dropout_dropout    [8, 256, 256]           -   \n",
      "311_block_list.7.sa.head_list.7.Linear_key          [8, 256, 64]     32.768k   \n",
      "312_block_list.7.sa.head_list.7.Linear_query        [8, 256, 64]     32.768k   \n",
      "313_block_list.7.sa.head_list.7.Linear_value        [8, 256, 64]     32.768k   \n",
      "314_block_list.7.sa.head_list.7.Dropout_dropout    [8, 256, 256]           -   \n",
      "315_block_list.7.sa.Linear_proj                    [8, 256, 512]    262.656k   \n",
      "316_block_list.7.sa.Dropout_dropout                [8, 256, 512]           -   \n",
      "317_block_list.7.LayerNorm_ln2                     [8, 256, 512]      1.024k   \n",
      "318_block_list.7.ff.layers.Linear_0               [8, 256, 2048]   1.050624M   \n",
      "319_block_list.7.ff.layers.GELU_1                 [8, 256, 2048]           -   \n",
      "320_block_list.7.ff.layers.Linear_2                [8, 256, 512]   1.049088M   \n",
      "321_block_list.7.ff.layers.Dropout_3               [8, 256, 512]           -   \n",
      "322_final_ln                                       [8, 256, 512]      1.024k   \n",
      "323_lm_head                                      [8, 256, 50257]  25.781841M   \n",
      "\n",
      "                                                  Mult-Adds  \n",
      "Layer                                                        \n",
      "0_token_embeddings                               25.731584M  \n",
      "1_position_embeddings                              131.072k  \n",
      "2_block_list.0.LayerNorm_ln1                          512.0  \n",
      "3_block_list.0.sa.head_list.0.Linear_key            32.768k  \n",
      "4_block_list.0.sa.head_list.0.Linear_query          32.768k  \n",
      "5_block_list.0.sa.head_list.0.Linear_value          32.768k  \n",
      "6_block_list.0.sa.head_list.0.Dropout_dropout             -  \n",
      "7_block_list.0.sa.head_list.1.Linear_key            32.768k  \n",
      "8_block_list.0.sa.head_list.1.Linear_query          32.768k  \n",
      "9_block_list.0.sa.head_list.1.Linear_value          32.768k  \n",
      "10_block_list.0.sa.head_list.1.Dropout_dropout            -  \n",
      "11_block_list.0.sa.head_list.2.Linear_key           32.768k  \n",
      "12_block_list.0.sa.head_list.2.Linear_query         32.768k  \n",
      "13_block_list.0.sa.head_list.2.Linear_value         32.768k  \n",
      "14_block_list.0.sa.head_list.2.Dropout_dropout            -  \n",
      "15_block_list.0.sa.head_list.3.Linear_key           32.768k  \n",
      "16_block_list.0.sa.head_list.3.Linear_query         32.768k  \n",
      "17_block_list.0.sa.head_list.3.Linear_value         32.768k  \n",
      "18_block_list.0.sa.head_list.3.Dropout_dropout            -  \n",
      "19_block_list.0.sa.head_list.4.Linear_key           32.768k  \n",
      "20_block_list.0.sa.head_list.4.Linear_query         32.768k  \n",
      "21_block_list.0.sa.head_list.4.Linear_value         32.768k  \n",
      "22_block_list.0.sa.head_list.4.Dropout_dropout            -  \n",
      "23_block_list.0.sa.head_list.5.Linear_key           32.768k  \n",
      "24_block_list.0.sa.head_list.5.Linear_query         32.768k  \n",
      "25_block_list.0.sa.head_list.5.Linear_value         32.768k  \n",
      "26_block_list.0.sa.head_list.5.Dropout_dropout            -  \n",
      "27_block_list.0.sa.head_list.6.Linear_key           32.768k  \n",
      "28_block_list.0.sa.head_list.6.Linear_query         32.768k  \n",
      "29_block_list.0.sa.head_list.6.Linear_value         32.768k  \n",
      "30_block_list.0.sa.head_list.6.Dropout_dropout            -  \n",
      "31_block_list.0.sa.head_list.7.Linear_key           32.768k  \n",
      "32_block_list.0.sa.head_list.7.Linear_query         32.768k  \n",
      "33_block_list.0.sa.head_list.7.Linear_value         32.768k  \n",
      "34_block_list.0.sa.head_list.7.Dropout_dropout            -  \n",
      "35_block_list.0.sa.Linear_proj                     262.144k  \n",
      "36_block_list.0.sa.Dropout_dropout                        -  \n",
      "37_block_list.0.LayerNorm_ln2                         512.0  \n",
      "38_block_list.0.ff.layers.Linear_0                1.048576M  \n",
      "39_block_list.0.ff.layers.GELU_1                          -  \n",
      "40_block_list.0.ff.layers.Linear_2                1.048576M  \n",
      "41_block_list.0.ff.layers.Dropout_3                       -  \n",
      "42_block_list.1.LayerNorm_ln1                         512.0  \n",
      "43_block_list.1.sa.head_list.0.Linear_key           32.768k  \n",
      "44_block_list.1.sa.head_list.0.Linear_query         32.768k  \n",
      "45_block_list.1.sa.head_list.0.Linear_value         32.768k  \n",
      "46_block_list.1.sa.head_list.0.Dropout_dropout            -  \n",
      "47_block_list.1.sa.head_list.1.Linear_key           32.768k  \n",
      "48_block_list.1.sa.head_list.1.Linear_query         32.768k  \n",
      "49_block_list.1.sa.head_list.1.Linear_value         32.768k  \n",
      "50_block_list.1.sa.head_list.1.Dropout_dropout            -  \n",
      "51_block_list.1.sa.head_list.2.Linear_key           32.768k  \n",
      "52_block_list.1.sa.head_list.2.Linear_query         32.768k  \n",
      "53_block_list.1.sa.head_list.2.Linear_value         32.768k  \n",
      "54_block_list.1.sa.head_list.2.Dropout_dropout            -  \n",
      "55_block_list.1.sa.head_list.3.Linear_key           32.768k  \n",
      "56_block_list.1.sa.head_list.3.Linear_query         32.768k  \n",
      "57_block_list.1.sa.head_list.3.Linear_value         32.768k  \n",
      "58_block_list.1.sa.head_list.3.Dropout_dropout            -  \n",
      "59_block_list.1.sa.head_list.4.Linear_key           32.768k  \n",
      "60_block_list.1.sa.head_list.4.Linear_query         32.768k  \n",
      "61_block_list.1.sa.head_list.4.Linear_value         32.768k  \n",
      "62_block_list.1.sa.head_list.4.Dropout_dropout            -  \n",
      "63_block_list.1.sa.head_list.5.Linear_key           32.768k  \n",
      "64_block_list.1.sa.head_list.5.Linear_query         32.768k  \n",
      "65_block_list.1.sa.head_list.5.Linear_value         32.768k  \n",
      "66_block_list.1.sa.head_list.5.Dropout_dropout            -  \n",
      "67_block_list.1.sa.head_list.6.Linear_key           32.768k  \n",
      "68_block_list.1.sa.head_list.6.Linear_query         32.768k  \n",
      "69_block_list.1.sa.head_list.6.Linear_value         32.768k  \n",
      "70_block_list.1.sa.head_list.6.Dropout_dropout            -  \n",
      "71_block_list.1.sa.head_list.7.Linear_key           32.768k  \n",
      "72_block_list.1.sa.head_list.7.Linear_query         32.768k  \n",
      "73_block_list.1.sa.head_list.7.Linear_value         32.768k  \n",
      "74_block_list.1.sa.head_list.7.Dropout_dropout            -  \n",
      "75_block_list.1.sa.Linear_proj                     262.144k  \n",
      "76_block_list.1.sa.Dropout_dropout                        -  \n",
      "77_block_list.1.LayerNorm_ln2                         512.0  \n",
      "78_block_list.1.ff.layers.Linear_0                1.048576M  \n",
      "79_block_list.1.ff.layers.GELU_1                          -  \n",
      "80_block_list.1.ff.layers.Linear_2                1.048576M  \n",
      "81_block_list.1.ff.layers.Dropout_3                       -  \n",
      "82_block_list.2.LayerNorm_ln1                         512.0  \n",
      "83_block_list.2.sa.head_list.0.Linear_key           32.768k  \n",
      "84_block_list.2.sa.head_list.0.Linear_query         32.768k  \n",
      "85_block_list.2.sa.head_list.0.Linear_value         32.768k  \n",
      "86_block_list.2.sa.head_list.0.Dropout_dropout            -  \n",
      "87_block_list.2.sa.head_list.1.Linear_key           32.768k  \n",
      "88_block_list.2.sa.head_list.1.Linear_query         32.768k  \n",
      "89_block_list.2.sa.head_list.1.Linear_value         32.768k  \n",
      "90_block_list.2.sa.head_list.1.Dropout_dropout            -  \n",
      "91_block_list.2.sa.head_list.2.Linear_key           32.768k  \n",
      "92_block_list.2.sa.head_list.2.Linear_query         32.768k  \n",
      "93_block_list.2.sa.head_list.2.Linear_value         32.768k  \n",
      "94_block_list.2.sa.head_list.2.Dropout_dropout            -  \n",
      "95_block_list.2.sa.head_list.3.Linear_key           32.768k  \n",
      "96_block_list.2.sa.head_list.3.Linear_query         32.768k  \n",
      "97_block_list.2.sa.head_list.3.Linear_value         32.768k  \n",
      "98_block_list.2.sa.head_list.3.Dropout_dropout            -  \n",
      "99_block_list.2.sa.head_list.4.Linear_key           32.768k  \n",
      "100_block_list.2.sa.head_list.4.Linear_query        32.768k  \n",
      "101_block_list.2.sa.head_list.4.Linear_value        32.768k  \n",
      "102_block_list.2.sa.head_list.4.Dropout_dropout           -  \n",
      "103_block_list.2.sa.head_list.5.Linear_key          32.768k  \n",
      "104_block_list.2.sa.head_list.5.Linear_query        32.768k  \n",
      "105_block_list.2.sa.head_list.5.Linear_value        32.768k  \n",
      "106_block_list.2.sa.head_list.5.Dropout_dropout           -  \n",
      "107_block_list.2.sa.head_list.6.Linear_key          32.768k  \n",
      "108_block_list.2.sa.head_list.6.Linear_query        32.768k  \n",
      "109_block_list.2.sa.head_list.6.Linear_value        32.768k  \n",
      "110_block_list.2.sa.head_list.6.Dropout_dropout           -  \n",
      "111_block_list.2.sa.head_list.7.Linear_key          32.768k  \n",
      "112_block_list.2.sa.head_list.7.Linear_query        32.768k  \n",
      "113_block_list.2.sa.head_list.7.Linear_value        32.768k  \n",
      "114_block_list.2.sa.head_list.7.Dropout_dropout           -  \n",
      "115_block_list.2.sa.Linear_proj                    262.144k  \n",
      "116_block_list.2.sa.Dropout_dropout                       -  \n",
      "117_block_list.2.LayerNorm_ln2                        512.0  \n",
      "118_block_list.2.ff.layers.Linear_0               1.048576M  \n",
      "119_block_list.2.ff.layers.GELU_1                         -  \n",
      "120_block_list.2.ff.layers.Linear_2               1.048576M  \n",
      "121_block_list.2.ff.layers.Dropout_3                      -  \n",
      "122_block_list.3.LayerNorm_ln1                        512.0  \n",
      "123_block_list.3.sa.head_list.0.Linear_key          32.768k  \n",
      "124_block_list.3.sa.head_list.0.Linear_query        32.768k  \n",
      "125_block_list.3.sa.head_list.0.Linear_value        32.768k  \n",
      "126_block_list.3.sa.head_list.0.Dropout_dropout           -  \n",
      "127_block_list.3.sa.head_list.1.Linear_key          32.768k  \n",
      "128_block_list.3.sa.head_list.1.Linear_query        32.768k  \n",
      "129_block_list.3.sa.head_list.1.Linear_value        32.768k  \n",
      "130_block_list.3.sa.head_list.1.Dropout_dropout           -  \n",
      "131_block_list.3.sa.head_list.2.Linear_key          32.768k  \n",
      "132_block_list.3.sa.head_list.2.Linear_query        32.768k  \n",
      "133_block_list.3.sa.head_list.2.Linear_value        32.768k  \n",
      "134_block_list.3.sa.head_list.2.Dropout_dropout           -  \n",
      "135_block_list.3.sa.head_list.3.Linear_key          32.768k  \n",
      "136_block_list.3.sa.head_list.3.Linear_query        32.768k  \n",
      "137_block_list.3.sa.head_list.3.Linear_value        32.768k  \n",
      "138_block_list.3.sa.head_list.3.Dropout_dropout           -  \n",
      "139_block_list.3.sa.head_list.4.Linear_key          32.768k  \n",
      "140_block_list.3.sa.head_list.4.Linear_query        32.768k  \n",
      "141_block_list.3.sa.head_list.4.Linear_value        32.768k  \n",
      "142_block_list.3.sa.head_list.4.Dropout_dropout           -  \n",
      "143_block_list.3.sa.head_list.5.Linear_key          32.768k  \n",
      "144_block_list.3.sa.head_list.5.Linear_query        32.768k  \n",
      "145_block_list.3.sa.head_list.5.Linear_value        32.768k  \n",
      "146_block_list.3.sa.head_list.5.Dropout_dropout           -  \n",
      "147_block_list.3.sa.head_list.6.Linear_key          32.768k  \n",
      "148_block_list.3.sa.head_list.6.Linear_query        32.768k  \n",
      "149_block_list.3.sa.head_list.6.Linear_value        32.768k  \n",
      "150_block_list.3.sa.head_list.6.Dropout_dropout           -  \n",
      "151_block_list.3.sa.head_list.7.Linear_key          32.768k  \n",
      "152_block_list.3.sa.head_list.7.Linear_query        32.768k  \n",
      "153_block_list.3.sa.head_list.7.Linear_value        32.768k  \n",
      "154_block_list.3.sa.head_list.7.Dropout_dropout           -  \n",
      "155_block_list.3.sa.Linear_proj                    262.144k  \n",
      "156_block_list.3.sa.Dropout_dropout                       -  \n",
      "157_block_list.3.LayerNorm_ln2                        512.0  \n",
      "158_block_list.3.ff.layers.Linear_0               1.048576M  \n",
      "159_block_list.3.ff.layers.GELU_1                         -  \n",
      "160_block_list.3.ff.layers.Linear_2               1.048576M  \n",
      "161_block_list.3.ff.layers.Dropout_3                      -  \n",
      "162_block_list.4.LayerNorm_ln1                        512.0  \n",
      "163_block_list.4.sa.head_list.0.Linear_key          32.768k  \n",
      "164_block_list.4.sa.head_list.0.Linear_query        32.768k  \n",
      "165_block_list.4.sa.head_list.0.Linear_value        32.768k  \n",
      "166_block_list.4.sa.head_list.0.Dropout_dropout           -  \n",
      "167_block_list.4.sa.head_list.1.Linear_key          32.768k  \n",
      "168_block_list.4.sa.head_list.1.Linear_query        32.768k  \n",
      "169_block_list.4.sa.head_list.1.Linear_value        32.768k  \n",
      "170_block_list.4.sa.head_list.1.Dropout_dropout           -  \n",
      "171_block_list.4.sa.head_list.2.Linear_key          32.768k  \n",
      "172_block_list.4.sa.head_list.2.Linear_query        32.768k  \n",
      "173_block_list.4.sa.head_list.2.Linear_value        32.768k  \n",
      "174_block_list.4.sa.head_list.2.Dropout_dropout           -  \n",
      "175_block_list.4.sa.head_list.3.Linear_key          32.768k  \n",
      "176_block_list.4.sa.head_list.3.Linear_query        32.768k  \n",
      "177_block_list.4.sa.head_list.3.Linear_value        32.768k  \n",
      "178_block_list.4.sa.head_list.3.Dropout_dropout           -  \n",
      "179_block_list.4.sa.head_list.4.Linear_key          32.768k  \n",
      "180_block_list.4.sa.head_list.4.Linear_query        32.768k  \n",
      "181_block_list.4.sa.head_list.4.Linear_value        32.768k  \n",
      "182_block_list.4.sa.head_list.4.Dropout_dropout           -  \n",
      "183_block_list.4.sa.head_list.5.Linear_key          32.768k  \n",
      "184_block_list.4.sa.head_list.5.Linear_query        32.768k  \n",
      "185_block_list.4.sa.head_list.5.Linear_value        32.768k  \n",
      "186_block_list.4.sa.head_list.5.Dropout_dropout           -  \n",
      "187_block_list.4.sa.head_list.6.Linear_key          32.768k  \n",
      "188_block_list.4.sa.head_list.6.Linear_query        32.768k  \n",
      "189_block_list.4.sa.head_list.6.Linear_value        32.768k  \n",
      "190_block_list.4.sa.head_list.6.Dropout_dropout           -  \n",
      "191_block_list.4.sa.head_list.7.Linear_key          32.768k  \n",
      "192_block_list.4.sa.head_list.7.Linear_query        32.768k  \n",
      "193_block_list.4.sa.head_list.7.Linear_value        32.768k  \n",
      "194_block_list.4.sa.head_list.7.Dropout_dropout           -  \n",
      "195_block_list.4.sa.Linear_proj                    262.144k  \n",
      "196_block_list.4.sa.Dropout_dropout                       -  \n",
      "197_block_list.4.LayerNorm_ln2                        512.0  \n",
      "198_block_list.4.ff.layers.Linear_0               1.048576M  \n",
      "199_block_list.4.ff.layers.GELU_1                         -  \n",
      "200_block_list.4.ff.layers.Linear_2               1.048576M  \n",
      "201_block_list.4.ff.layers.Dropout_3                      -  \n",
      "202_block_list.5.LayerNorm_ln1                        512.0  \n",
      "203_block_list.5.sa.head_list.0.Linear_key          32.768k  \n",
      "204_block_list.5.sa.head_list.0.Linear_query        32.768k  \n",
      "205_block_list.5.sa.head_list.0.Linear_value        32.768k  \n",
      "206_block_list.5.sa.head_list.0.Dropout_dropout           -  \n",
      "207_block_list.5.sa.head_list.1.Linear_key          32.768k  \n",
      "208_block_list.5.sa.head_list.1.Linear_query        32.768k  \n",
      "209_block_list.5.sa.head_list.1.Linear_value        32.768k  \n",
      "210_block_list.5.sa.head_list.1.Dropout_dropout           -  \n",
      "211_block_list.5.sa.head_list.2.Linear_key          32.768k  \n",
      "212_block_list.5.sa.head_list.2.Linear_query        32.768k  \n",
      "213_block_list.5.sa.head_list.2.Linear_value        32.768k  \n",
      "214_block_list.5.sa.head_list.2.Dropout_dropout           -  \n",
      "215_block_list.5.sa.head_list.3.Linear_key          32.768k  \n",
      "216_block_list.5.sa.head_list.3.Linear_query        32.768k  \n",
      "217_block_list.5.sa.head_list.3.Linear_value        32.768k  \n",
      "218_block_list.5.sa.head_list.3.Dropout_dropout           -  \n",
      "219_block_list.5.sa.head_list.4.Linear_key          32.768k  \n",
      "220_block_list.5.sa.head_list.4.Linear_query        32.768k  \n",
      "221_block_list.5.sa.head_list.4.Linear_value        32.768k  \n",
      "222_block_list.5.sa.head_list.4.Dropout_dropout           -  \n",
      "223_block_list.5.sa.head_list.5.Linear_key          32.768k  \n",
      "224_block_list.5.sa.head_list.5.Linear_query        32.768k  \n",
      "225_block_list.5.sa.head_list.5.Linear_value        32.768k  \n",
      "226_block_list.5.sa.head_list.5.Dropout_dropout           -  \n",
      "227_block_list.5.sa.head_list.6.Linear_key          32.768k  \n",
      "228_block_list.5.sa.head_list.6.Linear_query        32.768k  \n",
      "229_block_list.5.sa.head_list.6.Linear_value        32.768k  \n",
      "230_block_list.5.sa.head_list.6.Dropout_dropout           -  \n",
      "231_block_list.5.sa.head_list.7.Linear_key          32.768k  \n",
      "232_block_list.5.sa.head_list.7.Linear_query        32.768k  \n",
      "233_block_list.5.sa.head_list.7.Linear_value        32.768k  \n",
      "234_block_list.5.sa.head_list.7.Dropout_dropout           -  \n",
      "235_block_list.5.sa.Linear_proj                    262.144k  \n",
      "236_block_list.5.sa.Dropout_dropout                       -  \n",
      "237_block_list.5.LayerNorm_ln2                        512.0  \n",
      "238_block_list.5.ff.layers.Linear_0               1.048576M  \n",
      "239_block_list.5.ff.layers.GELU_1                         -  \n",
      "240_block_list.5.ff.layers.Linear_2               1.048576M  \n",
      "241_block_list.5.ff.layers.Dropout_3                      -  \n",
      "242_block_list.6.LayerNorm_ln1                        512.0  \n",
      "243_block_list.6.sa.head_list.0.Linear_key          32.768k  \n",
      "244_block_list.6.sa.head_list.0.Linear_query        32.768k  \n",
      "245_block_list.6.sa.head_list.0.Linear_value        32.768k  \n",
      "246_block_list.6.sa.head_list.0.Dropout_dropout           -  \n",
      "247_block_list.6.sa.head_list.1.Linear_key          32.768k  \n",
      "248_block_list.6.sa.head_list.1.Linear_query        32.768k  \n",
      "249_block_list.6.sa.head_list.1.Linear_value        32.768k  \n",
      "250_block_list.6.sa.head_list.1.Dropout_dropout           -  \n",
      "251_block_list.6.sa.head_list.2.Linear_key          32.768k  \n",
      "252_block_list.6.sa.head_list.2.Linear_query        32.768k  \n",
      "253_block_list.6.sa.head_list.2.Linear_value        32.768k  \n",
      "254_block_list.6.sa.head_list.2.Dropout_dropout           -  \n",
      "255_block_list.6.sa.head_list.3.Linear_key          32.768k  \n",
      "256_block_list.6.sa.head_list.3.Linear_query        32.768k  \n",
      "257_block_list.6.sa.head_list.3.Linear_value        32.768k  \n",
      "258_block_list.6.sa.head_list.3.Dropout_dropout           -  \n",
      "259_block_list.6.sa.head_list.4.Linear_key          32.768k  \n",
      "260_block_list.6.sa.head_list.4.Linear_query        32.768k  \n",
      "261_block_list.6.sa.head_list.4.Linear_value        32.768k  \n",
      "262_block_list.6.sa.head_list.4.Dropout_dropout           -  \n",
      "263_block_list.6.sa.head_list.5.Linear_key          32.768k  \n",
      "264_block_list.6.sa.head_list.5.Linear_query        32.768k  \n",
      "265_block_list.6.sa.head_list.5.Linear_value        32.768k  \n",
      "266_block_list.6.sa.head_list.5.Dropout_dropout           -  \n",
      "267_block_list.6.sa.head_list.6.Linear_key          32.768k  \n",
      "268_block_list.6.sa.head_list.6.Linear_query        32.768k  \n",
      "269_block_list.6.sa.head_list.6.Linear_value        32.768k  \n",
      "270_block_list.6.sa.head_list.6.Dropout_dropout           -  \n",
      "271_block_list.6.sa.head_list.7.Linear_key          32.768k  \n",
      "272_block_list.6.sa.head_list.7.Linear_query        32.768k  \n",
      "273_block_list.6.sa.head_list.7.Linear_value        32.768k  \n",
      "274_block_list.6.sa.head_list.7.Dropout_dropout           -  \n",
      "275_block_list.6.sa.Linear_proj                    262.144k  \n",
      "276_block_list.6.sa.Dropout_dropout                       -  \n",
      "277_block_list.6.LayerNorm_ln2                        512.0  \n",
      "278_block_list.6.ff.layers.Linear_0               1.048576M  \n",
      "279_block_list.6.ff.layers.GELU_1                         -  \n",
      "280_block_list.6.ff.layers.Linear_2               1.048576M  \n",
      "281_block_list.6.ff.layers.Dropout_3                      -  \n",
      "282_block_list.7.LayerNorm_ln1                        512.0  \n",
      "283_block_list.7.sa.head_list.0.Linear_key          32.768k  \n",
      "284_block_list.7.sa.head_list.0.Linear_query        32.768k  \n",
      "285_block_list.7.sa.head_list.0.Linear_value        32.768k  \n",
      "286_block_list.7.sa.head_list.0.Dropout_dropout           -  \n",
      "287_block_list.7.sa.head_list.1.Linear_key          32.768k  \n",
      "288_block_list.7.sa.head_list.1.Linear_query        32.768k  \n",
      "289_block_list.7.sa.head_list.1.Linear_value        32.768k  \n",
      "290_block_list.7.sa.head_list.1.Dropout_dropout           -  \n",
      "291_block_list.7.sa.head_list.2.Linear_key          32.768k  \n",
      "292_block_list.7.sa.head_list.2.Linear_query        32.768k  \n",
      "293_block_list.7.sa.head_list.2.Linear_value        32.768k  \n",
      "294_block_list.7.sa.head_list.2.Dropout_dropout           -  \n",
      "295_block_list.7.sa.head_list.3.Linear_key          32.768k  \n",
      "296_block_list.7.sa.head_list.3.Linear_query        32.768k  \n",
      "297_block_list.7.sa.head_list.3.Linear_value        32.768k  \n",
      "298_block_list.7.sa.head_list.3.Dropout_dropout           -  \n",
      "299_block_list.7.sa.head_list.4.Linear_key          32.768k  \n",
      "300_block_list.7.sa.head_list.4.Linear_query        32.768k  \n",
      "301_block_list.7.sa.head_list.4.Linear_value        32.768k  \n",
      "302_block_list.7.sa.head_list.4.Dropout_dropout           -  \n",
      "303_block_list.7.sa.head_list.5.Linear_key          32.768k  \n",
      "304_block_list.7.sa.head_list.5.Linear_query        32.768k  \n",
      "305_block_list.7.sa.head_list.5.Linear_value        32.768k  \n",
      "306_block_list.7.sa.head_list.5.Dropout_dropout           -  \n",
      "307_block_list.7.sa.head_list.6.Linear_key          32.768k  \n",
      "308_block_list.7.sa.head_list.6.Linear_query        32.768k  \n",
      "309_block_list.7.sa.head_list.6.Linear_value        32.768k  \n",
      "310_block_list.7.sa.head_list.6.Dropout_dropout           -  \n",
      "311_block_list.7.sa.head_list.7.Linear_key          32.768k  \n",
      "312_block_list.7.sa.head_list.7.Linear_query        32.768k  \n",
      "313_block_list.7.sa.head_list.7.Linear_value        32.768k  \n",
      "314_block_list.7.sa.head_list.7.Dropout_dropout           -  \n",
      "315_block_list.7.sa.Linear_proj                    262.144k  \n",
      "316_block_list.7.sa.Dropout_dropout                       -  \n",
      "317_block_list.7.LayerNorm_ln2                        512.0  \n",
      "318_block_list.7.ff.layers.Linear_0               1.048576M  \n",
      "319_block_list.7.ff.layers.GELU_1                         -  \n",
      "320_block_list.7.ff.layers.Linear_2               1.048576M  \n",
      "321_block_list.7.ff.layers.Dropout_3                      -  \n",
      "322_final_ln                                          512.0  \n",
      "323_lm_head                                      25.731584M  \n",
      "------------------------------------------------------------------------------------------------------\n",
      "                          Totals\n",
      "Total params          76.852305M\n",
      "Trainable params      76.852305M\n",
      "Non-trainable params         0.0\n",
      "Mult-Adds             76.768768M\n",
      "======================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssg2/miniconda3/envs/idl/lib/python3.8/site-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: The default value of numeric_only in DataFrame.sum is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df_sum = df.sum()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_token_embeddings</th>\n",
       "      <td>[512, 50257]</td>\n",
       "      <td>[8, 256, 512]</td>\n",
       "      <td>25731584.0</td>\n",
       "      <td>25731584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_position_embeddings</th>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[256, 512]</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>131072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_block_list.0.LayerNorm_ln1</th>\n",
       "      <td>[512]</td>\n",
       "      <td>[8, 256, 512]</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_block_list.0.sa.head_list.0.Linear_key</th>\n",
       "      <td>[512, 64]</td>\n",
       "      <td>[8, 256, 64]</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>32768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_block_list.0.sa.head_list.0.Linear_query</th>\n",
       "      <td>[512, 64]</td>\n",
       "      <td>[8, 256, 64]</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>32768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319_block_list.7.ff.layers.GELU_1</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 256, 2048]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320_block_list.7.ff.layers.Linear_2</th>\n",
       "      <td>[2048, 512]</td>\n",
       "      <td>[8, 256, 512]</td>\n",
       "      <td>1049088.0</td>\n",
       "      <td>1048576.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321_block_list.7.ff.layers.Dropout_3</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 256, 512]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322_final_ln</th>\n",
       "      <td>[512]</td>\n",
       "      <td>[8, 256, 512]</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323_lm_head</th>\n",
       "      <td>[512, 50257]</td>\n",
       "      <td>[8, 256, 50257]</td>\n",
       "      <td>25781841.0</td>\n",
       "      <td>25731584.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Kernel Shape     Output Shape  \\\n",
       "Layer                                                                       \n",
       "0_token_embeddings                          [512, 50257]    [8, 256, 512]   \n",
       "1_position_embeddings                         [512, 256]       [256, 512]   \n",
       "2_block_list.0.LayerNorm_ln1                       [512]    [8, 256, 512]   \n",
       "3_block_list.0.sa.head_list.0.Linear_key       [512, 64]     [8, 256, 64]   \n",
       "4_block_list.0.sa.head_list.0.Linear_query     [512, 64]     [8, 256, 64]   \n",
       "...                                                  ...              ...   \n",
       "319_block_list.7.ff.layers.GELU_1                      -   [8, 256, 2048]   \n",
       "320_block_list.7.ff.layers.Linear_2          [2048, 512]    [8, 256, 512]   \n",
       "321_block_list.7.ff.layers.Dropout_3                   -    [8, 256, 512]   \n",
       "322_final_ln                                       [512]    [8, 256, 512]   \n",
       "323_lm_head                                 [512, 50257]  [8, 256, 50257]   \n",
       "\n",
       "                                                Params   Mult-Adds  \n",
       "Layer                                                               \n",
       "0_token_embeddings                          25731584.0  25731584.0  \n",
       "1_position_embeddings                         131072.0    131072.0  \n",
       "2_block_list.0.LayerNorm_ln1                    1024.0       512.0  \n",
       "3_block_list.0.sa.head_list.0.Linear_key       32768.0     32768.0  \n",
       "4_block_list.0.sa.head_list.0.Linear_query     32768.0     32768.0  \n",
       "...                                                ...         ...  \n",
       "319_block_list.7.ff.layers.GELU_1                  NaN         NaN  \n",
       "320_block_list.7.ff.layers.Linear_2          1049088.0   1048576.0  \n",
       "321_block_list.7.ff.layers.Dropout_3               NaN         NaN  \n",
       "322_final_ln                                    1024.0       512.0  \n",
       "323_lm_head                                 25781841.0  25731584.0  \n",
       "\n",
       "[324 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, xb.to(device), yb.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "N8rVNj48QLUc"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "\n",
    "\n",
    "# for generation\n",
    "start_ix = torch.zeros((1,1), dtype=torch.long, device=device) # (newline character in a single batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "eT5YkoSNQLUc"
   },
   "outputs": [],
   "source": [
    "# poor man's lr scheduler. why? because cosine with warmup isn't readily available on torch (it's warm RESTARTS)\n",
    "# but idc about restarting eh?\n",
    "def get_lr(it):\n",
    "    \"get lr at a specific iteration\"\n",
    "    max_lr = config.lr\n",
    "    min_lr = config.min_lr\n",
    "    warmup_iters = config.warmup_iters\n",
    "    max_lr_decay_iters = config.num_iters # can also be made into another param\n",
    "    if it <= warmup_iters:\n",
    "        return max_lr * (it / warmup_iters)\n",
    "\n",
    "    if it > max_lr_decay_iters:\n",
    "        # decaying only up to a certain point, interesting\n",
    "        return min_lr\n",
    "    ratio = (it - warmup_iters) / (max_lr_decay_iters - warmup_iters) # how much % of decay cycle is done?\n",
    "    coeff = 0.5 * (1 + math.cos(math.pi * ratio)) # [0,1]\n",
    "    return min_lr + coeff * (max_lr - min_lr) # beautiful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "9X5IiaarQLUc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_lr():\n",
    "    import random\n",
    "    import matplotlib.pyplot as plt\n",
    "    x = [i for i in range(0,10000,100)]\n",
    "    y = [get_lr(i) for i in x]\n",
    "    plt.plot(x, y)\n",
    "    plt.show()\n",
    "\n",
    "test_lr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CVOkmmi_QLUc"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "@torch.no_grad()\n",
    "def estimate_losses(config):\n",
    "    model.eval()\n",
    "    losses = {'train': -1., 'val': -1.}\n",
    "    for split in ['train', 'val']:\n",
    "        loss = 0\n",
    "        for _ in range(config.eval_iters):\n",
    "            # xb, yb = next(iter(val_loader))\n",
    "            # xb, yb = xb.to(device), yb.to(device)\n",
    "            xb, yb = get_batch('val')\n",
    "            loss += model(xb, yb)[1].item()\n",
    "        loss /= config.eval_iters\n",
    "        if split == 'train':\n",
    "            losses['train'] = loss\n",
    "        else:\n",
    "            losses['val'] = loss\n",
    "    model.train()\n",
    "    return losses\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "47ZGa3tkMSAi"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_losses(config, train_loader, val_loader):\n",
    "    model.eval()\n",
    "    losses = {'train': -1., 'val': -1.}\n",
    "    train_loss = 0\n",
    "    train_iters = min(config.eval_iters, len(train_loader))\n",
    "    for i, (xb, yb) in enumerate(train_loader):\n",
    "        if i >= train_iters:\n",
    "            break\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        _, loss = model(xb, yb)\n",
    "        train_loss += loss.item()\n",
    "    losses['train'] = train_loss / train_iters\n",
    "\n",
    "    # Evaluate validation loss (considering only config.eval_iters iterations)\n",
    "    val_loss = 0\n",
    "    val_iters = min(config.eval_iters, len(val_loader))\n",
    "    for i, (xb, yb) in enumerate(val_loader):\n",
    "        if i >= val_iters:\n",
    "            break\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        _, loss = model(xb, yb)\n",
    "        val_loss += loss.item()\n",
    "    losses['val'] = val_loss / val_iters\n",
    "\n",
    "    model.train()\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "kEvNGlwJ1aPr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Load Pretrained\n",
    "CKPT_PATH = 'exps/pretrain_v2/best_model.pth'\n",
    "ckpt = torch.load(CKPT_PATH)\n",
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJfqzDg2QLUc"
   },
   "source": [
    "## WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "no1t4aJ5QLUc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    }
   ],
   "source": [
    "wandb.login(key=\"\")\n",
    "run = wandb.init(\n",
    "        name    = 'pretrain_v1', ## Wandb creates random run names if you skip this field\n",
    "        reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
    "        # entity = 'thunderbuddies',\n",
    "        # run_id = ### Insert specific run id here if you want to resume a previous run\n",
    "        # resume = \"must\" ### You need this to resume previous runs, but comment out reinit = True when using this\n",
    "        project = \"ideal_gpt\", ### Project should be created in your wandb account\n",
    "        config = config, ### Wandb Config for your run,\n",
    "        mode='disabled'\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "smwh3FSyQLUc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "XLdX2OG3QLUd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "cur_iter = 0\n",
    "best_val = 1e9\n",
    "best_path = 'tmp_best_model.pth'\n",
    "running_loss = 0.0\n",
    "loss_counter=0\n",
    "pbar = tqdm(total=config.num_iters, dynamic_ncols=True, leave=False, position=0, desc=\"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Z9UAAmpQLUd"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "while cur_iter <= config.num_iters:\n",
    "    optimizer.zero_grad(set_to_none = True) # https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html\n",
    "    # poor man's lr scheduler\n",
    "    cur_lr = get_lr(cur_iter) if config.lr_decay else config.lr\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = cur_lr\n",
    "\n",
    "    # xb, yb = next(iter(train_loader))\n",
    "    for micro_step in range(config.gradient_accumulation_steps):\n",
    "        xb, yb = get_batch('train')\n",
    "        # xb, yb = xb.to(device), yb.to(device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            logits, loss = model(xb, yb)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        train_loss = running_loss / (loss_counter + 1)\n",
    "        loss_counter += 1\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "    if config.grad_clip != 0.0:\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip)\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "    # val every eval_intervals\n",
    "    if cur_iter % config.eval_interval == 0:\n",
    "        losses = estimate_losses(config)\n",
    "        val_loss = losses['val']\n",
    "        train_loss = losses['train']\n",
    "        print(f'Val @ Epoch {cur_iter}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}')\n",
    "        wandb.log({\n",
    "            'val_loss': val_loss,\n",
    "            'iter': cur_iter,\n",
    "            'lr': optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "            print(f'Saved best model to {best_path}')\n",
    "        print('Sample Generation')\n",
    "        print(tokenizer.decode(model.generate(start_ix, 100)[0].tolist()))\n",
    "\n",
    "    # train logs\n",
    "    wandb.log({\n",
    "        'train_loss': train_loss,\n",
    "        'iter': cur_iter,\n",
    "        'lr': cur_lr\n",
    "    })\n",
    "    pbar.set_postfix(\n",
    "            loss = \"{:.04f}\".format(train_loss),\n",
    "            lr = cur_lr\n",
    "        )\n",
    "    pbar.update()\n",
    "\n",
    "\n",
    "    cur_iter += 1\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "BRMAeKP5PfOJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val @ Epoch 0: Train Loss=2.2386, Val Loss=2.9403\n",
      "Saved best model to tmp_best_model.pth\n",
      "Sample Generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 23/10000 [02:25<60:48:30, 21.94s/it, loss=2.2386, lr=0]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! We officially launched MMD here! Get our daily newsletter HERE!<|endoftext|>New culture\n",
      "\n",
      "Narc levitation has evolved from an island which practiced practicality. Now it has taken the form of a perfectly normal, beautiful, urban startup called Misanthropy, or MakuinOBY. MakuinOBY is not simply a sustainable hobby one can take to make the ‘thing’ off, it is also one that decides what goes making use of them all at enlisted,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 28/10000 [02:40<17:14:53,  6.23s/it, loss=3.1096, lr=1e-5]"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "NUM_EPOCHS=5\n",
    "cur_iter=0\n",
    "\n",
    "while cur_iter <= NUM_EPOCHS:\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    cur_lr = get_lr(cur_iter) if config.lr_decay else config.lr\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = cur_lr\n",
    "\n",
    "    # Iterate over batches from the DataLoader\n",
    "    steps = 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            logits, loss = model(xb, yb)\n",
    "        running_loss += loss.item()\n",
    "        train_loss = running_loss / (loss_counter + 1)\n",
    "        loss_counter += 1\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        steps += 1\n",
    "        if steps % config.gradient_accumulation_steps == 0:\n",
    "            if config.grad_clip != 0.0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip)\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        del xb, yb, logits, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    if cur_iter % config.eval_interval == 0:\n",
    "        losses = estimate_losses(config, train_loader, val_loader)  # Now we pass val_loader to estimate_losses\n",
    "        val_loss = losses['val']\n",
    "        train_loss = losses['train']\n",
    "        print(f'Val @ Epoch {cur_iter}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}')\n",
    "        wandb.log({\n",
    "            'val_loss': val_loss,\n",
    "            'iter': cur_iter,\n",
    "            'lr': optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "            print(f'Saved best model to {best_path}')\n",
    "        print('Sample Generation')\n",
    "        print(tokenizer.decode(model.generate(start_ix, 100)[0].tolist()))\n",
    "\n",
    "    # Log training metrics for current iteration\n",
    "    wandb.log({\n",
    "        'train_loss': train_loss,\n",
    "        'iter': cur_iter,\n",
    "        'lr': cur_lr\n",
    "    })\n",
    "    pbar.set_postfix(loss=\"{:.04f}\".format(train_loss), lr=cur_lr)\n",
    "    pbar.update()\n",
    "\n",
    "    cur_iter += 1  # Increment iteration count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wgKbRvnvQLUd"
   },
   "outputs": [],
   "source": [
    "print(tokenizer.decode(model.generate(start_ix, 100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNo-EkEkQLUd"
   },
   "outputs": [],
   "source": [
    "def prompt(p, max_len=100):\n",
    "    if not p:\n",
    "        print('Enter non-empty string!')\n",
    "        return\n",
    "\n",
    "    tokens = torch.tensor(tokenizer.encode_ordinary(p))\n",
    "    tokens = tokens.unsqueeze(0) # add batch dimension\n",
    "    tokens = tokens.to(device)\n",
    "    return tokenizer.decode(model.generate(tokens, max_len)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3F-jfFBjQLUd"
   },
   "outputs": [],
   "source": [
    "prompt('Hello world, my name is' , 1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "024d4f026f184760a2f3b4eb2c624a95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "067898ad433a455e8deb863494b7a428": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0d25851a01942868ce5d5e4d76ad284",
      "placeholder": "​",
      "style": "IPY_MODEL_12257421e51e4a7a916880b5fb690d90",
      "value": " 39199/392632 [00:37&lt;04:27, 1320.28 examples/s]"
     }
    },
    "12257421e51e4a7a916880b5fb690d90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2719a96cddd74b32870d18f31f4ad293": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "307746d700d34a94b2a5d2612ff2efb0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "642e89fcada04c16a34b469b21bf80c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_66a71622ed53488ebabc61778e624b96",
       "IPY_MODEL_abf72b3336b14d82b59cfc42b91f4f41",
       "IPY_MODEL_067898ad433a455e8deb863494b7a428"
      ],
      "layout": "IPY_MODEL_2719a96cddd74b32870d18f31f4ad293"
     }
    },
    "64ff9a51f7264cb68d848f111b0e6857": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "66a71622ed53488ebabc61778e624b96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7403d3083e740208a18888a170f975e",
      "placeholder": "​",
      "style": "IPY_MODEL_64ff9a51f7264cb68d848f111b0e6857",
      "value": "Applying chat template (num_proc=8):  10%"
     }
    },
    "abf72b3336b14d82b59cfc42b91f4f41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_307746d700d34a94b2a5d2612ff2efb0",
      "max": 392632,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_024d4f026f184760a2f3b4eb2c624a95",
      "value": 39199
     }
    },
    "b7403d3083e740208a18888a170f975e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0d25851a01942868ce5d5e4d76ad284": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
