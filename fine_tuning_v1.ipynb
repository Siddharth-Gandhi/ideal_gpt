{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUPM_w4HjJ3U"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "203bvpDsQLUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2df87a77-3150-4e9f-c5b2-35ffcf77657d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.4.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.8.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.12.25)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.23.5)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (15.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.23.5)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=15d43096f725231144c6ce91fbb69d4a030c4d11ca78052a6b18cddaf6d1f503\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install sacrebleu\n",
        "!pip install evaluate\n",
        "!pip install rouge_score\n",
        "\n",
        "import math\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import tiktoken\n",
        "from transformers import GPT2Tokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import load_dataset, load_metric, DatasetDict\n",
        "from torchsummaryX import summary\n",
        "import wandb\n",
        "from dataclasses import dataclass\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from multiprocessing import cpu_count\n",
        "import random\n",
        "import gc\n",
        "import pickle\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LovtcItVQLUX"
      },
      "outputs": [],
      "source": [
        "# set seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "cudnn.deterministic = True\n",
        "cudnn.benchmark = False\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_H8zHj2Swll"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68u9am1JSzIX",
        "outputId": "79ce33f4-4637-44a6-cf96-47a404d3ae97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "datasets_train = load_dataset(\"Shannnh/hw5-changed\", split = 'train')\n",
        "datasets_val = load_dataset(\"Shannnh/hw5-changed\", split = 'validation')\n",
        "datasets_test = load_dataset(\"Shannnh/hw5-changed\", split = 'test_ds')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m40ZM0re8-RR",
        "outputId": "9499ab94-bd55-4439-f7d7-23de84b891a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['Classifier', 'Prompt', 'Messages', 'PromptId'])\n",
            "392632\n",
            "27664\n",
            "15434\n"
          ]
        }
      ],
      "source": [
        "print(datasets_train[0].keys())\n",
        "print(len(datasets_train))\n",
        "print(len(datasets_val))\n",
        "print(len(datasets_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9FF1NANfYRw"
      },
      "outputs": [],
      "source": [
        "# datasets_train = datasets_train.shuffle(seed=42).select(range(100))\n",
        "# datasets_val = datasets_val.shuffle(seed=42).select(range(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3CVcHzOfYRx",
        "outputId": "0cc8c37b-fa33-4fce-d105-4f00ca3714fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Summarization', 'Question&Answer', 'SentimentAnalysis', 'NamedEntity']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "datasets_train.unique('Classifier')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-849v2wQQLUX"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Prz8c1bYQLUY",
        "outputId": "427fa9de-886b-46a6-c066-96f56816b0e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IDeaLGPTConfig(batch_size=8, gradient_accumulation_steps=4, num_iters=5, eval_iters=3, eval_interval=1, device='cuda', sequence_length=256, vocab_size=50257, num_blocks=8, num_heads=8, embed_dim=512, dropout=0.1, bias=False, num_workers=8, train_test_split=0.8, SUBSET_PERCENTAGE=0.01, lr=0.002, lr_decay=True, warmup_iters=1000, min_lr=6e-06, weight_decay=0.1, grad_clip=1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "@dataclass\n",
        "class IDeaLGPTConfig:\n",
        "\n",
        "    # General\n",
        "    batch_size: int = 8\n",
        "    gradient_accumulation_steps: int = 4\n",
        "    num_iters: int = 5\n",
        "    eval_iters: int = 3\n",
        "    eval_interval: int = 1\n",
        "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    # device: str = 'cpu'\n",
        "\n",
        "    # Model\n",
        "    sequence_length: int = 256\n",
        "    vocab_size: int = 50257 # gpt2 vocab\n",
        "    num_blocks: int = 8\n",
        "    num_heads: int = 8\n",
        "    embed_dim: int = 512\n",
        "    dropout: float = 0.1\n",
        "    bias: bool = False\n",
        "\n",
        "    # Data\n",
        "    num_workers: int = 8\n",
        "    train_test_split: float = 0.8\n",
        "    SUBSET_PERCENTAGE: float =0.01 # % of OWT to train on, between 0 and 1\n",
        "\n",
        "    # LR scheduler\n",
        "    lr: float = 2e-3\n",
        "    lr_decay: bool = True\n",
        "    warmup_iters: int = 1000\n",
        "    min_lr: float = 6e-6\n",
        "\n",
        "    # optimizer\n",
        "    weight_decay: float = 1e-1\n",
        "    grad_clip: float = 1.0\n",
        "\n",
        "\n",
        "config = IDeaLGPTConfig()\n",
        "device = config.device\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IkXs4hTQLUZ",
        "outputId": "27d3d54a-5c1b-49d8-a47d-0cc199f401d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Effective batch size = 32\n"
          ]
        }
      ],
      "source": [
        "print(f'Effective batch size = {config.batch_size * config.gradient_accumulation_steps}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6FXk8H1QLUZ"
      },
      "source": [
        "# Loading Data and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF87zNglQLUZ"
      },
      "outputs": [],
      "source": [
        "# hf_dataset = load_dataset(\"Skylion007/openwebtext\", split='train') # only has one split - train\n",
        "# hf_dataset = hf_dataset.with_format(\"torch\")\n",
        "# hf_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-UOmFJFQLUZ"
      },
      "outputs": [],
      "source": [
        "# # data = dataset['train'].shuffle(seed=42).select(range(int(len(dataset['train']) * SUBSET_PERCENTAGE)))\n",
        "# # hf_dataset = hf_dataset.select(range(int(len(hf_dataset) * config.SUBSET_PERCENTAGE)))\n",
        "# hf_dataset = hf_dataset.train_test_split(train_size=config.train_test_split)\n",
        "# hf_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DljsEgbQLUZ"
      },
      "outputs": [],
      "source": [
        "# train_hf_dataset, val_hf_dataset = hf_dataset['train'], hf_dataset['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bKU7Y-6QLUZ"
      },
      "source": [
        "## Tokenizer - OpenAI tiktoken (changed to GPT2Tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvwoPFbiQLUZ",
        "outputId": "20502cae-a7e7-4d04-a6c2-1c84254d2545"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[31373, 995]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#tokenizer = tiktoken.get_encoding(\"cl100k_base\") # gpt4 tokenizer - NOTE: need to change vocab_size in config if used\n",
        "#tokenizer = tiktoken.encoding_for_model('gpt-2')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.encode('hello world')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsUdOVMmjFJ1"
      },
      "outputs": [],
      "source": [
        "tokenizer.model_max_length = config.sequence_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_0F5g1T81XC"
      },
      "outputs": [],
      "source": [
        "tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAqwxz2xzasy",
        "outputId": "29ddbf9e-c687-4963-a9df-ee87460d0b89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50257"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "vocab_size = tokenizer.vocab_size #same as tiktoken\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFDoKw26tevh"
      },
      "outputs": [],
      "source": [
        "# set pad_token_id equal to the eos_token_id if not set\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcD3xq9d1PvS"
      },
      "outputs": [],
      "source": [
        "DEFAULT_CHAT_TEMPLATE = \"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + ' '.join(message['content'].split()[:150]) + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\"\n",
        "tokenizer.chat_template = DEFAULT_CHAT_TEMPLATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbRQjaafylLA"
      },
      "outputs": [],
      "source": [
        "def apply_chat_template(example, tokenizer):\n",
        "    messages = example[\"Messages\"]\n",
        "    #\n",
        "    example[\"text\"] = tokenizer.apply_chat_template(messages, tokenize=False, max_length=config.sequence_length, truncation=True)\n",
        "    example[\"tokens\"] = tokenizer.apply_chat_template(messages, tokenize=True, max_length=config.sequence_length, truncation=True)\n",
        "    return example\n",
        "\n",
        "column_names = list(datasets_train.features)\n",
        "datasets_train = datasets_train.map(apply_chat_template,\n",
        "                                num_proc=cpu_count(),\n",
        "                                fn_kwargs={\"tokenizer\": tokenizer},\n",
        "                                remove_columns=column_names,\n",
        "                                desc=\"Applying chat template\")\n",
        "datasets_val = datasets_val.map(apply_chat_template,\n",
        "                                num_proc=cpu_count(),\n",
        "                                fn_kwargs={\"tokenizer\": tokenizer},\n",
        "                                remove_columns=column_names,\n",
        "                                desc=\"Applying chat template\")\n",
        "datasets_test = datasets_test.map(apply_chat_template,\n",
        "                                num_proc=cpu_count(),\n",
        "                                fn_kwargs={\"tokenizer\": tokenizer},\n",
        "                                remove_columns=column_names,\n",
        "                                desc=\"Applying chat template\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPgMqZiO4bae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5efb276-6dbf-45aa-8408-cdc3e24a72f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 20952 of the processed training set:\n",
            "\n",
            "<|system|>\n",
            "<|endoftext|>\n",
            "<|user|>\n",
            "Economic_inequality While acknowledging the central role economic growth can potentially play in human development, poverty reduction and the achievement of the Millennium Development Goals, it is becoming widely understood amongst the development community that special efforts must be made to ensure poorer sections of society are able to participate in economic growth. The effect of economic growth on poverty reduction – the growth elasticity of poverty – can depend on the existing level of inequality. For instance, with low inequality a country with a growth rate of 2% per head and 40% of its population living in poverty, can halve poverty in ten years, but a country with high inequality would take nearly 60 years to achieve the same reduction. In the words of the Secretary General of the United Nations Ban Ki-Moon: \"While economic growth is necessary, it is not sufficient for progress on reducing poverty.\" What needs to<|endoftext|>\n",
            "<|assistant|>\n",
            "special efforts,special efforts,special efforts<|endoftext|>\n",
            "\n",
            "token: [27, 91, 10057, 91, 29, 198, 50256, 198, 27, 91, 7220, 91, 29, 198, 48307, 62, 500, 13237, 2893, 25937, 262, 4318, 2597, 3034, 3349, 460, 6196, 711, 287, 1692, 2478, 11, 8098, 7741, 290, 262, 13293, 286, 262, 26139, 7712, 28510, 11, 340, 318, 5033, 6768, 7247, 12077, 262, 2478, 2055, 326, 2041, 4040, 1276, 307, 925, 284, 4155, 26647, 9004, 286, 3592, 389, 1498, 284, 8277, 287, 3034, 3349, 13, 383, 1245, 286, 3034, 3349, 319, 8098, 7741, 784, 262, 3349, 27468, 414, 286, 8098, 784, 460, 4745, 319, 262, 4683, 1241, 286, 12791, 13, 1114, 4554, 11, 351, 1877, 12791, 257, 1499, 351, 257, 3349, 2494, 286, 362, 4, 583, 1182, 290, 2319, 4, 286, 663, 3265, 2877, 287, 8098, 11, 460, 10284, 303, 8098, 287, 3478, 812, 11, 475, 257, 1499, 351, 1029, 12791, 561, 1011, 3016, 3126, 812, 284, 4620, 262, 976, 7741, 13, 554, 262, 2456, 286, 262, 4986, 3611, 286, 262, 1578, 7973, 10274, 21927, 12, 31640, 25, 366, 3633, 3034, 3349, 318, 3306, 11, 340, 318, 407, 6751, 329, 4371, 319, 8868, 8098, 526, 1867, 2476, 284, 50256, 198, 27, 91, 562, 10167, 91, 29, 198, 20887, 4040, 11, 20887, 4040, 11, 20887, 4040, 50256, 198]\n",
            "sample length: 1059\n",
            "token length:204\n",
            "Sample 3648 of the processed training set:\n",
            "\n",
            "<|system|>\n",
            "<|endoftext|>\n",
            "<|user|>\n",
            "Summarize the following CNN article: A New South Wales company has been forced to settle a tab of more than $10,000 with the ACCC, after it advertised '100 per cent Aussie' beer that was actually made in China. The Independent Liquor Group was hit with an infringement notice by the Australian Competition and Consumer Commission, and had to pay the fine of $10,200 after its green and gold clad beer was falsely advertised. Independent Liquor Group was fined for advertising this Chinese brewed beer as 'Aussie beer' 'Aussie Beer' labelling from March 2014 to August 2014 featured a map of Australia with '100 per cent owned' inside it, and the statement 'Australia's finest malt'. However, contrary to what its packaging suggested, the beer is made in China. The ACCC dished out the penalty in accordance with the Australian Consumer Law. 'Country of origin representations, particularly those designed to grab the<|endoftext|>\n",
            "<|assistant|>\n",
            "Independent Liquor Group fined $10,200 by the ACCC for false advertising .\n",
            "Beer claimed to be '100% Aussie' but is actually brewed in China .\n",
            "'Aussie Beer' with misleading labelling sold from March to August 2014 .\n",
            "Punishment handed out in line with the Australian Consumer Law .<|endoftext|>\n",
            "\n",
            "token: [27, 91, 10057, 91, 29, 198, 50256, 198, 27, 91, 7220, 91, 29, 198, 13065, 3876, 1096, 262, 1708, 8100, 2708, 25, 317, 968, 2520, 11769, 1664, 468, 587, 4137, 284, 12259, 257, 7400, 286, 517, 621, 720, 940, 11, 830, 351, 262, 15859, 34, 11, 706, 340, 23944, 705, 3064, 583, 1247, 317, 43480, 6, 6099, 326, 373, 1682, 925, 287, 2807, 13, 383, 13362, 35515, 273, 4912, 373, 2277, 351, 281, 23059, 4003, 416, 262, 6638, 27348, 290, 18110, 4513, 11, 290, 550, 284, 1414, 262, 3734, 286, 720, 940, 11, 2167, 706, 663, 4077, 290, 3869, 38186, 6099, 373, 24566, 23944, 13, 13362, 35515, 273, 4912, 373, 22643, 329, 8560, 428, 3999, 40163, 6099, 355, 705, 32, 43480, 6099, 6, 705, 32, 43480, 16971, 6, 2248, 9417, 422, 2805, 1946, 284, 2932, 1946, 8096, 257, 3975, 286, 4505, 351, 705, 3064, 583, 1247, 6898, 6, 2641, 340, 11, 290, 262, 2643, 705, 27429, 338, 18822, 26868, 4458, 2102, 11, 10388, 284, 644, 663, 16846, 5220, 11, 262, 6099, 318, 925, 287, 2807, 13, 383, 15859, 34, 595, 704, 503, 262, 7389, 287, 10213, 351, 262, 6638, 18110, 3854, 13, 705, 33921, 286, 8159, 24612, 11, 3573, 883, 3562, 284, 5552, 262, 50256, 198, 27, 91, 562, 10167, 91, 29, 198, 40566, 35515, 273, 4912, 22643, 720, 940, 11, 2167, 416, 262, 15859, 34, 329, 3991, 8560, 764, 198, 49802, 4752, 284, 307, 705, 3064, 4, 317, 43480, 6, 475, 318, 1682, 40163, 287, 2807, 764, 198, 6, 32, 43480, 16971, 6, 351, 15850]\n",
            "sample length: 1271\n",
            "token length:256\n"
          ]
        }
      ],
      "source": [
        "# what's in datasets now\n",
        "# datasets_train : [{'text':'abcd','tokens':[1,2,3]},{'text':'bcd','tokens':[2,3]},...]\n",
        "for index in random.sample(range(len(datasets_val)), 2):\n",
        "    print(f\"Sample {index} of the processed training set:\\n\\n{datasets_val[index]['text']}\")\n",
        "    print(f\"token: {datasets_val[index]['tokens']}\")\n",
        "    print(f\"sample length: {len(datasets_val[index]['text'])}\")\n",
        "    print(f\"token length:{len(datasets_val[index]['tokens'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQSXViFqfYRy"
      },
      "outputs": [],
      "source": [
        "# total_token_length = 0\n",
        "# sample_count = len(datasets_train)\n",
        "\n",
        "# # Calculate total token length across all samples\n",
        "# for data in tqdm(datasets_train):\n",
        "#     encoded_length = len(tokenizer.encode(data['text']))\n",
        "#     total_token_length += encoded_length\n",
        "\n",
        "# # Compute the average token length\n",
        "# average_token_length = total_token_length / sample_count\n",
        "\n",
        "# print(f\"Average token length: {average_token_length}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jg0MOKomarrU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5abd3b92-50ec-41ae-b5aa-afd1b96397e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrfc-IpwOrFY"
      },
      "outputs": [],
      "source": [
        "# save dataset\n",
        "\n",
        "def save_dataset(dataset, filename):\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(dataset, f)\n",
        "save_dataset(datasets_train, 'hw5/train.bin')\n",
        "save_dataset(datasets_val, 'hw5/val.bin')\n",
        "save_dataset(datasets_test, 'hw5/test.bin')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AghJe4bCQLUa"
      },
      "source": [
        "## Pytorch Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFzA_Ake41t5"
      },
      "source": [
        "For long texts, the current approach randomly selects segments of text that are equal to config.sequence_length. However, methods such as sliding windows could also be explored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTYPPcyx6OtP"
      },
      "outputs": [],
      "source": [
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, root_dir, split):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (str): Dataset root directory containing the data files.\n",
        "        \"\"\"\n",
        "        file_path = os.path.join(root_dir, \"train.bin\") if split == 'train' else os.path.join(root_dir, \"val.bin\")\n",
        "        with open(file_path, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        tokens = sample['tokens']\n",
        "        # if the number of tokens is more than the sequence_length, randomly choose a segment\n",
        "        # if len(tokens) > config.sequence_length + 1:\n",
        "        #     num_possible_starts = len(tokens) - config.sequence_length\n",
        "        #     start = random.randint(0, num_possible_starts - 1)\n",
        "        #     segment = tokens[start:start + self.sequence_length + 1]\n",
        "        # else:\n",
        "        #     segment = tokens\n",
        "\n",
        "        if len(tokens) < config.sequence_length + 1:\n",
        "            padded_tokens = np.pad(tokens, (0, config.sequence_length + 1 - len(tokens)), 'constant', constant_values=tokenizer.pad_token_id)\n",
        "        else:\n",
        "            padded_tokens = tokens[:config.sequence_length + 1]\n",
        "\n",
        "        xb = torch.tensor(padded_tokens[:-1], dtype=torch.int64)\n",
        "        yb = torch.tensor(padded_tokens[1:], dtype=torch.int64)\n",
        "        return xb, yb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQJEY7Ye_v9t",
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# class TestDataset(Dataset):\n",
        "#     def __init__(self, root_dir):\n",
        "#         \"\"\"\n",
        "#         Args:\n",
        "#             root_dir (str): Dataset root directory containing the data files.\n",
        "#         \"\"\"\n",
        "#         file_path = os.path.join(root_dir, \"test.bin\")\n",
        "#         with open(file_path, 'rb') as f:\n",
        "#             data = pickle.load(f)\n",
        "#         self.data = data\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         sample = self.data[idx]\n",
        "#         tokens = sample['tokens']\n",
        "#         # if len(tokens) > config.sequence_length + 1:\n",
        "#         #     num_possible_starts = len(tokens) - config.sequence_length\n",
        "#         #     start = random.randint(0, num_possible_starts - 1)\n",
        "#         #     segment = tokens[start:start + config.sequence_length + 1]\n",
        "#         # else:\n",
        "#         #     segment = tokens\n",
        "#         if len(tokens) < config.sequence_length + 1:\n",
        "#             padded_tokens = np.pad(tokens, (0, config.sequence_length + 1 - len(tokens)), 'constant', constant_values=tokenizer.pad_token_id)\n",
        "#         else:\n",
        "#             padded_tokens = tokens[:config.sequence_length + 1]\n",
        "\n",
        "#         xb = torch.tensor(padded_tokens[:-1], dtype=torch.int64)\n",
        "#         return xb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3HIbJmBQLUa"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8HvMPG8QLUa"
      },
      "outputs": [],
      "source": [
        "# train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=1)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zI90SEqFQLUb",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# for x, y in train_loader:\n",
        "#     print(x.shape, y.shape)\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5oYgzrkQLUb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "072ac4d3-e18d-453c-ebe0-5fd3a962e209"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# poor man's dataloader\\n# but actual motivation is - im too lazy to write and deal with pad tokens in above method to read data\\n# since there are documents which are less than sequence length and they mess up the batch\\n# this method is cleaner, i get to learn something new (np.memmap!) and it's fun!\\n\\ndata_dir = os.path.join('data', 'owt')\\n\\ndef get_batch(split):\\n    file_path = os.path.join(data_dir, 'val' if split == 'val.bin' else 'train.bin')\\n    # memmap allows to read huge .bin files without loading entire thing. magic?\\n    data = np.memmap(file_path, mode='r', dtype=np.uint16) # fp16?\\n    idx = torch.randint(len(data) - config.sequence_length, (config.batch_size, ))\\n    xb = torch.stack([torch.from_numpy(data[i:i+config.sequence_length].astype(np.int64)) for i in idx], dim=0)\\n    yb = torch.stack([torch.from_numpy(data[i+1:i+config.sequence_length+1].astype(np.int64)) for i in idx], dim=0)\\n    if device == 'cuda':\\n        # pin_memory is an optimization to reserve some space in cpu mem which is used for moving to gpu\\n        # reduces overhead -> increases perf\\n        # non_blocking = True is async data transfer\\n        xb, yb = xb.pin_memory().to(device, non_blocking=True), yb.pin_memory().to(device, non_blocking=True)\\n    return xb, yb\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "'''\n",
        "# poor man's dataloader\n",
        "# but actual motivation is - im too lazy to write and deal with pad tokens in above method to read data\n",
        "# since there are documents which are less than sequence length and they mess up the batch\n",
        "# this method is cleaner, i get to learn something new (np.memmap!) and it's fun!\n",
        "\n",
        "data_dir = os.path.join('data', 'owt')\n",
        "\n",
        "def get_batch(split):\n",
        "    file_path = os.path.join(data_dir, 'val' if split == 'val.bin' else 'train.bin')\n",
        "    # memmap allows to read huge .bin files without loading entire thing. magic?\n",
        "    data = np.memmap(file_path, mode='r', dtype=np.uint16) # fp16?\n",
        "    idx = torch.randint(len(data) - config.sequence_length, (config.batch_size, ))\n",
        "    xb = torch.stack([torch.from_numpy(data[i:i+config.sequence_length].astype(np.int64)) for i in idx], dim=0)\n",
        "    yb = torch.stack([torch.from_numpy(data[i+1:i+config.sequence_length+1].astype(np.int64)) for i in idx], dim=0)\n",
        "    if device == 'cuda':\n",
        "        # pin_memory is an optimization to reserve some space in cpu mem which is used for moving to gpu\n",
        "        # reduces overhead -> increases perf\n",
        "        # non_blocking = True is async data transfer\n",
        "        xb, yb = xb.pin_memory().to(device, non_blocking=True), yb.pin_memory().to(device, non_blocking=True)\n",
        "    return xb, yb\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXmyEb8b9PyQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfc5875b-41bc-4a6c-ee3c-2b867189097a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "\n",
        "DATA_DIR        = 'hw5'\n",
        "\n",
        "train_dataset   = TrainDataset(\n",
        "    root_dir    = DATA_DIR,\n",
        "    split   = \"train\"\n",
        ")\n",
        "\n",
        "val_dataset     = TrainDataset(\n",
        "    root_dir    = DATA_DIR,\n",
        "    split   = \"val\"\n",
        ")\n",
        "\n",
        "# test_dataset    = TestDataset(\n",
        "#     root_dir    = DATA_DIR\n",
        "# )\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbCG6BXFfYRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91efb73a-a076-4efb-e9fe-c22b7b7bf703"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([256]), torch.Size([256]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "xb, yb = train_dataset[0]\n",
        "xb.shape, yb.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1itLTzKtB7e-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61bbf0fc-ec82-49e3-e85c-2d5ef6fd99f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Size           :  8\n",
            "Train Batches        :  49079\n",
            "Val Batches          :  3458\n"
          ]
        }
      ],
      "source": [
        "train_loader    = torch.utils.data.DataLoader(\n",
        "    dataset     = train_dataset,\n",
        "    batch_size  = config.batch_size,\n",
        "    shuffle     = True,\n",
        "    num_workers = 2,\n",
        "    pin_memory  = True\n",
        ")\n",
        "\n",
        "val_loader      = torch.utils.data.DataLoader(\n",
        "    dataset     = val_dataset,\n",
        "    batch_size  = config.batch_size,\n",
        "    shuffle     = False,\n",
        "    num_workers = 1,\n",
        "    pin_memory  = True\n",
        ")\n",
        "\n",
        "# test_loader     = torch.utils.data.DataLoader(\n",
        "#     dataset     = test_dataset,\n",
        "#     batch_size  = config.batch_size,\n",
        "#     shuffle     = False,\n",
        "#     num_workers = 1,\n",
        "#     pin_memory  = True\n",
        "# )\n",
        "\n",
        "print(\"Batch Size           : \", config.batch_size)\n",
        "print(\"Train Batches        : \", train_loader.__len__())\n",
        "print(\"Val Batches          : \", val_loader.__len__())\n",
        "# print(\"Test Batches         : \", test_loader.__len__())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIYb0gtYFenJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6b6c7ce-c8ab-4325-b944-8fe66e6dcd4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking the Shapes of the Data --\n",
            "\n",
            "xb shape:\t\ttorch.Size([8, 256])\n",
            "yb shape:\t\ttorch.Size([8, 256])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "''' Sanity Check '''\n",
        "\n",
        "print(\"Checking the Shapes of the Data --\\n\")\n",
        "\n",
        "for batch in train_loader:\n",
        "    xb, yb = batch\n",
        "\n",
        "    print(f\"xb shape:\\t\\t{xb.shape}\")\n",
        "    print(f\"yb shape:\\t\\t{yb.shape}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mmd9hflKQjF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "7674187a-9cea-4f08-962a-109cd2e9a488"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndata_dir = '/content/hw5/'\\ndef get_batch(split):\\n    file_path = os.path.join(data_dir, 'val.bin' if split == 'val' else 'train.bin')\\n\\n\\n    with open(file_path, 'rb') as f:\\n        data = pickle.load(f)\\n\\n    xb = torch.empty((config.batch_size, config.sequence_length), dtype=torch.int64)\\n    yb = torch.empty((config.batch_size, config.sequence_length), dtype=torch.int64)\\n\\n    for b in range(config.batch_size):\\n        tokens = data[b]['tokens']\\n        if len(tokens) < config.sequence_length:\\n            padded_tokens = np.pad(tokens, (0, config.sequence_length - len(tokens)), 'constant', constant_values=tokenizer.pad_token_id)\\n        else:\\n            padded_tokens = tokens[:config.sequence_length]\\n\\n\\n        xb[b] = torch.tensor(padded_tokens[:-1], dtype=torch.int64)\\n        yb[b] = torch.tensor(padded_tokens[1:], dtype=torch.int64)\\n\\n    if device == 'cuda':\\n        xb, yb = xb.pin_memory().to(device, non_blocking=True), yb.pin_memory().to(device, non_blocking=True)\\n\\n    return xb, yb\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# I tried it, but failed.QAQ. It seems that using np.memmap requires synchronously recording the length of each data entry, which makes padding inconvenient.\n",
        "'''\n",
        "data_dir = '/content/hw5/'\n",
        "def get_batch(split):\n",
        "    file_path = os.path.join(data_dir, 'val.bin' if split == 'val' else 'train.bin')\n",
        "\n",
        "\n",
        "    with open(file_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    xb = torch.empty((config.batch_size, config.sequence_length), dtype=torch.int64)\n",
        "    yb = torch.empty((config.batch_size, config.sequence_length), dtype=torch.int64)\n",
        "\n",
        "    for b in range(config.batch_size):\n",
        "        tokens = data[b]['tokens']\n",
        "        if len(tokens) < config.sequence_length:\n",
        "            padded_tokens = np.pad(tokens, (0, config.sequence_length - len(tokens)), 'constant', constant_values=tokenizer.pad_token_id)\n",
        "        else:\n",
        "            padded_tokens = tokens[:config.sequence_length]\n",
        "\n",
        "\n",
        "        xb[b] = torch.tensor(padded_tokens[:-1], dtype=torch.int64)\n",
        "        yb[b] = torch.tensor(padded_tokens[1:], dtype=torch.int64)\n",
        "\n",
        "    if device == 'cuda':\n",
        "        xb, yb = xb.pin_memory().to(device, non_blocking=True), yb.pin_memory().to(device, non_blocking=True)\n",
        "\n",
        "    return xb, yb\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ3b6b23QLUb"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsZa23FJQLUb"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "    # def __init__(self, embed_dim, head_size, sequence_length, dropout):\n",
        "    def __init__(self, config, interim_head_size):\n",
        "        super().__init__()\n",
        "        self.embed_dim = config.embed_dim\n",
        "        self.interim_head_size = interim_head_size # say embed_dim = 32 -> broken into say 4 heads, so this will be 8, to be concated back to 32\n",
        "        self.key = nn.Linear(config.embed_dim, interim_head_size, bias=config.bias)\n",
        "        self.query = nn.Linear(config.embed_dim, interim_head_size, bias=config.bias)\n",
        "        self.value = nn.Linear(config.embed_dim, interim_head_size, bias=config.bias)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones((config.sequence_length, config.sequence_length))))\n",
        "\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x) # (b,t,c) -> (b,t,h)\n",
        "        q = self.query(x) # (b,t,c) -> (b,t,h)\n",
        "        v = self.value(x) # (b,t,c) -> (b,t,h)\n",
        "        wei = k @ q.transpose(-2, -1) * self.embed_dim**(-0.5) # (b,t,h) @ (b,h,t) -> (b,t,t)\n",
        "\n",
        "        wei = wei.masked_fill((self.tril[:T, :T] == 0.), -torch.inf) # type: ignore\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "\n",
        "        xbow = wei @ v # (b,t,t) @ (b,t,h) -> (b,t,h)\n",
        "        return xbow\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    # def __init__(self, num_heads, embed_dim, head_size, sequence_length, dropout):\n",
        "    def __init__(self, config, interim_head_size):\n",
        "        super().__init__()\n",
        "        self.head_list = nn.ModuleList([Head(config, interim_head_size) for _ in range(config.num_heads)])\n",
        "        self.proj = nn.Linear(config.embed_dim, config.embed_dim)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.head_list], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(config.embed_dim, 4*config.embed_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(4*config.embed_dim, config.embed_dim),\n",
        "            nn.Dropout(config.dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    # def __init__(self, num_heads, embed_dim, sequence_length, dropout):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.interim_head_size = config.embed_dim // config.num_heads\n",
        "        self.sa = MultiHeadAttention(config, self.interim_head_size)\n",
        "        self.ff = FeedForward(config)\n",
        "        self.ln1 = nn.LayerNorm(config.embed_dim)\n",
        "        self.ln2 = nn.LayerNorm(config.embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x)) # communication\n",
        "        x = x + self.ff(self.ln2(x)) # computation\n",
        "        return x\n",
        "\n",
        "\n",
        "class Transformer(torch.nn.Module):\n",
        "    # def __init__(self, embed_dim, vocab_size, sequence_length, num_heads, num_blocks, dropout):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.sequence_length = config.sequence_length\n",
        "        self.token_embeddings = torch.nn.Embedding(config.vocab_size, config.embed_dim)\n",
        "        self.position_embeddings = nn.Embedding(config.sequence_length, config.embed_dim)\n",
        "        self.block_list = nn.Sequential(*[Block(config)\n",
        "                                          for _ in range(config.num_blocks)])\n",
        "        self.final_ln = nn.LayerNorm(config.embed_dim)\n",
        "        self.lm_head = nn.Linear(config.embed_dim, config.vocab_size)\n",
        "\n",
        "    def forward(self, ixs, targets=None):\n",
        "        # ixs: (b,t)\n",
        "        # targets: (b,t)\n",
        "        B, T = ixs.shape\n",
        "        x = self.token_embeddings(ixs) # (b,t,c=embed_dim)\n",
        "        pos_embeds = self.position_embeddings(torch.arange(T, device=device)) # (t,c=embed_dim)\n",
        "        x += pos_embeds\n",
        "        x = self.block_list(x)\n",
        "        x = self.final_ln(x)\n",
        "        logits = self.lm_head(x) # (b,t,c=vocab_size)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            mask = (ixs != tokenizer.pad_token_id)  # (b,t), True where not a pad token\n",
        "            logits = logits.permute(0, 2, 1)  # (b,c,t)\n",
        "\n",
        "            # Use the mask to filter out loss on padding positions\n",
        "            # logits are now (b, c, t), targets are (b, t), mask is (b, t)\n",
        "            # Utilizing .masked_fill to turn pad positions to a very large negative value to ignore them in softmax\n",
        "            loss = F.cross_entropy(logits, targets, reduction='none')  # (b, t) get loss per token\n",
        "            loss = (loss * mask).sum() / mask.sum()  # average loss only over non-pad tokens\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, ixs, max_len):\n",
        "        \"\"\"\n",
        "        ixs: (b,t) - input sequence to start generating from\n",
        "        max_len: int - maximum length of the generated sequence\n",
        "        \"\"\"\n",
        "        b, t = ixs.shape\n",
        "        for _ in range(max_len):\n",
        "            # generation (b, ) next tokens in parallel\n",
        "            ixs_cond = ixs[:, -self.sequence_length:] # consider only the last sequence_length tokens\n",
        "            logits, loss = self.forward(ixs_cond) # logits=(b,t,c), loss is ignored\n",
        "            # get juse the final timestep\n",
        "            last_logits = logits[:, -1, :] # (b,c)\n",
        "            # normalize\n",
        "            last_probs = F.softmax(last_logits, dim=-1) # across c\n",
        "            next_tokens = torch.multinomial(last_probs, 1) # (b,c) -> (b)\n",
        "            ixs = torch.cat((ixs, next_tokens), dim=1) # across t so (b,t) -> (b, t+1)\n",
        "        return ixs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mlj4sY57QLUb"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uM9xrNVCQLUb"
      },
      "outputs": [],
      "source": [
        "# model = Transformer(embed_dim, vocab_size, sequence_length, num_heads, num_blocks, dropout).to(device)\n",
        "model = Transformer(config).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXZIOVpRQLUc",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a0189903-7e85-4b1b-c476-6928547c3a43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: The default value of numeric_only in DataFrame.sum is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  df_sum = df.sum()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================\n",
            "                                                 Kernel Shape  \\\n",
            "Layer                                                           \n",
            "0_token_embeddings                               [512, 50257]   \n",
            "1_position_embeddings                              [512, 256]   \n",
            "2_block_list.0.LayerNorm_ln1                            [512]   \n",
            "3_block_list.0.sa.head_list.0.Linear_key            [512, 64]   \n",
            "4_block_list.0.sa.head_list.0.Linear_query          [512, 64]   \n",
            "5_block_list.0.sa.head_list.0.Linear_value          [512, 64]   \n",
            "6_block_list.0.sa.head_list.0.Dropout_dropout               -   \n",
            "7_block_list.0.sa.head_list.1.Linear_key            [512, 64]   \n",
            "8_block_list.0.sa.head_list.1.Linear_query          [512, 64]   \n",
            "9_block_list.0.sa.head_list.1.Linear_value          [512, 64]   \n",
            "10_block_list.0.sa.head_list.1.Dropout_dropout              -   \n",
            "11_block_list.0.sa.head_list.2.Linear_key           [512, 64]   \n",
            "12_block_list.0.sa.head_list.2.Linear_query         [512, 64]   \n",
            "13_block_list.0.sa.head_list.2.Linear_value         [512, 64]   \n",
            "14_block_list.0.sa.head_list.2.Dropout_dropout              -   \n",
            "15_block_list.0.sa.head_list.3.Linear_key           [512, 64]   \n",
            "16_block_list.0.sa.head_list.3.Linear_query         [512, 64]   \n",
            "17_block_list.0.sa.head_list.3.Linear_value         [512, 64]   \n",
            "18_block_list.0.sa.head_list.3.Dropout_dropout              -   \n",
            "19_block_list.0.sa.head_list.4.Linear_key           [512, 64]   \n",
            "20_block_list.0.sa.head_list.4.Linear_query         [512, 64]   \n",
            "21_block_list.0.sa.head_list.4.Linear_value         [512, 64]   \n",
            "22_block_list.0.sa.head_list.4.Dropout_dropout              -   \n",
            "23_block_list.0.sa.head_list.5.Linear_key           [512, 64]   \n",
            "24_block_list.0.sa.head_list.5.Linear_query         [512, 64]   \n",
            "25_block_list.0.sa.head_list.5.Linear_value         [512, 64]   \n",
            "26_block_list.0.sa.head_list.5.Dropout_dropout              -   \n",
            "27_block_list.0.sa.head_list.6.Linear_key           [512, 64]   \n",
            "28_block_list.0.sa.head_list.6.Linear_query         [512, 64]   \n",
            "29_block_list.0.sa.head_list.6.Linear_value         [512, 64]   \n",
            "30_block_list.0.sa.head_list.6.Dropout_dropout              -   \n",
            "31_block_list.0.sa.head_list.7.Linear_key           [512, 64]   \n",
            "32_block_list.0.sa.head_list.7.Linear_query         [512, 64]   \n",
            "33_block_list.0.sa.head_list.7.Linear_value         [512, 64]   \n",
            "34_block_list.0.sa.head_list.7.Dropout_dropout              -   \n",
            "35_block_list.0.sa.Linear_proj                     [512, 512]   \n",
            "36_block_list.0.sa.Dropout_dropout                          -   \n",
            "37_block_list.0.LayerNorm_ln2                           [512]   \n",
            "38_block_list.0.ff.layers.Linear_0                [512, 2048]   \n",
            "39_block_list.0.ff.layers.GELU_1                            -   \n",
            "40_block_list.0.ff.layers.Linear_2                [2048, 512]   \n",
            "41_block_list.0.ff.layers.Dropout_3                         -   \n",
            "42_block_list.1.LayerNorm_ln1                           [512]   \n",
            "43_block_list.1.sa.head_list.0.Linear_key           [512, 64]   \n",
            "44_block_list.1.sa.head_list.0.Linear_query         [512, 64]   \n",
            "45_block_list.1.sa.head_list.0.Linear_value         [512, 64]   \n",
            "46_block_list.1.sa.head_list.0.Dropout_dropout              -   \n",
            "47_block_list.1.sa.head_list.1.Linear_key           [512, 64]   \n",
            "48_block_list.1.sa.head_list.1.Linear_query         [512, 64]   \n",
            "49_block_list.1.sa.head_list.1.Linear_value         [512, 64]   \n",
            "50_block_list.1.sa.head_list.1.Dropout_dropout              -   \n",
            "51_block_list.1.sa.head_list.2.Linear_key           [512, 64]   \n",
            "52_block_list.1.sa.head_list.2.Linear_query         [512, 64]   \n",
            "53_block_list.1.sa.head_list.2.Linear_value         [512, 64]   \n",
            "54_block_list.1.sa.head_list.2.Dropout_dropout              -   \n",
            "55_block_list.1.sa.head_list.3.Linear_key           [512, 64]   \n",
            "56_block_list.1.sa.head_list.3.Linear_query         [512, 64]   \n",
            "57_block_list.1.sa.head_list.3.Linear_value         [512, 64]   \n",
            "58_block_list.1.sa.head_list.3.Dropout_dropout              -   \n",
            "59_block_list.1.sa.head_list.4.Linear_key           [512, 64]   \n",
            "60_block_list.1.sa.head_list.4.Linear_query         [512, 64]   \n",
            "61_block_list.1.sa.head_list.4.Linear_value         [512, 64]   \n",
            "62_block_list.1.sa.head_list.4.Dropout_dropout              -   \n",
            "63_block_list.1.sa.head_list.5.Linear_key           [512, 64]   \n",
            "64_block_list.1.sa.head_list.5.Linear_query         [512, 64]   \n",
            "65_block_list.1.sa.head_list.5.Linear_value         [512, 64]   \n",
            "66_block_list.1.sa.head_list.5.Dropout_dropout              -   \n",
            "67_block_list.1.sa.head_list.6.Linear_key           [512, 64]   \n",
            "68_block_list.1.sa.head_list.6.Linear_query         [512, 64]   \n",
            "69_block_list.1.sa.head_list.6.Linear_value         [512, 64]   \n",
            "70_block_list.1.sa.head_list.6.Dropout_dropout              -   \n",
            "71_block_list.1.sa.head_list.7.Linear_key           [512, 64]   \n",
            "72_block_list.1.sa.head_list.7.Linear_query         [512, 64]   \n",
            "73_block_list.1.sa.head_list.7.Linear_value         [512, 64]   \n",
            "74_block_list.1.sa.head_list.7.Dropout_dropout              -   \n",
            "75_block_list.1.sa.Linear_proj                     [512, 512]   \n",
            "76_block_list.1.sa.Dropout_dropout                          -   \n",
            "77_block_list.1.LayerNorm_ln2                           [512]   \n",
            "78_block_list.1.ff.layers.Linear_0                [512, 2048]   \n",
            "79_block_list.1.ff.layers.GELU_1                            -   \n",
            "80_block_list.1.ff.layers.Linear_2                [2048, 512]   \n",
            "81_block_list.1.ff.layers.Dropout_3                         -   \n",
            "82_block_list.2.LayerNorm_ln1                           [512]   \n",
            "83_block_list.2.sa.head_list.0.Linear_key           [512, 64]   \n",
            "84_block_list.2.sa.head_list.0.Linear_query         [512, 64]   \n",
            "85_block_list.2.sa.head_list.0.Linear_value         [512, 64]   \n",
            "86_block_list.2.sa.head_list.0.Dropout_dropout              -   \n",
            "87_block_list.2.sa.head_list.1.Linear_key           [512, 64]   \n",
            "88_block_list.2.sa.head_list.1.Linear_query         [512, 64]   \n",
            "89_block_list.2.sa.head_list.1.Linear_value         [512, 64]   \n",
            "90_block_list.2.sa.head_list.1.Dropout_dropout              -   \n",
            "91_block_list.2.sa.head_list.2.Linear_key           [512, 64]   \n",
            "92_block_list.2.sa.head_list.2.Linear_query         [512, 64]   \n",
            "93_block_list.2.sa.head_list.2.Linear_value         [512, 64]   \n",
            "94_block_list.2.sa.head_list.2.Dropout_dropout              -   \n",
            "95_block_list.2.sa.head_list.3.Linear_key           [512, 64]   \n",
            "96_block_list.2.sa.head_list.3.Linear_query         [512, 64]   \n",
            "97_block_list.2.sa.head_list.3.Linear_value         [512, 64]   \n",
            "98_block_list.2.sa.head_list.3.Dropout_dropout              -   \n",
            "99_block_list.2.sa.head_list.4.Linear_key           [512, 64]   \n",
            "100_block_list.2.sa.head_list.4.Linear_query        [512, 64]   \n",
            "101_block_list.2.sa.head_list.4.Linear_value        [512, 64]   \n",
            "102_block_list.2.sa.head_list.4.Dropout_dropout             -   \n",
            "103_block_list.2.sa.head_list.5.Linear_key          [512, 64]   \n",
            "104_block_list.2.sa.head_list.5.Linear_query        [512, 64]   \n",
            "105_block_list.2.sa.head_list.5.Linear_value        [512, 64]   \n",
            "106_block_list.2.sa.head_list.5.Dropout_dropout             -   \n",
            "107_block_list.2.sa.head_list.6.Linear_key          [512, 64]   \n",
            "108_block_list.2.sa.head_list.6.Linear_query        [512, 64]   \n",
            "109_block_list.2.sa.head_list.6.Linear_value        [512, 64]   \n",
            "110_block_list.2.sa.head_list.6.Dropout_dropout             -   \n",
            "111_block_list.2.sa.head_list.7.Linear_key          [512, 64]   \n",
            "112_block_list.2.sa.head_list.7.Linear_query        [512, 64]   \n",
            "113_block_list.2.sa.head_list.7.Linear_value        [512, 64]   \n",
            "114_block_list.2.sa.head_list.7.Dropout_dropout             -   \n",
            "115_block_list.2.sa.Linear_proj                    [512, 512]   \n",
            "116_block_list.2.sa.Dropout_dropout                         -   \n",
            "117_block_list.2.LayerNorm_ln2                          [512]   \n",
            "118_block_list.2.ff.layers.Linear_0               [512, 2048]   \n",
            "119_block_list.2.ff.layers.GELU_1                           -   \n",
            "120_block_list.2.ff.layers.Linear_2               [2048, 512]   \n",
            "121_block_list.2.ff.layers.Dropout_3                        -   \n",
            "122_block_list.3.LayerNorm_ln1                          [512]   \n",
            "123_block_list.3.sa.head_list.0.Linear_key          [512, 64]   \n",
            "124_block_list.3.sa.head_list.0.Linear_query        [512, 64]   \n",
            "125_block_list.3.sa.head_list.0.Linear_value        [512, 64]   \n",
            "126_block_list.3.sa.head_list.0.Dropout_dropout             -   \n",
            "127_block_list.3.sa.head_list.1.Linear_key          [512, 64]   \n",
            "128_block_list.3.sa.head_list.1.Linear_query        [512, 64]   \n",
            "129_block_list.3.sa.head_list.1.Linear_value        [512, 64]   \n",
            "130_block_list.3.sa.head_list.1.Dropout_dropout             -   \n",
            "131_block_list.3.sa.head_list.2.Linear_key          [512, 64]   \n",
            "132_block_list.3.sa.head_list.2.Linear_query        [512, 64]   \n",
            "133_block_list.3.sa.head_list.2.Linear_value        [512, 64]   \n",
            "134_block_list.3.sa.head_list.2.Dropout_dropout             -   \n",
            "135_block_list.3.sa.head_list.3.Linear_key          [512, 64]   \n",
            "136_block_list.3.sa.head_list.3.Linear_query        [512, 64]   \n",
            "137_block_list.3.sa.head_list.3.Linear_value        [512, 64]   \n",
            "138_block_list.3.sa.head_list.3.Dropout_dropout             -   \n",
            "139_block_list.3.sa.head_list.4.Linear_key          [512, 64]   \n",
            "140_block_list.3.sa.head_list.4.Linear_query        [512, 64]   \n",
            "141_block_list.3.sa.head_list.4.Linear_value        [512, 64]   \n",
            "142_block_list.3.sa.head_list.4.Dropout_dropout             -   \n",
            "143_block_list.3.sa.head_list.5.Linear_key          [512, 64]   \n",
            "144_block_list.3.sa.head_list.5.Linear_query        [512, 64]   \n",
            "145_block_list.3.sa.head_list.5.Linear_value        [512, 64]   \n",
            "146_block_list.3.sa.head_list.5.Dropout_dropout             -   \n",
            "147_block_list.3.sa.head_list.6.Linear_key          [512, 64]   \n",
            "148_block_list.3.sa.head_list.6.Linear_query        [512, 64]   \n",
            "149_block_list.3.sa.head_list.6.Linear_value        [512, 64]   \n",
            "150_block_list.3.sa.head_list.6.Dropout_dropout             -   \n",
            "151_block_list.3.sa.head_list.7.Linear_key          [512, 64]   \n",
            "152_block_list.3.sa.head_list.7.Linear_query        [512, 64]   \n",
            "153_block_list.3.sa.head_list.7.Linear_value        [512, 64]   \n",
            "154_block_list.3.sa.head_list.7.Dropout_dropout             -   \n",
            "155_block_list.3.sa.Linear_proj                    [512, 512]   \n",
            "156_block_list.3.sa.Dropout_dropout                         -   \n",
            "157_block_list.3.LayerNorm_ln2                          [512]   \n",
            "158_block_list.3.ff.layers.Linear_0               [512, 2048]   \n",
            "159_block_list.3.ff.layers.GELU_1                           -   \n",
            "160_block_list.3.ff.layers.Linear_2               [2048, 512]   \n",
            "161_block_list.3.ff.layers.Dropout_3                        -   \n",
            "162_block_list.4.LayerNorm_ln1                          [512]   \n",
            "163_block_list.4.sa.head_list.0.Linear_key          [512, 64]   \n",
            "164_block_list.4.sa.head_list.0.Linear_query        [512, 64]   \n",
            "165_block_list.4.sa.head_list.0.Linear_value        [512, 64]   \n",
            "166_block_list.4.sa.head_list.0.Dropout_dropout             -   \n",
            "167_block_list.4.sa.head_list.1.Linear_key          [512, 64]   \n",
            "168_block_list.4.sa.head_list.1.Linear_query        [512, 64]   \n",
            "169_block_list.4.sa.head_list.1.Linear_value        [512, 64]   \n",
            "170_block_list.4.sa.head_list.1.Dropout_dropout             -   \n",
            "171_block_list.4.sa.head_list.2.Linear_key          [512, 64]   \n",
            "172_block_list.4.sa.head_list.2.Linear_query        [512, 64]   \n",
            "173_block_list.4.sa.head_list.2.Linear_value        [512, 64]   \n",
            "174_block_list.4.sa.head_list.2.Dropout_dropout             -   \n",
            "175_block_list.4.sa.head_list.3.Linear_key          [512, 64]   \n",
            "176_block_list.4.sa.head_list.3.Linear_query        [512, 64]   \n",
            "177_block_list.4.sa.head_list.3.Linear_value        [512, 64]   \n",
            "178_block_list.4.sa.head_list.3.Dropout_dropout             -   \n",
            "179_block_list.4.sa.head_list.4.Linear_key          [512, 64]   \n",
            "180_block_list.4.sa.head_list.4.Linear_query        [512, 64]   \n",
            "181_block_list.4.sa.head_list.4.Linear_value        [512, 64]   \n",
            "182_block_list.4.sa.head_list.4.Dropout_dropout             -   \n",
            "183_block_list.4.sa.head_list.5.Linear_key          [512, 64]   \n",
            "184_block_list.4.sa.head_list.5.Linear_query        [512, 64]   \n",
            "185_block_list.4.sa.head_list.5.Linear_value        [512, 64]   \n",
            "186_block_list.4.sa.head_list.5.Dropout_dropout             -   \n",
            "187_block_list.4.sa.head_list.6.Linear_key          [512, 64]   \n",
            "188_block_list.4.sa.head_list.6.Linear_query        [512, 64]   \n",
            "189_block_list.4.sa.head_list.6.Linear_value        [512, 64]   \n",
            "190_block_list.4.sa.head_list.6.Dropout_dropout             -   \n",
            "191_block_list.4.sa.head_list.7.Linear_key          [512, 64]   \n",
            "192_block_list.4.sa.head_list.7.Linear_query        [512, 64]   \n",
            "193_block_list.4.sa.head_list.7.Linear_value        [512, 64]   \n",
            "194_block_list.4.sa.head_list.7.Dropout_dropout             -   \n",
            "195_block_list.4.sa.Linear_proj                    [512, 512]   \n",
            "196_block_list.4.sa.Dropout_dropout                         -   \n",
            "197_block_list.4.LayerNorm_ln2                          [512]   \n",
            "198_block_list.4.ff.layers.Linear_0               [512, 2048]   \n",
            "199_block_list.4.ff.layers.GELU_1                           -   \n",
            "200_block_list.4.ff.layers.Linear_2               [2048, 512]   \n",
            "201_block_list.4.ff.layers.Dropout_3                        -   \n",
            "202_block_list.5.LayerNorm_ln1                          [512]   \n",
            "203_block_list.5.sa.head_list.0.Linear_key          [512, 64]   \n",
            "204_block_list.5.sa.head_list.0.Linear_query        [512, 64]   \n",
            "205_block_list.5.sa.head_list.0.Linear_value        [512, 64]   \n",
            "206_block_list.5.sa.head_list.0.Dropout_dropout             -   \n",
            "207_block_list.5.sa.head_list.1.Linear_key          [512, 64]   \n",
            "208_block_list.5.sa.head_list.1.Linear_query        [512, 64]   \n",
            "209_block_list.5.sa.head_list.1.Linear_value        [512, 64]   \n",
            "210_block_list.5.sa.head_list.1.Dropout_dropout             -   \n",
            "211_block_list.5.sa.head_list.2.Linear_key          [512, 64]   \n",
            "212_block_list.5.sa.head_list.2.Linear_query        [512, 64]   \n",
            "213_block_list.5.sa.head_list.2.Linear_value        [512, 64]   \n",
            "214_block_list.5.sa.head_list.2.Dropout_dropout             -   \n",
            "215_block_list.5.sa.head_list.3.Linear_key          [512, 64]   \n",
            "216_block_list.5.sa.head_list.3.Linear_query        [512, 64]   \n",
            "217_block_list.5.sa.head_list.3.Linear_value        [512, 64]   \n",
            "218_block_list.5.sa.head_list.3.Dropout_dropout             -   \n",
            "219_block_list.5.sa.head_list.4.Linear_key          [512, 64]   \n",
            "220_block_list.5.sa.head_list.4.Linear_query        [512, 64]   \n",
            "221_block_list.5.sa.head_list.4.Linear_value        [512, 64]   \n",
            "222_block_list.5.sa.head_list.4.Dropout_dropout             -   \n",
            "223_block_list.5.sa.head_list.5.Linear_key          [512, 64]   \n",
            "224_block_list.5.sa.head_list.5.Linear_query        [512, 64]   \n",
            "225_block_list.5.sa.head_list.5.Linear_value        [512, 64]   \n",
            "226_block_list.5.sa.head_list.5.Dropout_dropout             -   \n",
            "227_block_list.5.sa.head_list.6.Linear_key          [512, 64]   \n",
            "228_block_list.5.sa.head_list.6.Linear_query        [512, 64]   \n",
            "229_block_list.5.sa.head_list.6.Linear_value        [512, 64]   \n",
            "230_block_list.5.sa.head_list.6.Dropout_dropout             -   \n",
            "231_block_list.5.sa.head_list.7.Linear_key          [512, 64]   \n",
            "232_block_list.5.sa.head_list.7.Linear_query        [512, 64]   \n",
            "233_block_list.5.sa.head_list.7.Linear_value        [512, 64]   \n",
            "234_block_list.5.sa.head_list.7.Dropout_dropout             -   \n",
            "235_block_list.5.sa.Linear_proj                    [512, 512]   \n",
            "236_block_list.5.sa.Dropout_dropout                         -   \n",
            "237_block_list.5.LayerNorm_ln2                          [512]   \n",
            "238_block_list.5.ff.layers.Linear_0               [512, 2048]   \n",
            "239_block_list.5.ff.layers.GELU_1                           -   \n",
            "240_block_list.5.ff.layers.Linear_2               [2048, 512]   \n",
            "241_block_list.5.ff.layers.Dropout_3                        -   \n",
            "242_block_list.6.LayerNorm_ln1                          [512]   \n",
            "243_block_list.6.sa.head_list.0.Linear_key          [512, 64]   \n",
            "244_block_list.6.sa.head_list.0.Linear_query        [512, 64]   \n",
            "245_block_list.6.sa.head_list.0.Linear_value        [512, 64]   \n",
            "246_block_list.6.sa.head_list.0.Dropout_dropout             -   \n",
            "247_block_list.6.sa.head_list.1.Linear_key          [512, 64]   \n",
            "248_block_list.6.sa.head_list.1.Linear_query        [512, 64]   \n",
            "249_block_list.6.sa.head_list.1.Linear_value        [512, 64]   \n",
            "250_block_list.6.sa.head_list.1.Dropout_dropout             -   \n",
            "251_block_list.6.sa.head_list.2.Linear_key          [512, 64]   \n",
            "252_block_list.6.sa.head_list.2.Linear_query        [512, 64]   \n",
            "253_block_list.6.sa.head_list.2.Linear_value        [512, 64]   \n",
            "254_block_list.6.sa.head_list.2.Dropout_dropout             -   \n",
            "255_block_list.6.sa.head_list.3.Linear_key          [512, 64]   \n",
            "256_block_list.6.sa.head_list.3.Linear_query        [512, 64]   \n",
            "257_block_list.6.sa.head_list.3.Linear_value        [512, 64]   \n",
            "258_block_list.6.sa.head_list.3.Dropout_dropout             -   \n",
            "259_block_list.6.sa.head_list.4.Linear_key          [512, 64]   \n",
            "260_block_list.6.sa.head_list.4.Linear_query        [512, 64]   \n",
            "261_block_list.6.sa.head_list.4.Linear_value        [512, 64]   \n",
            "262_block_list.6.sa.head_list.4.Dropout_dropout             -   \n",
            "263_block_list.6.sa.head_list.5.Linear_key          [512, 64]   \n",
            "264_block_list.6.sa.head_list.5.Linear_query        [512, 64]   \n",
            "265_block_list.6.sa.head_list.5.Linear_value        [512, 64]   \n",
            "266_block_list.6.sa.head_list.5.Dropout_dropout             -   \n",
            "267_block_list.6.sa.head_list.6.Linear_key          [512, 64]   \n",
            "268_block_list.6.sa.head_list.6.Linear_query        [512, 64]   \n",
            "269_block_list.6.sa.head_list.6.Linear_value        [512, 64]   \n",
            "270_block_list.6.sa.head_list.6.Dropout_dropout             -   \n",
            "271_block_list.6.sa.head_list.7.Linear_key          [512, 64]   \n",
            "272_block_list.6.sa.head_list.7.Linear_query        [512, 64]   \n",
            "273_block_list.6.sa.head_list.7.Linear_value        [512, 64]   \n",
            "274_block_list.6.sa.head_list.7.Dropout_dropout             -   \n",
            "275_block_list.6.sa.Linear_proj                    [512, 512]   \n",
            "276_block_list.6.sa.Dropout_dropout                         -   \n",
            "277_block_list.6.LayerNorm_ln2                          [512]   \n",
            "278_block_list.6.ff.layers.Linear_0               [512, 2048]   \n",
            "279_block_list.6.ff.layers.GELU_1                           -   \n",
            "280_block_list.6.ff.layers.Linear_2               [2048, 512]   \n",
            "281_block_list.6.ff.layers.Dropout_3                        -   \n",
            "282_block_list.7.LayerNorm_ln1                          [512]   \n",
            "283_block_list.7.sa.head_list.0.Linear_key          [512, 64]   \n",
            "284_block_list.7.sa.head_list.0.Linear_query        [512, 64]   \n",
            "285_block_list.7.sa.head_list.0.Linear_value        [512, 64]   \n",
            "286_block_list.7.sa.head_list.0.Dropout_dropout             -   \n",
            "287_block_list.7.sa.head_list.1.Linear_key          [512, 64]   \n",
            "288_block_list.7.sa.head_list.1.Linear_query        [512, 64]   \n",
            "289_block_list.7.sa.head_list.1.Linear_value        [512, 64]   \n",
            "290_block_list.7.sa.head_list.1.Dropout_dropout             -   \n",
            "291_block_list.7.sa.head_list.2.Linear_key          [512, 64]   \n",
            "292_block_list.7.sa.head_list.2.Linear_query        [512, 64]   \n",
            "293_block_list.7.sa.head_list.2.Linear_value        [512, 64]   \n",
            "294_block_list.7.sa.head_list.2.Dropout_dropout             -   \n",
            "295_block_list.7.sa.head_list.3.Linear_key          [512, 64]   \n",
            "296_block_list.7.sa.head_list.3.Linear_query        [512, 64]   \n",
            "297_block_list.7.sa.head_list.3.Linear_value        [512, 64]   \n",
            "298_block_list.7.sa.head_list.3.Dropout_dropout             -   \n",
            "299_block_list.7.sa.head_list.4.Linear_key          [512, 64]   \n",
            "300_block_list.7.sa.head_list.4.Linear_query        [512, 64]   \n",
            "301_block_list.7.sa.head_list.4.Linear_value        [512, 64]   \n",
            "302_block_list.7.sa.head_list.4.Dropout_dropout             -   \n",
            "303_block_list.7.sa.head_list.5.Linear_key          [512, 64]   \n",
            "304_block_list.7.sa.head_list.5.Linear_query        [512, 64]   \n",
            "305_block_list.7.sa.head_list.5.Linear_value        [512, 64]   \n",
            "306_block_list.7.sa.head_list.5.Dropout_dropout             -   \n",
            "307_block_list.7.sa.head_list.6.Linear_key          [512, 64]   \n",
            "308_block_list.7.sa.head_list.6.Linear_query        [512, 64]   \n",
            "309_block_list.7.sa.head_list.6.Linear_value        [512, 64]   \n",
            "310_block_list.7.sa.head_list.6.Dropout_dropout             -   \n",
            "311_block_list.7.sa.head_list.7.Linear_key          [512, 64]   \n",
            "312_block_list.7.sa.head_list.7.Linear_query        [512, 64]   \n",
            "313_block_list.7.sa.head_list.7.Linear_value        [512, 64]   \n",
            "314_block_list.7.sa.head_list.7.Dropout_dropout             -   \n",
            "315_block_list.7.sa.Linear_proj                    [512, 512]   \n",
            "316_block_list.7.sa.Dropout_dropout                         -   \n",
            "317_block_list.7.LayerNorm_ln2                          [512]   \n",
            "318_block_list.7.ff.layers.Linear_0               [512, 2048]   \n",
            "319_block_list.7.ff.layers.GELU_1                           -   \n",
            "320_block_list.7.ff.layers.Linear_2               [2048, 512]   \n",
            "321_block_list.7.ff.layers.Dropout_3                        -   \n",
            "322_final_ln                                            [512]   \n",
            "323_lm_head                                      [512, 50257]   \n",
            "\n",
            "                                                    Output Shape      Params  \\\n",
            "Layer                                                                          \n",
            "0_token_embeddings                                 [8, 256, 512]  25.731584M   \n",
            "1_position_embeddings                                 [256, 512]    131.072k   \n",
            "2_block_list.0.LayerNorm_ln1                       [8, 256, 512]      1.024k   \n",
            "3_block_list.0.sa.head_list.0.Linear_key            [8, 256, 64]     32.768k   \n",
            "4_block_list.0.sa.head_list.0.Linear_query          [8, 256, 64]     32.768k   \n",
            "5_block_list.0.sa.head_list.0.Linear_value          [8, 256, 64]     32.768k   \n",
            "6_block_list.0.sa.head_list.0.Dropout_dropout      [8, 256, 256]           -   \n",
            "7_block_list.0.sa.head_list.1.Linear_key            [8, 256, 64]     32.768k   \n",
            "8_block_list.0.sa.head_list.1.Linear_query          [8, 256, 64]     32.768k   \n",
            "9_block_list.0.sa.head_list.1.Linear_value          [8, 256, 64]     32.768k   \n",
            "10_block_list.0.sa.head_list.1.Dropout_dropout     [8, 256, 256]           -   \n",
            "11_block_list.0.sa.head_list.2.Linear_key           [8, 256, 64]     32.768k   \n",
            "12_block_list.0.sa.head_list.2.Linear_query         [8, 256, 64]     32.768k   \n",
            "13_block_list.0.sa.head_list.2.Linear_value         [8, 256, 64]     32.768k   \n",
            "14_block_list.0.sa.head_list.2.Dropout_dropout     [8, 256, 256]           -   \n",
            "15_block_list.0.sa.head_list.3.Linear_key           [8, 256, 64]     32.768k   \n",
            "16_block_list.0.sa.head_list.3.Linear_query         [8, 256, 64]     32.768k   \n",
            "17_block_list.0.sa.head_list.3.Linear_value         [8, 256, 64]     32.768k   \n",
            "18_block_list.0.sa.head_list.3.Dropout_dropout     [8, 256, 256]           -   \n",
            "19_block_list.0.sa.head_list.4.Linear_key           [8, 256, 64]     32.768k   \n",
            "20_block_list.0.sa.head_list.4.Linear_query         [8, 256, 64]     32.768k   \n",
            "21_block_list.0.sa.head_list.4.Linear_value         [8, 256, 64]     32.768k   \n",
            "22_block_list.0.sa.head_list.4.Dropout_dropout     [8, 256, 256]           -   \n",
            "23_block_list.0.sa.head_list.5.Linear_key           [8, 256, 64]     32.768k   \n",
            "24_block_list.0.sa.head_list.5.Linear_query         [8, 256, 64]     32.768k   \n",
            "25_block_list.0.sa.head_list.5.Linear_value         [8, 256, 64]     32.768k   \n",
            "26_block_list.0.sa.head_list.5.Dropout_dropout     [8, 256, 256]           -   \n",
            "27_block_list.0.sa.head_list.6.Linear_key           [8, 256, 64]     32.768k   \n",
            "28_block_list.0.sa.head_list.6.Linear_query         [8, 256, 64]     32.768k   \n",
            "29_block_list.0.sa.head_list.6.Linear_value         [8, 256, 64]     32.768k   \n",
            "30_block_list.0.sa.head_list.6.Dropout_dropout     [8, 256, 256]           -   \n",
            "31_block_list.0.sa.head_list.7.Linear_key           [8, 256, 64]     32.768k   \n",
            "32_block_list.0.sa.head_list.7.Linear_query         [8, 256, 64]     32.768k   \n",
            "33_block_list.0.sa.head_list.7.Linear_value         [8, 256, 64]     32.768k   \n",
            "34_block_list.0.sa.head_list.7.Dropout_dropout     [8, 256, 256]           -   \n",
            "35_block_list.0.sa.Linear_proj                     [8, 256, 512]    262.656k   \n",
            "36_block_list.0.sa.Dropout_dropout                 [8, 256, 512]           -   \n",
            "37_block_list.0.LayerNorm_ln2                      [8, 256, 512]      1.024k   \n",
            "38_block_list.0.ff.layers.Linear_0                [8, 256, 2048]   1.050624M   \n",
            "39_block_list.0.ff.layers.GELU_1                  [8, 256, 2048]           -   \n",
            "40_block_list.0.ff.layers.Linear_2                 [8, 256, 512]   1.049088M   \n",
            "41_block_list.0.ff.layers.Dropout_3                [8, 256, 512]           -   \n",
            "42_block_list.1.LayerNorm_ln1                      [8, 256, 512]      1.024k   \n",
            "43_block_list.1.sa.head_list.0.Linear_key           [8, 256, 64]     32.768k   \n",
            "44_block_list.1.sa.head_list.0.Linear_query         [8, 256, 64]     32.768k   \n",
            "45_block_list.1.sa.head_list.0.Linear_value         [8, 256, 64]     32.768k   \n",
            "46_block_list.1.sa.head_list.0.Dropout_dropout     [8, 256, 256]           -   \n",
            "47_block_list.1.sa.head_list.1.Linear_key           [8, 256, 64]     32.768k   \n",
            "48_block_list.1.sa.head_list.1.Linear_query         [8, 256, 64]     32.768k   \n",
            "49_block_list.1.sa.head_list.1.Linear_value         [8, 256, 64]     32.768k   \n",
            "50_block_list.1.sa.head_list.1.Dropout_dropout     [8, 256, 256]           -   \n",
            "51_block_list.1.sa.head_list.2.Linear_key           [8, 256, 64]     32.768k   \n",
            "52_block_list.1.sa.head_list.2.Linear_query         [8, 256, 64]     32.768k   \n",
            "53_block_list.1.sa.head_list.2.Linear_value         [8, 256, 64]     32.768k   \n",
            "54_block_list.1.sa.head_list.2.Dropout_dropout     [8, 256, 256]           -   \n",
            "55_block_list.1.sa.head_list.3.Linear_key           [8, 256, 64]     32.768k   \n",
            "56_block_list.1.sa.head_list.3.Linear_query         [8, 256, 64]     32.768k   \n",
            "57_block_list.1.sa.head_list.3.Linear_value         [8, 256, 64]     32.768k   \n",
            "58_block_list.1.sa.head_list.3.Dropout_dropout     [8, 256, 256]           -   \n",
            "59_block_list.1.sa.head_list.4.Linear_key           [8, 256, 64]     32.768k   \n",
            "60_block_list.1.sa.head_list.4.Linear_query         [8, 256, 64]     32.768k   \n",
            "61_block_list.1.sa.head_list.4.Linear_value         [8, 256, 64]     32.768k   \n",
            "62_block_list.1.sa.head_list.4.Dropout_dropout     [8, 256, 256]           -   \n",
            "63_block_list.1.sa.head_list.5.Linear_key           [8, 256, 64]     32.768k   \n",
            "64_block_list.1.sa.head_list.5.Linear_query         [8, 256, 64]     32.768k   \n",
            "65_block_list.1.sa.head_list.5.Linear_value         [8, 256, 64]     32.768k   \n",
            "66_block_list.1.sa.head_list.5.Dropout_dropout     [8, 256, 256]           -   \n",
            "67_block_list.1.sa.head_list.6.Linear_key           [8, 256, 64]     32.768k   \n",
            "68_block_list.1.sa.head_list.6.Linear_query         [8, 256, 64]     32.768k   \n",
            "69_block_list.1.sa.head_list.6.Linear_value         [8, 256, 64]     32.768k   \n",
            "70_block_list.1.sa.head_list.6.Dropout_dropout     [8, 256, 256]           -   \n",
            "71_block_list.1.sa.head_list.7.Linear_key           [8, 256, 64]     32.768k   \n",
            "72_block_list.1.sa.head_list.7.Linear_query         [8, 256, 64]     32.768k   \n",
            "73_block_list.1.sa.head_list.7.Linear_value         [8, 256, 64]     32.768k   \n",
            "74_block_list.1.sa.head_list.7.Dropout_dropout     [8, 256, 256]           -   \n",
            "75_block_list.1.sa.Linear_proj                     [8, 256, 512]    262.656k   \n",
            "76_block_list.1.sa.Dropout_dropout                 [8, 256, 512]           -   \n",
            "77_block_list.1.LayerNorm_ln2                      [8, 256, 512]      1.024k   \n",
            "78_block_list.1.ff.layers.Linear_0                [8, 256, 2048]   1.050624M   \n",
            "79_block_list.1.ff.layers.GELU_1                  [8, 256, 2048]           -   \n",
            "80_block_list.1.ff.layers.Linear_2                 [8, 256, 512]   1.049088M   \n",
            "81_block_list.1.ff.layers.Dropout_3                [8, 256, 512]           -   \n",
            "82_block_list.2.LayerNorm_ln1                      [8, 256, 512]      1.024k   \n",
            "83_block_list.2.sa.head_list.0.Linear_key           [8, 256, 64]     32.768k   \n",
            "84_block_list.2.sa.head_list.0.Linear_query         [8, 256, 64]     32.768k   \n",
            "85_block_list.2.sa.head_list.0.Linear_value         [8, 256, 64]     32.768k   \n",
            "86_block_list.2.sa.head_list.0.Dropout_dropout     [8, 256, 256]           -   \n",
            "87_block_list.2.sa.head_list.1.Linear_key           [8, 256, 64]     32.768k   \n",
            "88_block_list.2.sa.head_list.1.Linear_query         [8, 256, 64]     32.768k   \n",
            "89_block_list.2.sa.head_list.1.Linear_value         [8, 256, 64]     32.768k   \n",
            "90_block_list.2.sa.head_list.1.Dropout_dropout     [8, 256, 256]           -   \n",
            "91_block_list.2.sa.head_list.2.Linear_key           [8, 256, 64]     32.768k   \n",
            "92_block_list.2.sa.head_list.2.Linear_query         [8, 256, 64]     32.768k   \n",
            "93_block_list.2.sa.head_list.2.Linear_value         [8, 256, 64]     32.768k   \n",
            "94_block_list.2.sa.head_list.2.Dropout_dropout     [8, 256, 256]           -   \n",
            "95_block_list.2.sa.head_list.3.Linear_key           [8, 256, 64]     32.768k   \n",
            "96_block_list.2.sa.head_list.3.Linear_query         [8, 256, 64]     32.768k   \n",
            "97_block_list.2.sa.head_list.3.Linear_value         [8, 256, 64]     32.768k   \n",
            "98_block_list.2.sa.head_list.3.Dropout_dropout     [8, 256, 256]           -   \n",
            "99_block_list.2.sa.head_list.4.Linear_key           [8, 256, 64]     32.768k   \n",
            "100_block_list.2.sa.head_list.4.Linear_query        [8, 256, 64]     32.768k   \n",
            "101_block_list.2.sa.head_list.4.Linear_value        [8, 256, 64]     32.768k   \n",
            "102_block_list.2.sa.head_list.4.Dropout_dropout    [8, 256, 256]           -   \n",
            "103_block_list.2.sa.head_list.5.Linear_key          [8, 256, 64]     32.768k   \n",
            "104_block_list.2.sa.head_list.5.Linear_query        [8, 256, 64]     32.768k   \n",
            "105_block_list.2.sa.head_list.5.Linear_value        [8, 256, 64]     32.768k   \n",
            "106_block_list.2.sa.head_list.5.Dropout_dropout    [8, 256, 256]           -   \n",
            "107_block_list.2.sa.head_list.6.Linear_key          [8, 256, 64]     32.768k   \n",
            "108_block_list.2.sa.head_list.6.Linear_query        [8, 256, 64]     32.768k   \n",
            "109_block_list.2.sa.head_list.6.Linear_value        [8, 256, 64]     32.768k   \n",
            "110_block_list.2.sa.head_list.6.Dropout_dropout    [8, 256, 256]           -   \n",
            "111_block_list.2.sa.head_list.7.Linear_key          [8, 256, 64]     32.768k   \n",
            "112_block_list.2.sa.head_list.7.Linear_query        [8, 256, 64]     32.768k   \n",
            "113_block_list.2.sa.head_list.7.Linear_value        [8, 256, 64]     32.768k   \n",
            "114_block_list.2.sa.head_list.7.Dropout_dropout    [8, 256, 256]           -   \n",
            "115_block_list.2.sa.Linear_proj                    [8, 256, 512]    262.656k   \n",
            "116_block_list.2.sa.Dropout_dropout                [8, 256, 512]           -   \n",
            "117_block_list.2.LayerNorm_ln2                     [8, 256, 512]      1.024k   \n",
            "118_block_list.2.ff.layers.Linear_0               [8, 256, 2048]   1.050624M   \n",
            "119_block_list.2.ff.layers.GELU_1                 [8, 256, 2048]           -   \n",
            "120_block_list.2.ff.layers.Linear_2                [8, 256, 512]   1.049088M   \n",
            "121_block_list.2.ff.layers.Dropout_3               [8, 256, 512]           -   \n",
            "122_block_list.3.LayerNorm_ln1                     [8, 256, 512]      1.024k   \n",
            "123_block_list.3.sa.head_list.0.Linear_key          [8, 256, 64]     32.768k   \n",
            "124_block_list.3.sa.head_list.0.Linear_query        [8, 256, 64]     32.768k   \n",
            "125_block_list.3.sa.head_list.0.Linear_value        [8, 256, 64]     32.768k   \n",
            "126_block_list.3.sa.head_list.0.Dropout_dropout    [8, 256, 256]           -   \n",
            "127_block_list.3.sa.head_list.1.Linear_key          [8, 256, 64]     32.768k   \n",
            "128_block_list.3.sa.head_list.1.Linear_query        [8, 256, 64]     32.768k   \n",
            "129_block_list.3.sa.head_list.1.Linear_value        [8, 256, 64]     32.768k   \n",
            "130_block_list.3.sa.head_list.1.Dropout_dropout    [8, 256, 256]           -   \n",
            "131_block_list.3.sa.head_list.2.Linear_key          [8, 256, 64]     32.768k   \n",
            "132_block_list.3.sa.head_list.2.Linear_query        [8, 256, 64]     32.768k   \n",
            "133_block_list.3.sa.head_list.2.Linear_value        [8, 256, 64]     32.768k   \n",
            "134_block_list.3.sa.head_list.2.Dropout_dropout    [8, 256, 256]           -   \n",
            "135_block_list.3.sa.head_list.3.Linear_key          [8, 256, 64]     32.768k   \n",
            "136_block_list.3.sa.head_list.3.Linear_query        [8, 256, 64]     32.768k   \n",
            "137_block_list.3.sa.head_list.3.Linear_value        [8, 256, 64]     32.768k   \n",
            "138_block_list.3.sa.head_list.3.Dropout_dropout    [8, 256, 256]           -   \n",
            "139_block_list.3.sa.head_list.4.Linear_key          [8, 256, 64]     32.768k   \n",
            "140_block_list.3.sa.head_list.4.Linear_query        [8, 256, 64]     32.768k   \n",
            "141_block_list.3.sa.head_list.4.Linear_value        [8, 256, 64]     32.768k   \n",
            "142_block_list.3.sa.head_list.4.Dropout_dropout    [8, 256, 256]           -   \n",
            "143_block_list.3.sa.head_list.5.Linear_key          [8, 256, 64]     32.768k   \n",
            "144_block_list.3.sa.head_list.5.Linear_query        [8, 256, 64]     32.768k   \n",
            "145_block_list.3.sa.head_list.5.Linear_value        [8, 256, 64]     32.768k   \n",
            "146_block_list.3.sa.head_list.5.Dropout_dropout    [8, 256, 256]           -   \n",
            "147_block_list.3.sa.head_list.6.Linear_key          [8, 256, 64]     32.768k   \n",
            "148_block_list.3.sa.head_list.6.Linear_query        [8, 256, 64]     32.768k   \n",
            "149_block_list.3.sa.head_list.6.Linear_value        [8, 256, 64]     32.768k   \n",
            "150_block_list.3.sa.head_list.6.Dropout_dropout    [8, 256, 256]           -   \n",
            "151_block_list.3.sa.head_list.7.Linear_key          [8, 256, 64]     32.768k   \n",
            "152_block_list.3.sa.head_list.7.Linear_query        [8, 256, 64]     32.768k   \n",
            "153_block_list.3.sa.head_list.7.Linear_value        [8, 256, 64]     32.768k   \n",
            "154_block_list.3.sa.head_list.7.Dropout_dropout    [8, 256, 256]           -   \n",
            "155_block_list.3.sa.Linear_proj                    [8, 256, 512]    262.656k   \n",
            "156_block_list.3.sa.Dropout_dropout                [8, 256, 512]           -   \n",
            "157_block_list.3.LayerNorm_ln2                     [8, 256, 512]      1.024k   \n",
            "158_block_list.3.ff.layers.Linear_0               [8, 256, 2048]   1.050624M   \n",
            "159_block_list.3.ff.layers.GELU_1                 [8, 256, 2048]           -   \n",
            "160_block_list.3.ff.layers.Linear_2                [8, 256, 512]   1.049088M   \n",
            "161_block_list.3.ff.layers.Dropout_3               [8, 256, 512]           -   \n",
            "162_block_list.4.LayerNorm_ln1                     [8, 256, 512]      1.024k   \n",
            "163_block_list.4.sa.head_list.0.Linear_key          [8, 256, 64]     32.768k   \n",
            "164_block_list.4.sa.head_list.0.Linear_query        [8, 256, 64]     32.768k   \n",
            "165_block_list.4.sa.head_list.0.Linear_value        [8, 256, 64]     32.768k   \n",
            "166_block_list.4.sa.head_list.0.Dropout_dropout    [8, 256, 256]           -   \n",
            "167_block_list.4.sa.head_list.1.Linear_key          [8, 256, 64]     32.768k   \n",
            "168_block_list.4.sa.head_list.1.Linear_query        [8, 256, 64]     32.768k   \n",
            "169_block_list.4.sa.head_list.1.Linear_value        [8, 256, 64]     32.768k   \n",
            "170_block_list.4.sa.head_list.1.Dropout_dropout    [8, 256, 256]           -   \n",
            "171_block_list.4.sa.head_list.2.Linear_key          [8, 256, 64]     32.768k   \n",
            "172_block_list.4.sa.head_list.2.Linear_query        [8, 256, 64]     32.768k   \n",
            "173_block_list.4.sa.head_list.2.Linear_value        [8, 256, 64]     32.768k   \n",
            "174_block_list.4.sa.head_list.2.Dropout_dropout    [8, 256, 256]           -   \n",
            "175_block_list.4.sa.head_list.3.Linear_key          [8, 256, 64]     32.768k   \n",
            "176_block_list.4.sa.head_list.3.Linear_query        [8, 256, 64]     32.768k   \n",
            "177_block_list.4.sa.head_list.3.Linear_value        [8, 256, 64]     32.768k   \n",
            "178_block_list.4.sa.head_list.3.Dropout_dropout    [8, 256, 256]           -   \n",
            "179_block_list.4.sa.head_list.4.Linear_key          [8, 256, 64]     32.768k   \n",
            "180_block_list.4.sa.head_list.4.Linear_query        [8, 256, 64]     32.768k   \n",
            "181_block_list.4.sa.head_list.4.Linear_value        [8, 256, 64]     32.768k   \n",
            "182_block_list.4.sa.head_list.4.Dropout_dropout    [8, 256, 256]           -   \n",
            "183_block_list.4.sa.head_list.5.Linear_key          [8, 256, 64]     32.768k   \n",
            "184_block_list.4.sa.head_list.5.Linear_query        [8, 256, 64]     32.768k   \n",
            "185_block_list.4.sa.head_list.5.Linear_value        [8, 256, 64]     32.768k   \n",
            "186_block_list.4.sa.head_list.5.Dropout_dropout    [8, 256, 256]           -   \n",
            "187_block_list.4.sa.head_list.6.Linear_key          [8, 256, 64]     32.768k   \n",
            "188_block_list.4.sa.head_list.6.Linear_query        [8, 256, 64]     32.768k   \n",
            "189_block_list.4.sa.head_list.6.Linear_value        [8, 256, 64]     32.768k   \n",
            "190_block_list.4.sa.head_list.6.Dropout_dropout    [8, 256, 256]           -   \n",
            "191_block_list.4.sa.head_list.7.Linear_key          [8, 256, 64]     32.768k   \n",
            "192_block_list.4.sa.head_list.7.Linear_query        [8, 256, 64]     32.768k   \n",
            "193_block_list.4.sa.head_list.7.Linear_value        [8, 256, 64]     32.768k   \n",
            "194_block_list.4.sa.head_list.7.Dropout_dropout    [8, 256, 256]           -   \n",
            "195_block_list.4.sa.Linear_proj                    [8, 256, 512]    262.656k   \n",
            "196_block_list.4.sa.Dropout_dropout                [8, 256, 512]           -   \n",
            "197_block_list.4.LayerNorm_ln2                     [8, 256, 512]      1.024k   \n",
            "198_block_list.4.ff.layers.Linear_0               [8, 256, 2048]   1.050624M   \n",
            "199_block_list.4.ff.layers.GELU_1                 [8, 256, 2048]           -   \n",
            "200_block_list.4.ff.layers.Linear_2                [8, 256, 512]   1.049088M   \n",
            "201_block_list.4.ff.layers.Dropout_3               [8, 256, 512]           -   \n",
            "202_block_list.5.LayerNorm_ln1                     [8, 256, 512]      1.024k   \n",
            "203_block_list.5.sa.head_list.0.Linear_key          [8, 256, 64]     32.768k   \n",
            "204_block_list.5.sa.head_list.0.Linear_query        [8, 256, 64]     32.768k   \n",
            "205_block_list.5.sa.head_list.0.Linear_value        [8, 256, 64]     32.768k   \n",
            "206_block_list.5.sa.head_list.0.Dropout_dropout    [8, 256, 256]           -   \n",
            "207_block_list.5.sa.head_list.1.Linear_key          [8, 256, 64]     32.768k   \n",
            "208_block_list.5.sa.head_list.1.Linear_query        [8, 256, 64]     32.768k   \n",
            "209_block_list.5.sa.head_list.1.Linear_value        [8, 256, 64]     32.768k   \n",
            "210_block_list.5.sa.head_list.1.Dropout_dropout    [8, 256, 256]           -   \n",
            "211_block_list.5.sa.head_list.2.Linear_key          [8, 256, 64]     32.768k   \n",
            "212_block_list.5.sa.head_list.2.Linear_query        [8, 256, 64]     32.768k   \n",
            "213_block_list.5.sa.head_list.2.Linear_value        [8, 256, 64]     32.768k   \n",
            "214_block_list.5.sa.head_list.2.Dropout_dropout    [8, 256, 256]           -   \n",
            "215_block_list.5.sa.head_list.3.Linear_key          [8, 256, 64]     32.768k   \n",
            "216_block_list.5.sa.head_list.3.Linear_query        [8, 256, 64]     32.768k   \n",
            "217_block_list.5.sa.head_list.3.Linear_value        [8, 256, 64]     32.768k   \n",
            "218_block_list.5.sa.head_list.3.Dropout_dropout    [8, 256, 256]           -   \n",
            "219_block_list.5.sa.head_list.4.Linear_key          [8, 256, 64]     32.768k   \n",
            "220_block_list.5.sa.head_list.4.Linear_query        [8, 256, 64]     32.768k   \n",
            "221_block_list.5.sa.head_list.4.Linear_value        [8, 256, 64]     32.768k   \n",
            "222_block_list.5.sa.head_list.4.Dropout_dropout    [8, 256, 256]           -   \n",
            "223_block_list.5.sa.head_list.5.Linear_key          [8, 256, 64]     32.768k   \n",
            "224_block_list.5.sa.head_list.5.Linear_query        [8, 256, 64]     32.768k   \n",
            "225_block_list.5.sa.head_list.5.Linear_value        [8, 256, 64]     32.768k   \n",
            "226_block_list.5.sa.head_list.5.Dropout_dropout    [8, 256, 256]           -   \n",
            "227_block_list.5.sa.head_list.6.Linear_key          [8, 256, 64]     32.768k   \n",
            "228_block_list.5.sa.head_list.6.Linear_query        [8, 256, 64]     32.768k   \n",
            "229_block_list.5.sa.head_list.6.Linear_value        [8, 256, 64]     32.768k   \n",
            "230_block_list.5.sa.head_list.6.Dropout_dropout    [8, 256, 256]           -   \n",
            "231_block_list.5.sa.head_list.7.Linear_key          [8, 256, 64]     32.768k   \n",
            "232_block_list.5.sa.head_list.7.Linear_query        [8, 256, 64]     32.768k   \n",
            "233_block_list.5.sa.head_list.7.Linear_value        [8, 256, 64]     32.768k   \n",
            "234_block_list.5.sa.head_list.7.Dropout_dropout    [8, 256, 256]           -   \n",
            "235_block_list.5.sa.Linear_proj                    [8, 256, 512]    262.656k   \n",
            "236_block_list.5.sa.Dropout_dropout                [8, 256, 512]           -   \n",
            "237_block_list.5.LayerNorm_ln2                     [8, 256, 512]      1.024k   \n",
            "238_block_list.5.ff.layers.Linear_0               [8, 256, 2048]   1.050624M   \n",
            "239_block_list.5.ff.layers.GELU_1                 [8, 256, 2048]           -   \n",
            "240_block_list.5.ff.layers.Linear_2                [8, 256, 512]   1.049088M   \n",
            "241_block_list.5.ff.layers.Dropout_3               [8, 256, 512]           -   \n",
            "242_block_list.6.LayerNorm_ln1                     [8, 256, 512]      1.024k   \n",
            "243_block_list.6.sa.head_list.0.Linear_key          [8, 256, 64]     32.768k   \n",
            "244_block_list.6.sa.head_list.0.Linear_query        [8, 256, 64]     32.768k   \n",
            "245_block_list.6.sa.head_list.0.Linear_value        [8, 256, 64]     32.768k   \n",
            "246_block_list.6.sa.head_list.0.Dropout_dropout    [8, 256, 256]           -   \n",
            "247_block_list.6.sa.head_list.1.Linear_key          [8, 256, 64]     32.768k   \n",
            "248_block_list.6.sa.head_list.1.Linear_query        [8, 256, 64]     32.768k   \n",
            "249_block_list.6.sa.head_list.1.Linear_value        [8, 256, 64]     32.768k   \n",
            "250_block_list.6.sa.head_list.1.Dropout_dropout    [8, 256, 256]           -   \n",
            "251_block_list.6.sa.head_list.2.Linear_key          [8, 256, 64]     32.768k   \n",
            "252_block_list.6.sa.head_list.2.Linear_query        [8, 256, 64]     32.768k   \n",
            "253_block_list.6.sa.head_list.2.Linear_value        [8, 256, 64]     32.768k   \n",
            "254_block_list.6.sa.head_list.2.Dropout_dropout    [8, 256, 256]           -   \n",
            "255_block_list.6.sa.head_list.3.Linear_key          [8, 256, 64]     32.768k   \n",
            "256_block_list.6.sa.head_list.3.Linear_query        [8, 256, 64]     32.768k   \n",
            "257_block_list.6.sa.head_list.3.Linear_value        [8, 256, 64]     32.768k   \n",
            "258_block_list.6.sa.head_list.3.Dropout_dropout    [8, 256, 256]           -   \n",
            "259_block_list.6.sa.head_list.4.Linear_key          [8, 256, 64]     32.768k   \n",
            "260_block_list.6.sa.head_list.4.Linear_query        [8, 256, 64]     32.768k   \n",
            "261_block_list.6.sa.head_list.4.Linear_value        [8, 256, 64]     32.768k   \n",
            "262_block_list.6.sa.head_list.4.Dropout_dropout    [8, 256, 256]           -   \n",
            "263_block_list.6.sa.head_list.5.Linear_key          [8, 256, 64]     32.768k   \n",
            "264_block_list.6.sa.head_list.5.Linear_query        [8, 256, 64]     32.768k   \n",
            "265_block_list.6.sa.head_list.5.Linear_value        [8, 256, 64]     32.768k   \n",
            "266_block_list.6.sa.head_list.5.Dropout_dropout    [8, 256, 256]           -   \n",
            "267_block_list.6.sa.head_list.6.Linear_key          [8, 256, 64]     32.768k   \n",
            "268_block_list.6.sa.head_list.6.Linear_query        [8, 256, 64]     32.768k   \n",
            "269_block_list.6.sa.head_list.6.Linear_value        [8, 256, 64]     32.768k   \n",
            "270_block_list.6.sa.head_list.6.Dropout_dropout    [8, 256, 256]           -   \n",
            "271_block_list.6.sa.head_list.7.Linear_key          [8, 256, 64]     32.768k   \n",
            "272_block_list.6.sa.head_list.7.Linear_query        [8, 256, 64]     32.768k   \n",
            "273_block_list.6.sa.head_list.7.Linear_value        [8, 256, 64]     32.768k   \n",
            "274_block_list.6.sa.head_list.7.Dropout_dropout    [8, 256, 256]           -   \n",
            "275_block_list.6.sa.Linear_proj                    [8, 256, 512]    262.656k   \n",
            "276_block_list.6.sa.Dropout_dropout                [8, 256, 512]           -   \n",
            "277_block_list.6.LayerNorm_ln2                     [8, 256, 512]      1.024k   \n",
            "278_block_list.6.ff.layers.Linear_0               [8, 256, 2048]   1.050624M   \n",
            "279_block_list.6.ff.layers.GELU_1                 [8, 256, 2048]           -   \n",
            "280_block_list.6.ff.layers.Linear_2                [8, 256, 512]   1.049088M   \n",
            "281_block_list.6.ff.layers.Dropout_3               [8, 256, 512]           -   \n",
            "282_block_list.7.LayerNorm_ln1                     [8, 256, 512]      1.024k   \n",
            "283_block_list.7.sa.head_list.0.Linear_key          [8, 256, 64]     32.768k   \n",
            "284_block_list.7.sa.head_list.0.Linear_query        [8, 256, 64]     32.768k   \n",
            "285_block_list.7.sa.head_list.0.Linear_value        [8, 256, 64]     32.768k   \n",
            "286_block_list.7.sa.head_list.0.Dropout_dropout    [8, 256, 256]           -   \n",
            "287_block_list.7.sa.head_list.1.Linear_key          [8, 256, 64]     32.768k   \n",
            "288_block_list.7.sa.head_list.1.Linear_query        [8, 256, 64]     32.768k   \n",
            "289_block_list.7.sa.head_list.1.Linear_value        [8, 256, 64]     32.768k   \n",
            "290_block_list.7.sa.head_list.1.Dropout_dropout    [8, 256, 256]           -   \n",
            "291_block_list.7.sa.head_list.2.Linear_key          [8, 256, 64]     32.768k   \n",
            "292_block_list.7.sa.head_list.2.Linear_query        [8, 256, 64]     32.768k   \n",
            "293_block_list.7.sa.head_list.2.Linear_value        [8, 256, 64]     32.768k   \n",
            "294_block_list.7.sa.head_list.2.Dropout_dropout    [8, 256, 256]           -   \n",
            "295_block_list.7.sa.head_list.3.Linear_key          [8, 256, 64]     32.768k   \n",
            "296_block_list.7.sa.head_list.3.Linear_query        [8, 256, 64]     32.768k   \n",
            "297_block_list.7.sa.head_list.3.Linear_value        [8, 256, 64]     32.768k   \n",
            "298_block_list.7.sa.head_list.3.Dropout_dropout    [8, 256, 256]           -   \n",
            "299_block_list.7.sa.head_list.4.Linear_key          [8, 256, 64]     32.768k   \n",
            "300_block_list.7.sa.head_list.4.Linear_query        [8, 256, 64]     32.768k   \n",
            "301_block_list.7.sa.head_list.4.Linear_value        [8, 256, 64]     32.768k   \n",
            "302_block_list.7.sa.head_list.4.Dropout_dropout    [8, 256, 256]           -   \n",
            "303_block_list.7.sa.head_list.5.Linear_key          [8, 256, 64]     32.768k   \n",
            "304_block_list.7.sa.head_list.5.Linear_query        [8, 256, 64]     32.768k   \n",
            "305_block_list.7.sa.head_list.5.Linear_value        [8, 256, 64]     32.768k   \n",
            "306_block_list.7.sa.head_list.5.Dropout_dropout    [8, 256, 256]           -   \n",
            "307_block_list.7.sa.head_list.6.Linear_key          [8, 256, 64]     32.768k   \n",
            "308_block_list.7.sa.head_list.6.Linear_query        [8, 256, 64]     32.768k   \n",
            "309_block_list.7.sa.head_list.6.Linear_value        [8, 256, 64]     32.768k   \n",
            "310_block_list.7.sa.head_list.6.Dropout_dropout    [8, 256, 256]           -   \n",
            "311_block_list.7.sa.head_list.7.Linear_key          [8, 256, 64]     32.768k   \n",
            "312_block_list.7.sa.head_list.7.Linear_query        [8, 256, 64]     32.768k   \n",
            "313_block_list.7.sa.head_list.7.Linear_value        [8, 256, 64]     32.768k   \n",
            "314_block_list.7.sa.head_list.7.Dropout_dropout    [8, 256, 256]           -   \n",
            "315_block_list.7.sa.Linear_proj                    [8, 256, 512]    262.656k   \n",
            "316_block_list.7.sa.Dropout_dropout                [8, 256, 512]           -   \n",
            "317_block_list.7.LayerNorm_ln2                     [8, 256, 512]      1.024k   \n",
            "318_block_list.7.ff.layers.Linear_0               [8, 256, 2048]   1.050624M   \n",
            "319_block_list.7.ff.layers.GELU_1                 [8, 256, 2048]           -   \n",
            "320_block_list.7.ff.layers.Linear_2                [8, 256, 512]   1.049088M   \n",
            "321_block_list.7.ff.layers.Dropout_3               [8, 256, 512]           -   \n",
            "322_final_ln                                       [8, 256, 512]      1.024k   \n",
            "323_lm_head                                      [8, 256, 50257]  25.781841M   \n",
            "\n",
            "                                                  Mult-Adds  \n",
            "Layer                                                        \n",
            "0_token_embeddings                               25.731584M  \n",
            "1_position_embeddings                              131.072k  \n",
            "2_block_list.0.LayerNorm_ln1                          512.0  \n",
            "3_block_list.0.sa.head_list.0.Linear_key            32.768k  \n",
            "4_block_list.0.sa.head_list.0.Linear_query          32.768k  \n",
            "5_block_list.0.sa.head_list.0.Linear_value          32.768k  \n",
            "6_block_list.0.sa.head_list.0.Dropout_dropout             -  \n",
            "7_block_list.0.sa.head_list.1.Linear_key            32.768k  \n",
            "8_block_list.0.sa.head_list.1.Linear_query          32.768k  \n",
            "9_block_list.0.sa.head_list.1.Linear_value          32.768k  \n",
            "10_block_list.0.sa.head_list.1.Dropout_dropout            -  \n",
            "11_block_list.0.sa.head_list.2.Linear_key           32.768k  \n",
            "12_block_list.0.sa.head_list.2.Linear_query         32.768k  \n",
            "13_block_list.0.sa.head_list.2.Linear_value         32.768k  \n",
            "14_block_list.0.sa.head_list.2.Dropout_dropout            -  \n",
            "15_block_list.0.sa.head_list.3.Linear_key           32.768k  \n",
            "16_block_list.0.sa.head_list.3.Linear_query         32.768k  \n",
            "17_block_list.0.sa.head_list.3.Linear_value         32.768k  \n",
            "18_block_list.0.sa.head_list.3.Dropout_dropout            -  \n",
            "19_block_list.0.sa.head_list.4.Linear_key           32.768k  \n",
            "20_block_list.0.sa.head_list.4.Linear_query         32.768k  \n",
            "21_block_list.0.sa.head_list.4.Linear_value         32.768k  \n",
            "22_block_list.0.sa.head_list.4.Dropout_dropout            -  \n",
            "23_block_list.0.sa.head_list.5.Linear_key           32.768k  \n",
            "24_block_list.0.sa.head_list.5.Linear_query         32.768k  \n",
            "25_block_list.0.sa.head_list.5.Linear_value         32.768k  \n",
            "26_block_list.0.sa.head_list.5.Dropout_dropout            -  \n",
            "27_block_list.0.sa.head_list.6.Linear_key           32.768k  \n",
            "28_block_list.0.sa.head_list.6.Linear_query         32.768k  \n",
            "29_block_list.0.sa.head_list.6.Linear_value         32.768k  \n",
            "30_block_list.0.sa.head_list.6.Dropout_dropout            -  \n",
            "31_block_list.0.sa.head_list.7.Linear_key           32.768k  \n",
            "32_block_list.0.sa.head_list.7.Linear_query         32.768k  \n",
            "33_block_list.0.sa.head_list.7.Linear_value         32.768k  \n",
            "34_block_list.0.sa.head_list.7.Dropout_dropout            -  \n",
            "35_block_list.0.sa.Linear_proj                     262.144k  \n",
            "36_block_list.0.sa.Dropout_dropout                        -  \n",
            "37_block_list.0.LayerNorm_ln2                         512.0  \n",
            "38_block_list.0.ff.layers.Linear_0                1.048576M  \n",
            "39_block_list.0.ff.layers.GELU_1                          -  \n",
            "40_block_list.0.ff.layers.Linear_2                1.048576M  \n",
            "41_block_list.0.ff.layers.Dropout_3                       -  \n",
            "42_block_list.1.LayerNorm_ln1                         512.0  \n",
            "43_block_list.1.sa.head_list.0.Linear_key           32.768k  \n",
            "44_block_list.1.sa.head_list.0.Linear_query         32.768k  \n",
            "45_block_list.1.sa.head_list.0.Linear_value         32.768k  \n",
            "46_block_list.1.sa.head_list.0.Dropout_dropout            -  \n",
            "47_block_list.1.sa.head_list.1.Linear_key           32.768k  \n",
            "48_block_list.1.sa.head_list.1.Linear_query         32.768k  \n",
            "49_block_list.1.sa.head_list.1.Linear_value         32.768k  \n",
            "50_block_list.1.sa.head_list.1.Dropout_dropout            -  \n",
            "51_block_list.1.sa.head_list.2.Linear_key           32.768k  \n",
            "52_block_list.1.sa.head_list.2.Linear_query         32.768k  \n",
            "53_block_list.1.sa.head_list.2.Linear_value         32.768k  \n",
            "54_block_list.1.sa.head_list.2.Dropout_dropout            -  \n",
            "55_block_list.1.sa.head_list.3.Linear_key           32.768k  \n",
            "56_block_list.1.sa.head_list.3.Linear_query         32.768k  \n",
            "57_block_list.1.sa.head_list.3.Linear_value         32.768k  \n",
            "58_block_list.1.sa.head_list.3.Dropout_dropout            -  \n",
            "59_block_list.1.sa.head_list.4.Linear_key           32.768k  \n",
            "60_block_list.1.sa.head_list.4.Linear_query         32.768k  \n",
            "61_block_list.1.sa.head_list.4.Linear_value         32.768k  \n",
            "62_block_list.1.sa.head_list.4.Dropout_dropout            -  \n",
            "63_block_list.1.sa.head_list.5.Linear_key           32.768k  \n",
            "64_block_list.1.sa.head_list.5.Linear_query         32.768k  \n",
            "65_block_list.1.sa.head_list.5.Linear_value         32.768k  \n",
            "66_block_list.1.sa.head_list.5.Dropout_dropout            -  \n",
            "67_block_list.1.sa.head_list.6.Linear_key           32.768k  \n",
            "68_block_list.1.sa.head_list.6.Linear_query         32.768k  \n",
            "69_block_list.1.sa.head_list.6.Linear_value         32.768k  \n",
            "70_block_list.1.sa.head_list.6.Dropout_dropout            -  \n",
            "71_block_list.1.sa.head_list.7.Linear_key           32.768k  \n",
            "72_block_list.1.sa.head_list.7.Linear_query         32.768k  \n",
            "73_block_list.1.sa.head_list.7.Linear_value         32.768k  \n",
            "74_block_list.1.sa.head_list.7.Dropout_dropout            -  \n",
            "75_block_list.1.sa.Linear_proj                     262.144k  \n",
            "76_block_list.1.sa.Dropout_dropout                        -  \n",
            "77_block_list.1.LayerNorm_ln2                         512.0  \n",
            "78_block_list.1.ff.layers.Linear_0                1.048576M  \n",
            "79_block_list.1.ff.layers.GELU_1                          -  \n",
            "80_block_list.1.ff.layers.Linear_2                1.048576M  \n",
            "81_block_list.1.ff.layers.Dropout_3                       -  \n",
            "82_block_list.2.LayerNorm_ln1                         512.0  \n",
            "83_block_list.2.sa.head_list.0.Linear_key           32.768k  \n",
            "84_block_list.2.sa.head_list.0.Linear_query         32.768k  \n",
            "85_block_list.2.sa.head_list.0.Linear_value         32.768k  \n",
            "86_block_list.2.sa.head_list.0.Dropout_dropout            -  \n",
            "87_block_list.2.sa.head_list.1.Linear_key           32.768k  \n",
            "88_block_list.2.sa.head_list.1.Linear_query         32.768k  \n",
            "89_block_list.2.sa.head_list.1.Linear_value         32.768k  \n",
            "90_block_list.2.sa.head_list.1.Dropout_dropout            -  \n",
            "91_block_list.2.sa.head_list.2.Linear_key           32.768k  \n",
            "92_block_list.2.sa.head_list.2.Linear_query         32.768k  \n",
            "93_block_list.2.sa.head_list.2.Linear_value         32.768k  \n",
            "94_block_list.2.sa.head_list.2.Dropout_dropout            -  \n",
            "95_block_list.2.sa.head_list.3.Linear_key           32.768k  \n",
            "96_block_list.2.sa.head_list.3.Linear_query         32.768k  \n",
            "97_block_list.2.sa.head_list.3.Linear_value         32.768k  \n",
            "98_block_list.2.sa.head_list.3.Dropout_dropout            -  \n",
            "99_block_list.2.sa.head_list.4.Linear_key           32.768k  \n",
            "100_block_list.2.sa.head_list.4.Linear_query        32.768k  \n",
            "101_block_list.2.sa.head_list.4.Linear_value        32.768k  \n",
            "102_block_list.2.sa.head_list.4.Dropout_dropout           -  \n",
            "103_block_list.2.sa.head_list.5.Linear_key          32.768k  \n",
            "104_block_list.2.sa.head_list.5.Linear_query        32.768k  \n",
            "105_block_list.2.sa.head_list.5.Linear_value        32.768k  \n",
            "106_block_list.2.sa.head_list.5.Dropout_dropout           -  \n",
            "107_block_list.2.sa.head_list.6.Linear_key          32.768k  \n",
            "108_block_list.2.sa.head_list.6.Linear_query        32.768k  \n",
            "109_block_list.2.sa.head_list.6.Linear_value        32.768k  \n",
            "110_block_list.2.sa.head_list.6.Dropout_dropout           -  \n",
            "111_block_list.2.sa.head_list.7.Linear_key          32.768k  \n",
            "112_block_list.2.sa.head_list.7.Linear_query        32.768k  \n",
            "113_block_list.2.sa.head_list.7.Linear_value        32.768k  \n",
            "114_block_list.2.sa.head_list.7.Dropout_dropout           -  \n",
            "115_block_list.2.sa.Linear_proj                    262.144k  \n",
            "116_block_list.2.sa.Dropout_dropout                       -  \n",
            "117_block_list.2.LayerNorm_ln2                        512.0  \n",
            "118_block_list.2.ff.layers.Linear_0               1.048576M  \n",
            "119_block_list.2.ff.layers.GELU_1                         -  \n",
            "120_block_list.2.ff.layers.Linear_2               1.048576M  \n",
            "121_block_list.2.ff.layers.Dropout_3                      -  \n",
            "122_block_list.3.LayerNorm_ln1                        512.0  \n",
            "123_block_list.3.sa.head_list.0.Linear_key          32.768k  \n",
            "124_block_list.3.sa.head_list.0.Linear_query        32.768k  \n",
            "125_block_list.3.sa.head_list.0.Linear_value        32.768k  \n",
            "126_block_list.3.sa.head_list.0.Dropout_dropout           -  \n",
            "127_block_list.3.sa.head_list.1.Linear_key          32.768k  \n",
            "128_block_list.3.sa.head_list.1.Linear_query        32.768k  \n",
            "129_block_list.3.sa.head_list.1.Linear_value        32.768k  \n",
            "130_block_list.3.sa.head_list.1.Dropout_dropout           -  \n",
            "131_block_list.3.sa.head_list.2.Linear_key          32.768k  \n",
            "132_block_list.3.sa.head_list.2.Linear_query        32.768k  \n",
            "133_block_list.3.sa.head_list.2.Linear_value        32.768k  \n",
            "134_block_list.3.sa.head_list.2.Dropout_dropout           -  \n",
            "135_block_list.3.sa.head_list.3.Linear_key          32.768k  \n",
            "136_block_list.3.sa.head_list.3.Linear_query        32.768k  \n",
            "137_block_list.3.sa.head_list.3.Linear_value        32.768k  \n",
            "138_block_list.3.sa.head_list.3.Dropout_dropout           -  \n",
            "139_block_list.3.sa.head_list.4.Linear_key          32.768k  \n",
            "140_block_list.3.sa.head_list.4.Linear_query        32.768k  \n",
            "141_block_list.3.sa.head_list.4.Linear_value        32.768k  \n",
            "142_block_list.3.sa.head_list.4.Dropout_dropout           -  \n",
            "143_block_list.3.sa.head_list.5.Linear_key          32.768k  \n",
            "144_block_list.3.sa.head_list.5.Linear_query        32.768k  \n",
            "145_block_list.3.sa.head_list.5.Linear_value        32.768k  \n",
            "146_block_list.3.sa.head_list.5.Dropout_dropout           -  \n",
            "147_block_list.3.sa.head_list.6.Linear_key          32.768k  \n",
            "148_block_list.3.sa.head_list.6.Linear_query        32.768k  \n",
            "149_block_list.3.sa.head_list.6.Linear_value        32.768k  \n",
            "150_block_list.3.sa.head_list.6.Dropout_dropout           -  \n",
            "151_block_list.3.sa.head_list.7.Linear_key          32.768k  \n",
            "152_block_list.3.sa.head_list.7.Linear_query        32.768k  \n",
            "153_block_list.3.sa.head_list.7.Linear_value        32.768k  \n",
            "154_block_list.3.sa.head_list.7.Dropout_dropout           -  \n",
            "155_block_list.3.sa.Linear_proj                    262.144k  \n",
            "156_block_list.3.sa.Dropout_dropout                       -  \n",
            "157_block_list.3.LayerNorm_ln2                        512.0  \n",
            "158_block_list.3.ff.layers.Linear_0               1.048576M  \n",
            "159_block_list.3.ff.layers.GELU_1                         -  \n",
            "160_block_list.3.ff.layers.Linear_2               1.048576M  \n",
            "161_block_list.3.ff.layers.Dropout_3                      -  \n",
            "162_block_list.4.LayerNorm_ln1                        512.0  \n",
            "163_block_list.4.sa.head_list.0.Linear_key          32.768k  \n",
            "164_block_list.4.sa.head_list.0.Linear_query        32.768k  \n",
            "165_block_list.4.sa.head_list.0.Linear_value        32.768k  \n",
            "166_block_list.4.sa.head_list.0.Dropout_dropout           -  \n",
            "167_block_list.4.sa.head_list.1.Linear_key          32.768k  \n",
            "168_block_list.4.sa.head_list.1.Linear_query        32.768k  \n",
            "169_block_list.4.sa.head_list.1.Linear_value        32.768k  \n",
            "170_block_list.4.sa.head_list.1.Dropout_dropout           -  \n",
            "171_block_list.4.sa.head_list.2.Linear_key          32.768k  \n",
            "172_block_list.4.sa.head_list.2.Linear_query        32.768k  \n",
            "173_block_list.4.sa.head_list.2.Linear_value        32.768k  \n",
            "174_block_list.4.sa.head_list.2.Dropout_dropout           -  \n",
            "175_block_list.4.sa.head_list.3.Linear_key          32.768k  \n",
            "176_block_list.4.sa.head_list.3.Linear_query        32.768k  \n",
            "177_block_list.4.sa.head_list.3.Linear_value        32.768k  \n",
            "178_block_list.4.sa.head_list.3.Dropout_dropout           -  \n",
            "179_block_list.4.sa.head_list.4.Linear_key          32.768k  \n",
            "180_block_list.4.sa.head_list.4.Linear_query        32.768k  \n",
            "181_block_list.4.sa.head_list.4.Linear_value        32.768k  \n",
            "182_block_list.4.sa.head_list.4.Dropout_dropout           -  \n",
            "183_block_list.4.sa.head_list.5.Linear_key          32.768k  \n",
            "184_block_list.4.sa.head_list.5.Linear_query        32.768k  \n",
            "185_block_list.4.sa.head_list.5.Linear_value        32.768k  \n",
            "186_block_list.4.sa.head_list.5.Dropout_dropout           -  \n",
            "187_block_list.4.sa.head_list.6.Linear_key          32.768k  \n",
            "188_block_list.4.sa.head_list.6.Linear_query        32.768k  \n",
            "189_block_list.4.sa.head_list.6.Linear_value        32.768k  \n",
            "190_block_list.4.sa.head_list.6.Dropout_dropout           -  \n",
            "191_block_list.4.sa.head_list.7.Linear_key          32.768k  \n",
            "192_block_list.4.sa.head_list.7.Linear_query        32.768k  \n",
            "193_block_list.4.sa.head_list.7.Linear_value        32.768k  \n",
            "194_block_list.4.sa.head_list.7.Dropout_dropout           -  \n",
            "195_block_list.4.sa.Linear_proj                    262.144k  \n",
            "196_block_list.4.sa.Dropout_dropout                       -  \n",
            "197_block_list.4.LayerNorm_ln2                        512.0  \n",
            "198_block_list.4.ff.layers.Linear_0               1.048576M  \n",
            "199_block_list.4.ff.layers.GELU_1                         -  \n",
            "200_block_list.4.ff.layers.Linear_2               1.048576M  \n",
            "201_block_list.4.ff.layers.Dropout_3                      -  \n",
            "202_block_list.5.LayerNorm_ln1                        512.0  \n",
            "203_block_list.5.sa.head_list.0.Linear_key          32.768k  \n",
            "204_block_list.5.sa.head_list.0.Linear_query        32.768k  \n",
            "205_block_list.5.sa.head_list.0.Linear_value        32.768k  \n",
            "206_block_list.5.sa.head_list.0.Dropout_dropout           -  \n",
            "207_block_list.5.sa.head_list.1.Linear_key          32.768k  \n",
            "208_block_list.5.sa.head_list.1.Linear_query        32.768k  \n",
            "209_block_list.5.sa.head_list.1.Linear_value        32.768k  \n",
            "210_block_list.5.sa.head_list.1.Dropout_dropout           -  \n",
            "211_block_list.5.sa.head_list.2.Linear_key          32.768k  \n",
            "212_block_list.5.sa.head_list.2.Linear_query        32.768k  \n",
            "213_block_list.5.sa.head_list.2.Linear_value        32.768k  \n",
            "214_block_list.5.sa.head_list.2.Dropout_dropout           -  \n",
            "215_block_list.5.sa.head_list.3.Linear_key          32.768k  \n",
            "216_block_list.5.sa.head_list.3.Linear_query        32.768k  \n",
            "217_block_list.5.sa.head_list.3.Linear_value        32.768k  \n",
            "218_block_list.5.sa.head_list.3.Dropout_dropout           -  \n",
            "219_block_list.5.sa.head_list.4.Linear_key          32.768k  \n",
            "220_block_list.5.sa.head_list.4.Linear_query        32.768k  \n",
            "221_block_list.5.sa.head_list.4.Linear_value        32.768k  \n",
            "222_block_list.5.sa.head_list.4.Dropout_dropout           -  \n",
            "223_block_list.5.sa.head_list.5.Linear_key          32.768k  \n",
            "224_block_list.5.sa.head_list.5.Linear_query        32.768k  \n",
            "225_block_list.5.sa.head_list.5.Linear_value        32.768k  \n",
            "226_block_list.5.sa.head_list.5.Dropout_dropout           -  \n",
            "227_block_list.5.sa.head_list.6.Linear_key          32.768k  \n",
            "228_block_list.5.sa.head_list.6.Linear_query        32.768k  \n",
            "229_block_list.5.sa.head_list.6.Linear_value        32.768k  \n",
            "230_block_list.5.sa.head_list.6.Dropout_dropout           -  \n",
            "231_block_list.5.sa.head_list.7.Linear_key          32.768k  \n",
            "232_block_list.5.sa.head_list.7.Linear_query        32.768k  \n",
            "233_block_list.5.sa.head_list.7.Linear_value        32.768k  \n",
            "234_block_list.5.sa.head_list.7.Dropout_dropout           -  \n",
            "235_block_list.5.sa.Linear_proj                    262.144k  \n",
            "236_block_list.5.sa.Dropout_dropout                       -  \n",
            "237_block_list.5.LayerNorm_ln2                        512.0  \n",
            "238_block_list.5.ff.layers.Linear_0               1.048576M  \n",
            "239_block_list.5.ff.layers.GELU_1                         -  \n",
            "240_block_list.5.ff.layers.Linear_2               1.048576M  \n",
            "241_block_list.5.ff.layers.Dropout_3                      -  \n",
            "242_block_list.6.LayerNorm_ln1                        512.0  \n",
            "243_block_list.6.sa.head_list.0.Linear_key          32.768k  \n",
            "244_block_list.6.sa.head_list.0.Linear_query        32.768k  \n",
            "245_block_list.6.sa.head_list.0.Linear_value        32.768k  \n",
            "246_block_list.6.sa.head_list.0.Dropout_dropout           -  \n",
            "247_block_list.6.sa.head_list.1.Linear_key          32.768k  \n",
            "248_block_list.6.sa.head_list.1.Linear_query        32.768k  \n",
            "249_block_list.6.sa.head_list.1.Linear_value        32.768k  \n",
            "250_block_list.6.sa.head_list.1.Dropout_dropout           -  \n",
            "251_block_list.6.sa.head_list.2.Linear_key          32.768k  \n",
            "252_block_list.6.sa.head_list.2.Linear_query        32.768k  \n",
            "253_block_list.6.sa.head_list.2.Linear_value        32.768k  \n",
            "254_block_list.6.sa.head_list.2.Dropout_dropout           -  \n",
            "255_block_list.6.sa.head_list.3.Linear_key          32.768k  \n",
            "256_block_list.6.sa.head_list.3.Linear_query        32.768k  \n",
            "257_block_list.6.sa.head_list.3.Linear_value        32.768k  \n",
            "258_block_list.6.sa.head_list.3.Dropout_dropout           -  \n",
            "259_block_list.6.sa.head_list.4.Linear_key          32.768k  \n",
            "260_block_list.6.sa.head_list.4.Linear_query        32.768k  \n",
            "261_block_list.6.sa.head_list.4.Linear_value        32.768k  \n",
            "262_block_list.6.sa.head_list.4.Dropout_dropout           -  \n",
            "263_block_list.6.sa.head_list.5.Linear_key          32.768k  \n",
            "264_block_list.6.sa.head_list.5.Linear_query        32.768k  \n",
            "265_block_list.6.sa.head_list.5.Linear_value        32.768k  \n",
            "266_block_list.6.sa.head_list.5.Dropout_dropout           -  \n",
            "267_block_list.6.sa.head_list.6.Linear_key          32.768k  \n",
            "268_block_list.6.sa.head_list.6.Linear_query        32.768k  \n",
            "269_block_list.6.sa.head_list.6.Linear_value        32.768k  \n",
            "270_block_list.6.sa.head_list.6.Dropout_dropout           -  \n",
            "271_block_list.6.sa.head_list.7.Linear_key          32.768k  \n",
            "272_block_list.6.sa.head_list.7.Linear_query        32.768k  \n",
            "273_block_list.6.sa.head_list.7.Linear_value        32.768k  \n",
            "274_block_list.6.sa.head_list.7.Dropout_dropout           -  \n",
            "275_block_list.6.sa.Linear_proj                    262.144k  \n",
            "276_block_list.6.sa.Dropout_dropout                       -  \n",
            "277_block_list.6.LayerNorm_ln2                        512.0  \n",
            "278_block_list.6.ff.layers.Linear_0               1.048576M  \n",
            "279_block_list.6.ff.layers.GELU_1                         -  \n",
            "280_block_list.6.ff.layers.Linear_2               1.048576M  \n",
            "281_block_list.6.ff.layers.Dropout_3                      -  \n",
            "282_block_list.7.LayerNorm_ln1                        512.0  \n",
            "283_block_list.7.sa.head_list.0.Linear_key          32.768k  \n",
            "284_block_list.7.sa.head_list.0.Linear_query        32.768k  \n",
            "285_block_list.7.sa.head_list.0.Linear_value        32.768k  \n",
            "286_block_list.7.sa.head_list.0.Dropout_dropout           -  \n",
            "287_block_list.7.sa.head_list.1.Linear_key          32.768k  \n",
            "288_block_list.7.sa.head_list.1.Linear_query        32.768k  \n",
            "289_block_list.7.sa.head_list.1.Linear_value        32.768k  \n",
            "290_block_list.7.sa.head_list.1.Dropout_dropout           -  \n",
            "291_block_list.7.sa.head_list.2.Linear_key          32.768k  \n",
            "292_block_list.7.sa.head_list.2.Linear_query        32.768k  \n",
            "293_block_list.7.sa.head_list.2.Linear_value        32.768k  \n",
            "294_block_list.7.sa.head_list.2.Dropout_dropout           -  \n",
            "295_block_list.7.sa.head_list.3.Linear_key          32.768k  \n",
            "296_block_list.7.sa.head_list.3.Linear_query        32.768k  \n",
            "297_block_list.7.sa.head_list.3.Linear_value        32.768k  \n",
            "298_block_list.7.sa.head_list.3.Dropout_dropout           -  \n",
            "299_block_list.7.sa.head_list.4.Linear_key          32.768k  \n",
            "300_block_list.7.sa.head_list.4.Linear_query        32.768k  \n",
            "301_block_list.7.sa.head_list.4.Linear_value        32.768k  \n",
            "302_block_list.7.sa.head_list.4.Dropout_dropout           -  \n",
            "303_block_list.7.sa.head_list.5.Linear_key          32.768k  \n",
            "304_block_list.7.sa.head_list.5.Linear_query        32.768k  \n",
            "305_block_list.7.sa.head_list.5.Linear_value        32.768k  \n",
            "306_block_list.7.sa.head_list.5.Dropout_dropout           -  \n",
            "307_block_list.7.sa.head_list.6.Linear_key          32.768k  \n",
            "308_block_list.7.sa.head_list.6.Linear_query        32.768k  \n",
            "309_block_list.7.sa.head_list.6.Linear_value        32.768k  \n",
            "310_block_list.7.sa.head_list.6.Dropout_dropout           -  \n",
            "311_block_list.7.sa.head_list.7.Linear_key          32.768k  \n",
            "312_block_list.7.sa.head_list.7.Linear_query        32.768k  \n",
            "313_block_list.7.sa.head_list.7.Linear_value        32.768k  \n",
            "314_block_list.7.sa.head_list.7.Dropout_dropout           -  \n",
            "315_block_list.7.sa.Linear_proj                    262.144k  \n",
            "316_block_list.7.sa.Dropout_dropout                       -  \n",
            "317_block_list.7.LayerNorm_ln2                        512.0  \n",
            "318_block_list.7.ff.layers.Linear_0               1.048576M  \n",
            "319_block_list.7.ff.layers.GELU_1                         -  \n",
            "320_block_list.7.ff.layers.Linear_2               1.048576M  \n",
            "321_block_list.7.ff.layers.Dropout_3                      -  \n",
            "322_final_ln                                          512.0  \n",
            "323_lm_head                                      25.731584M  \n",
            "------------------------------------------------------------------------------------------------------\n",
            "                          Totals\n",
            "Total params          76.852305M\n",
            "Trainable params      76.852305M\n",
            "Non-trainable params         0.0\n",
            "Mult-Adds             76.768768M\n",
            "======================================================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Kernel Shape     Output Shape  \\\n",
              "Layer                                                                       \n",
              "0_token_embeddings                          [512, 50257]    [8, 256, 512]   \n",
              "1_position_embeddings                         [512, 256]       [256, 512]   \n",
              "2_block_list.0.LayerNorm_ln1                       [512]    [8, 256, 512]   \n",
              "3_block_list.0.sa.head_list.0.Linear_key       [512, 64]     [8, 256, 64]   \n",
              "4_block_list.0.sa.head_list.0.Linear_query     [512, 64]     [8, 256, 64]   \n",
              "...                                                  ...              ...   \n",
              "319_block_list.7.ff.layers.GELU_1                      -   [8, 256, 2048]   \n",
              "320_block_list.7.ff.layers.Linear_2          [2048, 512]    [8, 256, 512]   \n",
              "321_block_list.7.ff.layers.Dropout_3                   -    [8, 256, 512]   \n",
              "322_final_ln                                       [512]    [8, 256, 512]   \n",
              "323_lm_head                                 [512, 50257]  [8, 256, 50257]   \n",
              "\n",
              "                                                Params   Mult-Adds  \n",
              "Layer                                                               \n",
              "0_token_embeddings                          25731584.0  25731584.0  \n",
              "1_position_embeddings                         131072.0    131072.0  \n",
              "2_block_list.0.LayerNorm_ln1                    1024.0       512.0  \n",
              "3_block_list.0.sa.head_list.0.Linear_key       32768.0     32768.0  \n",
              "4_block_list.0.sa.head_list.0.Linear_query     32768.0     32768.0  \n",
              "...                                                ...         ...  \n",
              "319_block_list.7.ff.layers.GELU_1                  NaN         NaN  \n",
              "320_block_list.7.ff.layers.Linear_2          1049088.0   1048576.0  \n",
              "321_block_list.7.ff.layers.Dropout_3               NaN         NaN  \n",
              "322_final_ln                                    1024.0       512.0  \n",
              "323_lm_head                                 25781841.0  25731584.0  \n",
              "\n",
              "[324 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d40caeb5-42e3-4e22-927c-54f3c752f426\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kernel Shape</th>\n",
              "      <th>Output Shape</th>\n",
              "      <th>Params</th>\n",
              "      <th>Mult-Adds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Layer</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_token_embeddings</th>\n",
              "      <td>[512, 50257]</td>\n",
              "      <td>[8, 256, 512]</td>\n",
              "      <td>25731584.0</td>\n",
              "      <td>25731584.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_position_embeddings</th>\n",
              "      <td>[512, 256]</td>\n",
              "      <td>[256, 512]</td>\n",
              "      <td>131072.0</td>\n",
              "      <td>131072.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_block_list.0.LayerNorm_ln1</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[8, 256, 512]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_block_list.0.sa.head_list.0.Linear_key</th>\n",
              "      <td>[512, 64]</td>\n",
              "      <td>[8, 256, 64]</td>\n",
              "      <td>32768.0</td>\n",
              "      <td>32768.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_block_list.0.sa.head_list.0.Linear_query</th>\n",
              "      <td>[512, 64]</td>\n",
              "      <td>[8, 256, 64]</td>\n",
              "      <td>32768.0</td>\n",
              "      <td>32768.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319_block_list.7.ff.layers.GELU_1</th>\n",
              "      <td>-</td>\n",
              "      <td>[8, 256, 2048]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320_block_list.7.ff.layers.Linear_2</th>\n",
              "      <td>[2048, 512]</td>\n",
              "      <td>[8, 256, 512]</td>\n",
              "      <td>1049088.0</td>\n",
              "      <td>1048576.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321_block_list.7.ff.layers.Dropout_3</th>\n",
              "      <td>-</td>\n",
              "      <td>[8, 256, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322_final_ln</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[8, 256, 512]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323_lm_head</th>\n",
              "      <td>[512, 50257]</td>\n",
              "      <td>[8, 256, 50257]</td>\n",
              "      <td>25781841.0</td>\n",
              "      <td>25731584.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>324 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d40caeb5-42e3-4e22-927c-54f3c752f426')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d40caeb5-42e3-4e22-927c-54f3c752f426 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d40caeb5-42e3-4e22-927c-54f3c752f426');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bf93ef31-85dc-469c-b20b-8b24233b7009\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf93ef31-85dc-469c-b20b-8b24233b7009')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bf93ef31-85dc-469c-b20b-8b24233b7009 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "unhashable type: 'list'"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "summary(model, xb.to(device), yb.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8rVNj48QLUc"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
        "\n",
        "\n",
        "# for generation\n",
        "start_ix = torch.zeros((1,1), dtype=torch.long, device=device) # (newline character in a single batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eT5YkoSNQLUc"
      },
      "outputs": [],
      "source": [
        "# poor man's lr scheduler. why? because cosine with warmup isn't readily available on torch (it's warm RESTARTS)\n",
        "# but idc about restarting eh?\n",
        "def get_lr(it):\n",
        "    \"get lr at a specific iteration\"\n",
        "    max_lr = config.lr\n",
        "    min_lr = config.min_lr\n",
        "    warmup_iters = config.warmup_iters\n",
        "    max_lr_decay_iters = config.num_iters # can also be made into another param\n",
        "    if it <= warmup_iters:\n",
        "        return max_lr * (it / warmup_iters)\n",
        "\n",
        "    if it > max_lr_decay_iters:\n",
        "        # decaying only up to a certain point, interesting\n",
        "        return min_lr\n",
        "    ratio = (it - warmup_iters) / (max_lr_decay_iters - warmup_iters) # how much % of decay cycle is done?\n",
        "    coeff = 0.5 * (1 + math.cos(math.pi * ratio)) # [0,1]\n",
        "    return min_lr + coeff * (max_lr - min_lr) # beautiful"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9X5IiaarQLUc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "3b37d9fd-c9bc-4510-eaa0-c0bde47146d6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def test_lr():\n",
        "    import random\n",
        "    import matplotlib.pyplot as plt\n",
        "    x = [i for i in range(0,10000,100)]\n",
        "    y = [get_lr(i) for i in x]\n",
        "    plt.plot(x, y)\n",
        "    plt.show()\n",
        "\n",
        "test_lr()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVOkmmi_QLUc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "be617803-f71e-4642-a4a7-22cae5dd0854"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n@torch.no_grad()\\ndef estimate_losses(config):\\n    model.eval()\\n    losses = {'train': -1., 'val': -1.}\\n    for split in ['train', 'val']:\\n        loss = 0\\n        for _ in range(config.eval_iters):\\n            # xb, yb = next(iter(val_loader))\\n            # xb, yb = xb.to(device), yb.to(device)\\n            xb, yb = get_batch('val')\\n            loss += model(xb, yb)[1].item()\\n        loss /= config.eval_iters\\n        if split == 'train':\\n            losses['train'] = loss\\n        else:\\n            losses['val'] = loss\\n    model.train()\\n    return losses\\n    \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "'''\n",
        "@torch.no_grad()\n",
        "def estimate_losses(config):\n",
        "    model.eval()\n",
        "    losses = {'train': -1., 'val': -1.}\n",
        "    for split in ['train', 'val']:\n",
        "        loss = 0\n",
        "        for _ in range(config.eval_iters):\n",
        "            # xb, yb = next(iter(val_loader))\n",
        "            # xb, yb = xb.to(device), yb.to(device)\n",
        "            xb, yb = get_batch('val')\n",
        "            loss += model(xb, yb)[1].item()\n",
        "        loss /= config.eval_iters\n",
        "        if split == 'train':\n",
        "            losses['train'] = loss\n",
        "        else:\n",
        "            losses['val'] = loss\n",
        "    model.train()\n",
        "    return losses\n",
        "    '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47ZGa3tkMSAi"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def estimate_losses(config, train_loader, val_loader):\n",
        "    model.eval()\n",
        "    losses = {'train': -1., 'val': -1.}\n",
        "    train_loss = 0\n",
        "    train_iters = min(config.eval_iters, len(train_loader))\n",
        "    for i, (xb, yb) in enumerate(train_loader):\n",
        "        if i >= train_iters:\n",
        "            break\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        _, loss = model(xb, yb)\n",
        "        train_loss += loss.item()\n",
        "    losses['train'] = train_loss / train_iters\n",
        "\n",
        "    # Evaluate validation loss (considering only config.eval_iters iterations)\n",
        "    val_loss = 0\n",
        "    val_iters = min(config.eval_iters, len(val_loader))\n",
        "    for i, (xb, yb) in enumerate(val_loader):\n",
        "        if i >= val_iters:\n",
        "            break\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        _, loss = model(xb, yb)\n",
        "        val_loss += loss.item()\n",
        "    losses['val'] = val_loss / val_iters\n",
        "\n",
        "    model.train()\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEvNGlwJ1aPr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b1fcded-280c-412c-973a-12120963dbe3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "#@title Load Pretrained\n",
        "CKPT_PATH = 'best_model.pth'\n",
        "ckpt = torch.load(CKPT_PATH)\n",
        "model.load_state_dict(ckpt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJfqzDg2QLUc"
      },
      "source": [
        "## WandB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "no1t4aJ5QLUc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "5edf1ab5-02dc-42af-dd1c-37a2626a8d2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhuayuyan\u001b[0m (\u001b[33mhuayuyang\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240427_223840-usogig48</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/huayuyang/ideal_gpt/runs/usogig48' target=\"_blank\">pretrain_v1</a></strong> to <a href='https://wandb.ai/huayuyang/ideal_gpt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/huayuyang/ideal_gpt' target=\"_blank\">https://wandb.ai/huayuyang/ideal_gpt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/huayuyang/ideal_gpt/runs/usogig48' target=\"_blank\">https://wandb.ai/huayuyang/ideal_gpt/runs/usogig48</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "wandb.login(key=\"11c390c26f231132a3244dc3831234fad032e629\")\n",
        "run = wandb.init(\n",
        "        name    = 'pretrain_v1', ## Wandb creates random run names if you skip this field\n",
        "        reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
        "        # entity = 'thunderbuddies',\n",
        "        # run_id = ### Insert specific run id here if you want to resume a previous run\n",
        "        # resume = \"must\" ### You need this to resume previous runs, but comment out reinit = True when using this\n",
        "        project = \"ideal_gpt\", ### Project should be created in your wandb account\n",
        "        config = config, ### Wandb Config for your run,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smwh3FSyQLUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36c53965-ded3-45ab-a480-ff493aa141a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "start_ix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLdX2OG3QLUd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1991619-3b5f-4934-ee16-739b9012bda3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "cur_iter = 0\n",
        "best_val = 1e9\n",
        "best_path = 'best_fine_tune_model.pth'\n",
        "running_loss = 0.0\n",
        "loss_counter=0\n",
        "pbar = tqdm(total=config.num_iters, dynamic_ncols=True, leave=False, position=0, desc=\"Train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Z9UAAmpQLUd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "4fb4b880-6873-48e8-bae0-410ea9489443"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nwhile cur_iter <= config.num_iters:\\n    optimizer.zero_grad(set_to_none = True) # https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html\\n    # poor man\\'s lr scheduler\\n    cur_lr = get_lr(cur_iter) if config.lr_decay else config.lr\\n    for param_group in optimizer.param_groups:\\n        param_group[\\'lr\\'] = cur_lr\\n\\n    # xb, yb = next(iter(train_loader))\\n    for micro_step in range(config.gradient_accumulation_steps):\\n        xb, yb = get_batch(\\'train\\')\\n        # xb, yb = xb.to(device), yb.to(device)\\n        with torch.cuda.amp.autocast():\\n            logits, loss = model(xb, yb)\\n\\n        running_loss += loss.item()\\n        train_loss = running_loss / (loss_counter + 1)\\n        loss_counter += 1\\n\\n        scaler.scale(loss).backward()\\n\\n    if config.grad_clip != 0.0:\\n        scaler.unscale_(optimizer)\\n        torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip)\\n    scaler.step(optimizer)\\n    scaler.update()\\n\\n    # val every eval_intervals\\n    if cur_iter % config.eval_interval == 0:\\n        losses = estimate_losses(config)\\n        val_loss = losses[\\'val\\']\\n        train_loss = losses[\\'train\\']\\n        print(f\\'Val @ Epoch {cur_iter}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}\\')\\n        wandb.log({\\n            \\'val_loss\\': val_loss,\\n            \\'iter\\': cur_iter,\\n            \\'lr\\': optimizer.param_groups[0][\\'lr\\']\\n        })\\n        if val_loss < best_val:\\n            best_val = val_loss\\n            torch.save(model.state_dict(), best_path)\\n            print(f\\'Saved best model to {best_path}\\')\\n        print(\\'Sample Generation\\')\\n        print(tokenizer.decode(model.generate(start_ix, 100)[0].tolist()))\\n\\n    # train logs\\n    wandb.log({\\n        \\'train_loss\\': train_loss,\\n        \\'iter\\': cur_iter,\\n        \\'lr\\': cur_lr\\n    })\\n    pbar.set_postfix(\\n            loss = \"{:.04f}\".format(train_loss),\\n            lr = cur_lr\\n        )\\n    pbar.update()\\n\\n\\n    cur_iter += 1\\n    '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "'''\n",
        "while cur_iter <= config.num_iters:\n",
        "    optimizer.zero_grad(set_to_none = True) # https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html\n",
        "    # poor man's lr scheduler\n",
        "    cur_lr = get_lr(cur_iter) if config.lr_decay else config.lr\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = cur_lr\n",
        "\n",
        "    # xb, yb = next(iter(train_loader))\n",
        "    for micro_step in range(config.gradient_accumulation_steps):\n",
        "        xb, yb = get_batch('train')\n",
        "        # xb, yb = xb.to(device), yb.to(device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            logits, loss = model(xb, yb)\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        train_loss = running_loss / (loss_counter + 1)\n",
        "        loss_counter += 1\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "    if config.grad_clip != 0.0:\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip)\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "\n",
        "    # val every eval_intervals\n",
        "    if cur_iter % config.eval_interval == 0:\n",
        "        losses = estimate_losses(config)\n",
        "        val_loss = losses['val']\n",
        "        train_loss = losses['train']\n",
        "        print(f'Val @ Epoch {cur_iter}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}')\n",
        "        wandb.log({\n",
        "            'val_loss': val_loss,\n",
        "            'iter': cur_iter,\n",
        "            'lr': optimizer.param_groups[0]['lr']\n",
        "        })\n",
        "        if val_loss < best_val:\n",
        "            best_val = val_loss\n",
        "            torch.save(model.state_dict(), best_path)\n",
        "            print(f'Saved best model to {best_path}')\n",
        "        print('Sample Generation')\n",
        "        print(tokenizer.decode(model.generate(start_ix, 100)[0].tolist()))\n",
        "\n",
        "    # train logs\n",
        "    wandb.log({\n",
        "        'train_loss': train_loss,\n",
        "        'iter': cur_iter,\n",
        "        'lr': cur_lr\n",
        "    })\n",
        "    pbar.set_postfix(\n",
        "            loss = \"{:.04f}\".format(train_loss),\n",
        "            lr = cur_lr\n",
        "        )\n",
        "    pbar.update()\n",
        "\n",
        "\n",
        "    cur_iter += 1\n",
        "    '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRMAeKP5PfOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ba742a5-fcc7-4536-d01f-9df730c88a62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val @ Epoch 0: Train Loss=3.9672, Val Loss=3.8640\n",
            "Saved best model to best_fine_tune_model.pth\n",
            "Sample Generation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  20%|██        | 1/5 [3:46:15<15:05:02, 13575.58s/it, loss=3.9672, lr=0]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "! This book set a record as being female, harder to sell to girls and more important, oh, we fucking hate her.<|endoftext|>[Update; 4/17: Fort Lauderdale is a town you’ll hear all day, counting! This one isn’t in the early 1960s, according to notepads!)\n",
            "\n",
            "Updated: Dec. 17, 25, Blog: “At the opening of the museum Poelty went to the Showbox. That’s upstairs\n",
            "Val @ Epoch 1: Train Loss=2.7668, Val Loss=2.7833\n",
            "Saved best model to best_fine_tune_model.pth\n",
            "Sample Generation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  40%|████      | 2/5 [7:35:30<11:24:03, 13681.33s/it, loss=2.7668, lr=2e-6]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "! acruero Monaco finale diorgio: janitorial du Laert Anthem no victoria by néln, ne pas mênci dada est seventh premiere. L'utilisateur diorgio, diorita dal vale 2.4 dentson a dorter operat diorui des decizationes enver satisfizziter. L'utilisateur a parcheface al partir l'al est militari glane, therefore fulf\n",
            "Val @ Epoch 2: Train Loss=2.7081, Val Loss=2.6940\n",
            "Saved best model to best_fine_tune_model.pth\n",
            "Sample Generation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  60%|██████    | 3/5 [11:24:52<7:37:15, 13717.99s/it, loss=2.7081, lr=4e-6] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!|<|endoftext|>All photos credit Jessica Sook. She still has a few bouts of anger, ruined by binge drinking. Now, she in fact is extremely relieved to be able to drink enough for her two teenage sons. Liz being an A and C filleteries in Nottingham. Abby, 58, has committed suicide whilst quaking in bed one last time. Parts of a scale from the top to top include Lord Ringo’s £60 bars, which are currently on sale for £30 each\n",
            "Val @ Epoch 3: Train Loss=2.6816, Val Loss=2.6426\n",
            "Saved best model to best_fine_tune_model.pth\n",
            "Sample Generation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  80%|████████  | 4/5 [15:14:15<3:48:55, 13735.64s/it, loss=2.6816, lr=6e-6]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!|system|>\n",
            "<|endoftext|>Renowned New York-based radio station The Letter America was broadcast on November 21, 1994. The new program was launched on November 22 triumphing eleven episodes and sharing two episodes with Uncertain, Much Odd Couples, TLC, and Spin. In 2010 after one of them aired, Paramount Television released the Do Good Network mini-claunch from its broadcast channels. All of its programming was licensed to CBS in October 2011, as was the Do Good Network/\n",
            "Val @ Epoch 4: Train Loss=2.5018, Val Loss=2.6105\n",
            "Saved best model to best_fine_tune_model.pth\n",
            "Sample Generation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 5/5 [19:03:59<00:00, 13753.26s/it, loss=2.5018, lr=8e-6]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!|system|>\n",
            "<|endoftext|>Humanity has age, has mass volunteerism, has bipartisanship and guild membership. Participation in any one age group is understood to be a one-way thing, for example, a role not only in American politics as it is included in American politics in many democratic systems today, but has, until recently, primarily been manifested in large-scale resistance protests due to cultural representations. It is a complete thing. With its powerful stripperry it is crucial that\n",
            "Val @ Epoch 5: Train Loss=2.6285, Val Loss=2.5855\n",
            "Saved best model to best_fine_tune_model.pth\n",
            "Sample Generation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 6it [22:53:17, 13754.78s/it, loss=2.6285, lr=1e-5]                       "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!|system|>\n",
            "<|endoftext|>Carlos Vazro search<|endoftext|>An ancient ancient history corresponds to the wide, continuous \"Perl 2\", a volcanic million dollar fine or greater (Pleife derpaitedus maeres e di filio lumate di crystallise, naΰˈlito, boodle, a branch) known as the Perl II. The rock is well marked with footstone, teeth, topped and tailpans, a large scalarm, and\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "cur_iter=0\n",
        "\n",
        "while cur_iter <= config.num_iters:\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    cur_lr = get_lr(cur_iter) if config.lr_decay else config.lr\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = cur_lr\n",
        "\n",
        "    # Iterate over batches from the DataLoader\n",
        "    steps = 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            logits, loss = model(xb, yb)\n",
        "        running_loss += loss.item()\n",
        "        train_loss = running_loss / (loss_counter + 1)\n",
        "        loss_counter += 1\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        steps += 1\n",
        "        if steps % config.gradient_accumulation_steps == 0:\n",
        "            if config.grad_clip != 0.0:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip)\n",
        "\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        del xb, yb, logits, loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    losses = estimate_losses(config, train_loader, val_loader)  # Now we pass val_loader to estimate_losses\n",
        "    val_loss = losses['val']\n",
        "    train_loss = losses['train']\n",
        "    print(f'Val @ Epoch {cur_iter}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}')\n",
        "    wandb.log({\n",
        "        'val_loss': val_loss,\n",
        "        'iter': cur_iter,\n",
        "        'lr': optimizer.param_groups[0]['lr']\n",
        "    })\n",
        "    if val_loss < best_val:\n",
        "        best_val = val_loss\n",
        "        torch.save(model.state_dict(), best_path)\n",
        "        print(f'Saved best model to {best_path}')\n",
        "    print('Sample Generation')\n",
        "    print(tokenizer.decode(model.generate(start_ix, 100)[0].tolist()))\n",
        "\n",
        "    # Log training metrics for current iteration\n",
        "    pbar.set_postfix(loss=\"{:.04f}\".format(train_loss), lr=cur_lr)\n",
        "    pbar.update()\n",
        "\n",
        "    cur_iter += 1  # Increment iteration count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgKbRvnvQLUd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92da5e46-d85f-4f57-8d23-ad0c89204003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!|system|>\n",
            "<|endoftext|>Another highly unusual part of a physique is that you need to guess that the body's characteristics are not the same as the body will. The more than one ton might be less wasted, the stronger the structure in your abdomen. The bones in the fascinator dry up significantly. For once, the pelvic bones, unlike the pelvic bones, are and still are relatively bland with soft material between them. So the Ebay2001 said that new limbs like me must be dissected\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(model.generate(start_ix, 100)[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNo-EkEkQLUd"
      },
      "outputs": [],
      "source": [
        "def generate_text(m, prompt, max_seq=100):\n",
        "    prompt = prompt.strip()\n",
        "\n",
        "    chat_template = f\"<|user|>\\n{' '.join(prompt.split()[:150])}<|endoftext|>\\n<|assistant|>\"\n",
        "    prompt_tokens = tokenizer.encode(chat_template, return_tensors='pt').to(device)\n",
        "\n",
        "    generated_tokens = m.generate(prompt_tokens, max_seq)\n",
        "\n",
        "    generated_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
        "\n",
        "    return generated_text[generated_text.find(\"<|assistant|>\") + len(\"<|assistant|>\"):]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load Evaluate Models\n",
        "\n",
        "base_model = Transformer(config).to(device)\n",
        "base_model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "fine_tuned_model = Transformer(config).to(device)\n",
        "fine_tuned_model.load_state_dict(torch.load('best_fine_tune_model.pth'))\n",
        "\n",
        "tmp = '''\n",
        "(CNN)Share, and your gift will be multiplied. That may sound like an esoteric adage, but when Zully Broussard selflessly decided to give one of her kidneys to a stranger, her generosity paired up with big data. It resulted in six patients receiving transplants. That surprised and wowed her. \"I thought I was going to help this one person who I don't know, but the fact that so many people can have a life extension, that's pretty big,\" Broussard told CNN affiliate KGO. She may feel guided in her generosity by a higher power. \"Thanks for all the support and prayers,\" a comment on a Facebook page in her name read. \"I know this entire journey is much bigger than all of us. I also know I'm just the messenger.\" CNN cannot verify the authenticity of the page. But the power that multiplied Broussard's gift was data processing of genetic profiles from donor-recipient pairs. It works on a simple swapping principle but takes it to a much higher level, according to California Pacific Medical Center in San Francisco. So high, that it is taking five surgeons, a covey of physician assistants, nurses and anesthesiologists, and more than 40 support staff to perform surgeries on 12 people. They are extracting six kidneys from donors and implanting them into six recipients. \"The ages of the donors and recipients range from 26 to 70 and include three parent and child pairs, one sibling pair and one brother and sister-in-law pair,\" the medical center said in a statement. The chain of surgeries is to be wrapped up Friday. In late March, the medical center is planning to hold a reception for all 12 patients. Here's how the super swap works, according to California Pacific Medical Center. Say, your brother needs a kidney to save his life, or at least get off of dialysis, and you're willing to give him one of yours. But then it turns out that your kidney is not a match for him, and it's certain his body would reject it. Your brother can then get on a years-long waiting list for a kidney coming from an organ donor who died. Maybe that will work out -- or not, and time could run out for him. Alternatively, you and your brother could look for another recipient-living donor couple like yourselves -- say, two more siblings, where the donor's kidney isn't suited for his sister, the recipient. But maybe your kidney is a match for his sister, and his kidney is a match for your brother. So, you'd do a swap. That's called a paired donation. It's a bit of a surgical square dance, where four people cross over partners temporarily and everybody goes home smiling. But instead of a square dance, Broussard's generous move set off a chain reaction, like dominoes falling. Her kidney, which was removed Thursday, went to a recipient, who was paired with a donor. That donor's kidney went to the next recipient, who was also paired with a donor, and so on. On Friday, the last donor will give a kidney to someone who has been biding time on one of those deceased donor lists to complete the chain. Such long-chain transplanting is rare. It's been done before, California Pacific Medical Center said in a statement, but matching up the people in the chain has been laborious and taken a long time. That changed when a computer programmer named David Jacobs received a kidney transplant. He had been waiting on a deceased donor list, when a live donor came along -- someone nice enough to give away a kidney to a stranger. Jacobs paid it forward with his programming skills, creating MatchGrid, a program that genetically matches up donor pairs or chains quickly. \"When we did a five-way swap a few years ago, which was one of the largest, it took about three to four months. We did this in about three weeks,\" Jacobs said. But this chain wouldn't have worked so quickly without Broussard's generosity -- or may not have worked at all. \"The significance of the altruistic donor is that it opens up possibilities for pairing compatible donors and recipients,\" said Dr. Steven Katznelson. \"Where there had been only three or four options, with the inclusion of the altruistic donor, we had 140 options to consider for matching donors and recipients.\" And that's divine, Broussard's friend Shirley Williams wrote in a comment her on Broussard's Facebook page. \"You are a true angel my friend.\"\n",
        "'''\n",
        "\n",
        "print(generate_text(base_model, f'Summarize the following CNN article:\\n {tmp}', 50))\n",
        "print(generate_text(fine_tuned_model, f'Summarize the following CNN article:\\n {tmp}', 50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVoeUw6Q1NCv",
        "outputId": "ae63b8d9-5bae-454d-f2d5-64a822393b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Master is a 3D cardboard with removable batteries with an intriguing 3D geometry.\n",
            "\n",
            "Library Background black cells with brown salt in glass that are highly malleable on black paper.\n",
            "\n",
            "Skin colour. Honestly, I made these for several\n",
            "\n",
            "Zully Broussard received kidney for converting Patients' Choice kidney dialysis.\n",
            "She donated thousands in $2,000 sum to the hospital, charities.\n",
            "Broussard's transformation spurred donations and swarms of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluate Summarization\n",
        "\n",
        "def generate_outputs(classifier):\n",
        "  references = []\n",
        "  base_model_outputs = []\n",
        "  fine_tuned_outputs = []\n",
        "\n",
        "  count = 0\n",
        "  for i, row in enumerate(val_dataset):\n",
        "    if (row['Classifier'] != classifier):\n",
        "      continue\n",
        "\n",
        "    output_len = len(tokenizer.encode(row['Target']))\n",
        "    base_model_output = generate_text(base_model, row['Prompt'], output_len)\n",
        "    fine_tuned_model_output = generate_text(fine_tuned_model, row['Prompt'], output_len)\n",
        "\n",
        "    base_model_outputs.append(base_model_output)\n",
        "    fine_tuned_outputs.append(fine_tuned_model_output)\n",
        "    references.append([row['Target']])\n",
        "\n",
        "    # print(output_len)\n",
        "    # print()\n",
        "    # print(\"-------\")\n",
        "    # print(\"Question:\")\n",
        "    # print(row[\"Prompt\"])\n",
        "    # print(\"---Target----\")\n",
        "    # print(row[\"Target\"])\n",
        "    # print(\"---PreTrained----\")\n",
        "    # print(base_model_output)\n",
        "    # print(\"---FineTune----\")\n",
        "    # print(fine_tuned_model_output)\n",
        "    # print(\"-------\")\n",
        "    # print()\n",
        "\n",
        "    # base_model_bleu_score += sentence_bleu(row['Target'].split(), base_model_output.split())\n",
        "    # fine_tuned_bleu_score += sentence_bleu(row['Target'].split(), fine_tuned_model_output.split())\n",
        "\n",
        "    progress_bar.update()\n",
        "\n",
        "    count = count + 1\n",
        "    if count >= 1000:\n",
        "      break\n",
        "\n",
        "  return references, base_model_outputs, fine_tuned_outputs\n",
        "\n",
        "val_dataset = load_dataset(\"ccss4/hw5-finetuning\", split = 'validation')\n",
        "\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "progress_bar = tqdm(total=13368, dynamic_ncols=True, leave=False, position=0, desc='BLEU')\n",
        "refs, base_outputs, fine_tuned_outputs = generate_outputs('Summarization')\n",
        "progress_bar.close()\n",
        "\n",
        "print(\"BLEU score for pretrained model: \\n\", bleu.compute(predictions=base_outputs, references=refs))\n",
        "print(\"BLEU score for fine tuned model: \\n\", bleu.compute(predictions=fine_tuned_outputs, references=refs))"
      ],
      "metadata": {
        "id": "OcefIPvL2BmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluate Q&A\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "progress_bar = tqdm(total=10570, dynamic_ncols=True, leave=False, position=0, desc='ROUGE')\n",
        "refs, base_outputs, fine_tuned_outputs = generate_outputs('Question&Answer')\n",
        "progress_bar.close()\n",
        "\n",
        "\n",
        "print(\"ROUGE score for pretrained model: \\n\", rouge.compute(predictions=base_outputs, references=refs))\n",
        "print(\"ROUGE score for fine tuned model: \\n\", rouge.compute(predictions=fine_tuned_outputs, references=refs))"
      ],
      "metadata": {
        "id": "czEPELNIRNxC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42a9e1f5-c01f-48f0-fc22-5f8321eedad2"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE score for pretrained model: \n",
            " {'rouge1': 0.005884171647359108, 'rouge2': 0.0001719298245614035, 'rougeL': 0.005884673656145294, 'rougeLsum': 0.005785726595892363}\n",
            "ROUGE score for fine tuned model: \n",
            " {'rouge1': 0.05058140485230121, 'rouge2': 0.015982299459023463, 'rougeL': 0.05056974137260489, 'rougeLsum': 0.050600098589418996}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run.finish()"
      ],
      "metadata": {
        "id": "S5nM4aeYPcDP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265,
          "referenced_widgets": [
            "814ace72bca94677915caa433e076467"
          ]
        },
        "outputId": "a71136dd-807d-4fce-f317-739e8ba117cf"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "814ace72bca94677915caa433e076467"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iter</td><td>▁▂▄▅▇█</td></tr><tr><td>lr</td><td>▁▂▄▅▇█</td></tr><tr><td>val_loss</td><td>█▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>iter</td><td>5</td></tr><tr><td>lr</td><td>1e-05</td></tr><tr><td>val_loss</td><td>2.58552</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">pretrain_v1</strong> at: <a href='https://wandb.ai/huayuyang/ideal_gpt/runs/usogig48' target=\"_blank\">https://wandb.ai/huayuyang/ideal_gpt/runs/usogig48</a><br/> View project at: <a href='https://wandb.ai/huayuyang/ideal_gpt' target=\"_blank\">https://wandb.ai/huayuyang/ideal_gpt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240427_223840-usogig48/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}