{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUPM_w4HjJ3U"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "203bvpDsQLUW"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import tiktoken\n",
    "from transformers import GPT2Tokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from torchsummaryX import summary\n",
    "import wandb\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from multiprocessing import cpu_count\n",
    "import random\n",
    "import gc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LovtcItVQLUX"
   },
   "outputs": [],
   "source": [
    "# set seeds\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = False\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_H8zHj2Swll"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68u9am1JSzIX",
    "outputId": "13e957ad-9193-40f8-8423-f2960c9e4f15"
   },
   "outputs": [],
   "source": [
    "datasets_train = load_dataset(\"Shannnh/hw5-changed\", split = 'train')\n",
    "datasets_val = load_dataset(\"Shannnh/hw5-changed\", split = 'validation')\n",
    "datasets_test = load_dataset(\"Shannnh/hw5-changed\", split = 'test_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m40ZM0re8-RR",
    "outputId": "95fcac78-6bd7-4a4e-aa07-301989b5cb47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Classifier', 'Prompt', 'Messages', 'PromptId'])\n",
      "392632\n",
      "27664\n",
      "15434\n"
     ]
    }
   ],
   "source": [
    "print(datasets_train[0].keys())\n",
    "print(len(datasets_train))\n",
    "print(len(datasets_val))\n",
    "print(len(datasets_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets_train = datasets_train.shuffle(seed=42).select(range(100))\n",
    "# datasets_val = datasets_val.shuffle(seed=42).select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Summarization', 'Question&Answer', 'SentimentAnalysis', 'NamedEntity']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_train.unique('Classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-849v2wQQLUX"
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Prz8c1bYQLUY",
    "outputId": "00ae83ef-d32f-4dc3-c3a2-5e955407869c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IDeaLGPTConfig(batch_size=16, gradient_accumulation_steps=4, num_iters=10000, eval_iters=3, eval_interval=1000, device='cuda', finetune_epochs=3, sequence_length=256, vocab_size=50257, num_blocks=8, num_heads=8, embed_dim=512, dropout=0.1, bias=False, num_workers=8, train_test_split=0.8, SUBSET_PERCENTAGE=0.01, lr=0.002, lr_decay=True, warmup_iters=1000, min_lr=6e-06, finetune_lr=0.0001, weight_decay=0.1, grad_clip=1.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass\n",
    "class IDeaLGPTConfig:\n",
    "\n",
    "    # General\n",
    "    batch_size: int = 16 # 16\n",
    "    gradient_accumulation_steps: int = 4\n",
    "    num_iters: int = 10000\n",
    "    eval_iters: int = 3\n",
    "    eval_interval: int = 1000\n",
    "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    finetune_epochs: int = 3\n",
    "    # device: str = 'cpu'\n",
    "\n",
    "    # Model\n",
    "    sequence_length: int = 256\n",
    "    vocab_size: int = 50257 # gpt2 vocab\n",
    "    num_blocks: int = 8\n",
    "    num_heads: int = 8\n",
    "    embed_dim: int = 512\n",
    "    dropout: float = 0.1\n",
    "    bias: bool = False\n",
    "\n",
    "    # Data\n",
    "    num_workers: int = 8\n",
    "    train_test_split: float = 0.8\n",
    "    SUBSET_PERCENTAGE: float =0.01 # % of OWT to train on, between 0 and 1\n",
    "\n",
    "    # LR scheduler\n",
    "    lr: float = 2e-3\n",
    "    lr_decay: bool = True\n",
    "    warmup_iters: int = 1000\n",
    "    min_lr: float = 6e-6\n",
    "\n",
    "    finetune_lr: float = 1e-4\n",
    "\n",
    "    # optimizer\n",
    "    weight_decay: float = 1e-1\n",
    "    grad_clip: float = 1.0\n",
    "\n",
    "\n",
    "config = IDeaLGPTConfig()\n",
    "device = config.device\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4IkXs4hTQLUZ",
    "outputId": "1bb56acf-d9c3-4420-f94e-8d5db87cad31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective batch size = 64\n"
     ]
    }
   ],
   "source": [
    "print(f'Effective batch size = {config.batch_size * config.gradient_accumulation_steps}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6FXk8H1QLUZ"
   },
   "source": [
    "# Loading Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FF87zNglQLUZ"
   },
   "outputs": [],
   "source": [
    "# hf_dataset = load_dataset(\"Skylion007/openwebtext\", split='train') # only has one split - train\n",
    "# hf_dataset = hf_dataset.with_format(\"torch\")\n",
    "# hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Z-UOmFJFQLUZ"
   },
   "outputs": [],
   "source": [
    "# # data = dataset['train'].shuffle(seed=42).select(range(int(len(dataset['train']) * SUBSET_PERCENTAGE)))\n",
    "# # hf_dataset = hf_dataset.select(range(int(len(hf_dataset) * config.SUBSET_PERCENTAGE)))\n",
    "# hf_dataset = hf_dataset.train_test_split(train_size=config.train_test_split)\n",
    "# hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0DljsEgbQLUZ"
   },
   "outputs": [],
   "source": [
    "# train_hf_dataset, val_hf_dataset = hf_dataset['train'], hf_dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bKU7Y-6QLUZ"
   },
   "source": [
    "## Tokenizer - OpenAI tiktoken (changed to GPT2Tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvwoPFbiQLUZ",
    "outputId": "9752f1ea-9efb-41ca-99ec-76c867ba2dd5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31373, 995]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenizer = tiktoken.get_encoding(\"cl100k_base\") # gpt4 tokenizer - NOTE: need to change vocab_size in config if used\n",
    "#tokenizer = tiktoken.encoding_for_model('gpt-2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.encode('hello world')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bsUdOVMmjFJ1"
   },
   "outputs": [],
   "source": [
    "tokenizer.model_max_length = config.sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "h_0F5g1T81XC"
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OAqwxz2xzasy",
    "outputId": "dd2b680a-7b13-490f-f283-18e1d720fa34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = tokenizer.vocab_size #same as tiktoken\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "lFDoKw26tevh"
   },
   "outputs": [],
   "source": [
    "# set pad_token_id equal to the eos_token_id if not set\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZcD3xq9d1PvS"
   },
   "outputs": [],
   "source": [
    "DEFAULT_CHAT_TEMPLATE = \"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + ' '.join(message['content'].split()[:150]) + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\"\n",
    "# DEFAULT_CHAT_TEMPLATE = \"{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + ' '.join(message['content'].split()[:150]) + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\"\n",
    "\n",
    "tokenizer.chat_template = DEFAULT_CHAT_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'abcdefd'.find('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "642e89fcada04c16a34b469b21bf80c7",
      "66a71622ed53488ebabc61778e624b96",
      "abf72b3336b14d82b59cfc42b91f4f41",
      "067898ad433a455e8deb863494b7a428",
      "2719a96cddd74b32870d18f31f4ad293",
      "b7403d3083e740208a18888a170f975e",
      "64ff9a51f7264cb68d848f111b0e6857",
      "307746d700d34a94b2a5d2612ff2efb0",
      "024d4f026f184760a2f3b4eb2c624a95",
      "e0d25851a01942868ce5d5e4d76ad284",
      "12257421e51e4a7a916880b5fb690d90"
     ]
    },
    "id": "MbRQjaafylLA",
    "outputId": "dbea003d-9430-4b00-be64-2f72ba56189d"
   },
   "outputs": [],
   "source": [
    "def apply_chat_template(example, tokenizer):\n",
    "    messages = example[\"Messages\"]\n",
    "    #\n",
    "    example[\"text\"] = tokenizer.apply_chat_template(messages, tokenize=False, max_length=config.sequence_length, truncation=True)\n",
    "    example[\"tokens\"] = tokenizer.apply_chat_template(messages, tokenize=True, max_length=config.sequence_length, truncation=True)\n",
    "    return example\n",
    "\n",
    "column_names = list(datasets_train.features)\n",
    "# datasets_train = datasets_train.map(apply_chat_template,\n",
    "#                                 num_proc=8,\n",
    "#                                 fn_kwargs={\"tokenizer\": tokenizer},\n",
    "#                                 remove_columns=column_names,\n",
    "#                                 desc=\"Applying chat template\")\n",
    "datasets_val = datasets_val.map(apply_chat_template,\n",
    "                                num_proc=8,\n",
    "                                fn_kwargs={\"tokenizer\": tokenizer},\n",
    "                                remove_columns=column_names,\n",
    "                                desc=\"Applying chat template\")\n",
    "datasets_test = datasets_test.map(apply_chat_template,\n",
    "                                num_proc=8,\n",
    "                                fn_kwargs={\"tokenizer\": tokenizer},\n",
    "                                remove_columns=column_names,\n",
    "                                desc=\"Applying chat template\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don't think I'll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he'll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I'll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe's earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say 'kid star goes off the rails,'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter's latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer's \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he's legally an adult: \"I just think I'm going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "rPgMqZiO4bae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 13746 of the processed training set:\n",
      "\n",
      "<|system|>\n",
      "<|endoftext|>\n",
      "<|user|>\n",
      "Super_Bowl_50 With Rivera having been a linebacker with the Chicago Bears in Super Bowl XX, and Kubiak replacing Elway at the end of the Broncos' defeats in Super Bowls XXI and XXIV, this will be the first Super Bowl in which both head coaches played in the game themselves. In what Super Bowl did Rivera play?<|endoftext|>\n",
      "<|assistant|>\n",
      "Super Bowl XX,Super Bowl XX,XX<|endoftext|>\n",
      "\n",
      "sample length: 416\n",
      "token length:105\n",
      "Sample 7223 of the processed training set:\n",
      "\n",
      "<|system|>\n",
      "<|endoftext|>\n",
      "<|user|>\n",
      "Summarize the following CNN article: Ben Cohen's mother-in-law is due in court after allegedly harassing the former rugby player following his split from her daughter. Felicity Bassouls, 67, was outspoken in her criticism of Cohen - labelling him a 'disrespectful bully' - after he broke up with Abby late last year amid rumours of an affair with his Strictly Come Dancing partner Kristina Rihanoff. The athlete and activist, who was part of England's 2003 World Cup winning squad, had been married to Abby for 11 years and the couple have twin daughters. Scroll down for video . Due in court: Felicity Bassouls (left), 67, labelled Cohen (right) a 'disrespectful bully' when he split with her daughter Abby late last year . Rumour: Rihanoff (pictured) and Cohen both vehemently deny that any sort of romantic relationship took place . Mrs Bassouls is due in court this month accused of bombarding Cohen<|endoftext|>\n",
      "<|assistant|>\n",
      "Felicity Bassouls to appear in court this month charged with harassment .\n",
      "She is alleged to have bombarded Cohen with calls and emails last year .\n",
      "In September, her daughter Abby's marriage to the rugby star ended .\n",
      "He denied rumours split was linked to Strictly co-star Kristina Rihanoff .<|endoftext|>\n",
      "\n",
      "sample length: 1269\n",
      "token length:256\n"
     ]
    }
   ],
   "source": [
    "# what's in datasets now\n",
    "# datasets_train : [{'text':'abcd','tokens':[1,2,3]},{'text':'bcd','tokens':[2,3]},...]\n",
    "for index in random.sample(range(len(datasets_val)), 2):\n",
    "    print(f\"Sample {index} of the processed training set:\\n\\n{datasets_val[index]['text']}\")\n",
    "    # print(f\"token: {datasets_val[index]['tokens']}\")\n",
    "    print(f\"sample length: {len(datasets_val[index]['text'])}\") \n",
    "    print(f\"token length:{len(datasets_val[index]['tokens'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_token_length = 0\n",
    "# sample_count = len(datasets_train)\n",
    "\n",
    "# # Calculate total token length across all samples\n",
    "# for data in tqdm(datasets_train):\n",
    "#     encoded_length = len(tokenizer.encode(data['text']))\n",
    "#     total_token_length += encoded_length\n",
    "\n",
    "# # Compute the average token length\n",
    "# average_token_length = total_token_length / sample_count\n",
    "\n",
    "# print(f\"Average token length: {average_token_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "jg0MOKomarrU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "hrfc-IpwOrFY"
   },
   "outputs": [],
   "source": [
    "# # save dataset\n",
    "\n",
    "# def save_dataset(dataset, filename):\n",
    "#     with open(filename, 'wb') as f:\n",
    "#         pickle.dump(dataset, f)\n",
    "# save_dataset(datasets_train, 'data/finetune/train.bin')\n",
    "# save_dataset(datasets_val, 'data/finetune/val.bin')\n",
    "# save_dataset(datasets_test, 'data/finetune/test.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AghJe4bCQLUa"
   },
   "source": [
    "## Pytorch Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFzA_Ake41t5"
   },
   "source": [
    "For long texts, the current approach randomly selects segments of text that are equal to config.sequence_length. However, methods such as sliding windows could also be explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "sTYPPcyx6OtP"
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, root_dir, split):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Dataset root directory containing the data files.\n",
    "        \"\"\"\n",
    "        file_path = os.path.join(root_dir, \"train.bin\") if split == 'train' else os.path.join(root_dir, \"val.bin\")\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        tokens = sample['tokens']\n",
    "        # if the number of tokens is more than the sequence_length, randomly choose a segment\n",
    "        # if len(tokens) > config.sequence_length + 1:\n",
    "        #     num_possible_starts = len(tokens) - config.sequence_length\n",
    "        #     start = random.randint(0, num_possible_starts - 1)\n",
    "        #     segment = tokens[start:start + self.sequence_length + 1]\n",
    "        # else:\n",
    "        #     segment = tokens\n",
    "\n",
    "        if len(tokens) < config.sequence_length + 1:\n",
    "            padded_tokens = np.pad(tokens, (0, config.sequence_length + 1 - len(tokens)), 'constant', constant_values=tokenizer.pad_token_id)\n",
    "        else:\n",
    "            padded_tokens = tokens[:config.sequence_length + 1]\n",
    "\n",
    "        xb = torch.tensor(padded_tokens[:-1], dtype=torch.int64)\n",
    "        yb = torch.tensor(padded_tokens[1:], dtype=torch.int64)\n",
    "        return xb, yb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "XQJEY7Ye_v9t",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# class TestDataset(Dataset):\n",
    "#     def __init__(self, root_dir):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             root_dir (str): Dataset root directory containing the data files.\n",
    "#         \"\"\"\n",
    "#         file_path = os.path.join(root_dir, \"test.bin\")\n",
    "#         with open(file_path, 'rb') as f:\n",
    "#             data = pickle.load(f)\n",
    "#         self.data = data\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         sample = self.data[idx]\n",
    "#         tokens = sample['tokens']\n",
    "#         # if len(tokens) > config.sequence_length + 1:\n",
    "#         #     num_possible_starts = len(tokens) - config.sequence_length\n",
    "#         #     start = random.randint(0, num_possible_starts - 1)\n",
    "#         #     segment = tokens[start:start + config.sequence_length + 1]\n",
    "#         # else:\n",
    "#         #     segment = tokens\n",
    "#         if len(tokens) < config.sequence_length + 1:\n",
    "#             padded_tokens = np.pad(tokens, (0, config.sequence_length + 1 - len(tokens)), 'constant', constant_values=tokenizer.pad_token_id)\n",
    "#         else:\n",
    "#             padded_tokens = tokens[:config.sequence_length + 1]\n",
    "\n",
    "#         xb = torch.tensor(padded_tokens[:-1], dtype=torch.int64)\n",
    "#         return xb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3HIbJmBQLUa"
   },
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "y8HvMPG8QLUa"
   },
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=1)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "zI90SEqFQLUb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for x, y in train_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "q5oYgzrkQLUb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# poor man's dataloader\\n# but actual motivation is - im too lazy to write and deal with pad tokens in above method to read data\\n# since there are documents which are less than sequence length and they mess up the batch\\n# this method is cleaner, i get to learn something new (np.memmap!) and it's fun!\\n\\ndata_dir = os.path.join('data', 'owt')\\n\\ndef get_batch(split):\\n    file_path = os.path.join(data_dir, 'val' if split == 'val.bin' else 'train.bin')\\n    # memmap allows to read huge .bin files without loading entire thing. magic?\\n    data = np.memmap(file_path, mode='r', dtype=np.uint16) # fp16?\\n    idx = torch.randint(len(data) - config.sequence_length, (config.batch_size, ))\\n    xb = torch.stack([torch.from_numpy(data[i:i+config.sequence_length].astype(np.int64)) for i in idx], dim=0)\\n    yb = torch.stack([torch.from_numpy(data[i+1:i+config.sequence_length+1].astype(np.int64)) for i in idx], dim=0)\\n    if device == 'cuda':\\n        # pin_memory is an optimization to reserve some space in cpu mem which is used for moving to gpu\\n        # reduces overhead -> increases perf\\n        # non_blocking = True is async data transfer\\n        xb, yb = xb.pin_memory().to(device, non_blocking=True), yb.pin_memory().to(device, non_blocking=True)\\n    return xb, yb\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# poor man's dataloader\n",
    "# but actual motivation is - im too lazy to write and deal with pad tokens in above method to read data\n",
    "# since there are documents which are less than sequence length and they mess up the batch\n",
    "# this method is cleaner, i get to learn something new (np.memmap!) and it's fun!\n",
    "\n",
    "data_dir = os.path.join('data', 'owt')\n",
    "\n",
    "def get_batch(split):\n",
    "    file_path = os.path.join(data_dir, 'val' if split == 'val.bin' else 'train.bin')\n",
    "    # memmap allows to read huge .bin files without loading entire thing. magic?\n",
    "    data = np.memmap(file_path, mode='r', dtype=np.uint16) # fp16?\n",
    "    idx = torch.randint(len(data) - config.sequence_length, (config.batch_size, ))\n",
    "    xb = torch.stack([torch.from_numpy(data[i:i+config.sequence_length].astype(np.int64)) for i in idx], dim=0)\n",
    "    yb = torch.stack([torch.from_numpy(data[i+1:i+config.sequence_length+1].astype(np.int64)) for i in idx], dim=0)\n",
    "    if device == 'cuda':\n",
    "        # pin_memory is an optimization to reserve some space in cpu mem which is used for moving to gpu\n",
    "        # reduces overhead -> increases perf\n",
    "        # non_blocking = True is async data transfer\n",
    "        xb, yb = xb.pin_memory().to(device, non_blocking=True), yb.pin_memory().to(device, non_blocking=True)\n",
    "    return xb, yb\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "DXmyEb8b9PyQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "DATA_DIR        = 'data/finetune'\n",
    "\n",
    "train_dataset   = TrainDataset(\n",
    "    root_dir    = DATA_DIR,\n",
    "    split   = \"train\"\n",
    ")\n",
    "\n",
    "val_dataset     = TrainDataset(\n",
    "    root_dir    = DATA_DIR,\n",
    "    split   = \"val\"\n",
    ")\n",
    "\n",
    "# test_dataset    = TestDataset(\n",
    "#     root_dir    = DATA_DIR\n",
    "# )\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256]), torch.Size([256]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = train_dataset[0]\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "1itLTzKtB7e-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size           :  16\n",
      "Train Batches        :  24540\n",
      "Val Batches          :  1729\n"
     ]
    }
   ],
   "source": [
    "train_loader    = torch.utils.data.DataLoader(\n",
    "    dataset     = train_dataset,\n",
    "    batch_size  = config.batch_size,\n",
    "    shuffle     = True,\n",
    "    num_workers = 2,\n",
    "    pin_memory  = True\n",
    ")\n",
    "\n",
    "val_loader      = torch.utils.data.DataLoader(\n",
    "    dataset     = val_dataset,\n",
    "    batch_size  = config.batch_size,\n",
    "    shuffle     = False,\n",
    "    num_workers = 1,\n",
    "    pin_memory  = True\n",
    ")\n",
    "\n",
    "# test_loader     = torch.utils.data.DataLoader(\n",
    "#     dataset     = test_dataset,\n",
    "#     batch_size  = config.batch_size,\n",
    "#     shuffle     = False,\n",
    "#     num_workers = 1,\n",
    "#     pin_memory  = True\n",
    "# )\n",
    "\n",
    "print(\"Batch Size           : \", config.batch_size)\n",
    "print(\"Train Batches        : \", train_loader.__len__())\n",
    "print(\"Val Batches          : \", val_loader.__len__())\n",
    "# print(\"Test Batches         : \", test_loader.__len__())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "VIYb0gtYFenJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Shapes of the Data --\n",
      "\n",
      "xb shape:\t\ttorch.Size([16, 256])\n",
      "yb shape:\t\ttorch.Size([16, 256])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' Sanity Check '''\n",
    "\n",
    "print(\"Checking the Shapes of the Data --\\n\")\n",
    "\n",
    "for batch in train_loader:\n",
    "    xb, yb = batch\n",
    "\n",
    "    print(f\"xb shape:\\t\\t{xb.shape}\")\n",
    "    print(f\"yb shape:\\t\\t{yb.shape}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "1mmd9hflKQjF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata_dir = '/content/hw5/'\\ndef get_batch(split):\\n    file_path = os.path.join(data_dir, 'val.bin' if split == 'val' else 'train.bin')\\n\\n\\n    with open(file_path, 'rb') as f:\\n        data = pickle.load(f)\\n\\n    xb = torch.empty((config.batch_size, config.sequence_length), dtype=torch.int64)\\n    yb = torch.empty((config.batch_size, config.sequence_length), dtype=torch.int64)\\n\\n    for b in range(config.batch_size):\\n        tokens = data[b]['tokens']\\n        if len(tokens) < config.sequence_length:\\n            padded_tokens = np.pad(tokens, (0, config.sequence_length - len(tokens)), 'constant', constant_values=tokenizer.pad_token_id)\\n        else:\\n            padded_tokens = tokens[:config.sequence_length]\\n\\n\\n        xb[b] = torch.tensor(padded_tokens[:-1], dtype=torch.int64)\\n        yb[b] = torch.tensor(padded_tokens[1:], dtype=torch.int64)\\n\\n    if device == 'cuda':\\n        xb, yb = xb.pin_memory().to(device, non_blocking=True), yb.pin_memory().to(device, non_blocking=True)\\n\\n    return xb, yb\\n\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I tried it, but failed.QAQ. It seems that using np.memmap requires synchronously recording the length of each data entry, which makes padding inconvenient.\n",
    "'''\n",
    "data_dir = '/content/hw5/'\n",
    "def get_batch(split):\n",
    "    file_path = os.path.join(data_dir, 'val.bin' if split == 'val' else 'train.bin')\n",
    "\n",
    "\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    xb = torch.empty((config.batch_size, config.sequence_length), dtype=torch.int64)\n",
    "    yb = torch.empty((config.batch_size, config.sequence_length), dtype=torch.int64)\n",
    "\n",
    "    for b in range(config.batch_size):\n",
    "        tokens = data[b]['tokens']\n",
    "        if len(tokens) < config.sequence_length:\n",
    "            padded_tokens = np.pad(tokens, (0, config.sequence_length - len(tokens)), 'constant', constant_values=tokenizer.pad_token_id)\n",
    "        else:\n",
    "            padded_tokens = tokens[:config.sequence_length]\n",
    "\n",
    "\n",
    "        xb[b] = torch.tensor(padded_tokens[:-1], dtype=torch.int64)\n",
    "        yb[b] = torch.tensor(padded_tokens[1:], dtype=torch.int64)\n",
    "\n",
    "    if device == 'cuda':\n",
    "        xb, yb = xb.pin_memory().to(device, non_blocking=True), yb.pin_memory().to(device, non_blocking=True)\n",
    "\n",
    "    return xb, yb\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQ3b6b23QLUb"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "FsZa23FJQLUb"
   },
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    # def __init__(self, embed_dim, head_size, sequence_length, dropout):\n",
    "    def __init__(self, config, interim_head_size):\n",
    "        super().__init__()\n",
    "        self.embed_dim = config.embed_dim\n",
    "        self.interim_head_size = interim_head_size # say embed_dim = 32 -> broken into say 4 heads, so this will be 8, to be concated back to 32\n",
    "        self.key = nn.Linear(config.embed_dim, interim_head_size, bias=config.bias)\n",
    "        self.query = nn.Linear(config.embed_dim, interim_head_size, bias=config.bias)\n",
    "        self.value = nn.Linear(config.embed_dim, interim_head_size, bias=config.bias)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones((config.sequence_length, config.sequence_length))))\n",
    "\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x) # (b,t,c) -> (b,t,h)\n",
    "        q = self.query(x) # (b,t,c) -> (b,t,h)\n",
    "        v = self.value(x) # (b,t,c) -> (b,t,h)\n",
    "        wei = k @ q.transpose(-2, -1) * self.embed_dim**(-0.5) # (b,t,h) @ (b,h,t) -> (b,t,t)\n",
    "\n",
    "        wei = wei.masked_fill((self.tril[:T, :T] == 0.), -torch.inf) # type: ignore\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        xbow = wei @ v # (b,t,t) @ (b,t,h) -> (b,t,h)\n",
    "        return xbow\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    # def __init__(self, num_heads, embed_dim, head_size, sequence_length, dropout):\n",
    "    def __init__(self, config, interim_head_size):\n",
    "        super().__init__()\n",
    "        self.head_list = nn.ModuleList([Head(config, interim_head_size) for _ in range(config.num_heads)])\n",
    "        self.proj = nn.Linear(config.embed_dim, config.embed_dim)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.head_list], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(config.embed_dim, 4*config.embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4*config.embed_dim, config.embed_dim),\n",
    "            nn.Dropout(config.dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    # def __init__(self, num_heads, embed_dim, sequence_length, dropout):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.interim_head_size = config.embed_dim // config.num_heads\n",
    "        self.sa = MultiHeadAttention(config, self.interim_head_size)\n",
    "        self.ff = FeedForward(config)\n",
    "        self.ln1 = nn.LayerNorm(config.embed_dim)\n",
    "        self.ln2 = nn.LayerNorm(config.embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x)) # communication\n",
    "        x = x + self.ff(self.ln2(x)) # computation\n",
    "        return x\n",
    "\n",
    "\n",
    "class Transformer(torch.nn.Module):\n",
    "    # def __init__(self, embed_dim, vocab_size, sequence_length, num_heads, num_blocks, dropout):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.sequence_length = config.sequence_length\n",
    "        self.token_embeddings = torch.nn.Embedding(config.vocab_size, config.embed_dim)\n",
    "        self.position_embeddings = nn.Embedding(config.sequence_length, config.embed_dim)\n",
    "        self.block_list = nn.Sequential(*[Block(config)\n",
    "                                          for _ in range(config.num_blocks)])\n",
    "        self.final_ln = nn.LayerNorm(config.embed_dim)\n",
    "        self.lm_head = nn.Linear(config.embed_dim, config.vocab_size)\n",
    "\n",
    "    def forward(self, ixs, targets=None):\n",
    "        # ixs: (b,t)\n",
    "        # targets: (b,t)\n",
    "        B, T = ixs.shape\n",
    "        x = self.token_embeddings(ixs) # (b,t,c=embed_dim)\n",
    "        pos_embeds = self.position_embeddings(torch.arange(T, device=device)) # (t,c=embed_dim)\n",
    "        x += pos_embeds\n",
    "        x = self.block_list(x)\n",
    "        x = self.final_ln(x)\n",
    "        logits = self.lm_head(x) # (b,t,c=vocab_size)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            mask = (ixs != tokenizer.pad_token_id)  # (b,t), True where not a pad token\n",
    "            logits = logits.permute(0, 2, 1)  # (b,c,t)\n",
    "    \n",
    "            # Use the mask to filter out loss on padding positions\n",
    "            # logits are now (b, c, t), targets are (b, t), mask is (b, t)\n",
    "            # Utilizing .masked_fill to turn pad positions to a very large negative value to ignore them in softmax\n",
    "            loss = F.cross_entropy(logits, targets, reduction='none')  # (b, t) get loss per token\n",
    "            loss = (loss * mask).sum() / mask.sum()  # average loss only over non-pad tokens\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, ixs, max_len):\n",
    "        \"\"\"\n",
    "        ixs: (b,t) - input sequence to start generating from\n",
    "        max_len: int - maximum length of the generated sequence\n",
    "        \"\"\"\n",
    "        b, t = ixs.shape\n",
    "        for _ in range(max_len):\n",
    "            # generation (b, ) next tokens in parallel\n",
    "            ixs_cond = ixs[:, -self.sequence_length:] # consider only the last sequence_length tokens\n",
    "            logits, loss = self.forward(ixs_cond) # logits=(b,t,c), loss is ignored\n",
    "            # get juse the final timestep\n",
    "            last_logits = logits[:, -1, :] # (b,c)\n",
    "            # normalize\n",
    "            last_probs = F.softmax(last_logits, dim=-1) # across c\n",
    "            next_tokens = torch.multinomial(last_probs, 1) # (b,c) -> (b)\n",
    "            ixs = torch.cat((ixs, next_tokens), dim=1) # across t so (b,t) -> (b, t+1)\n",
    "        return ixs\n",
    "\n",
    "    def generate_prompt(self, ixs, max_len):\n",
    "        \"\"\"\n",
    "        ixs: (1,t) - input sequence to start generating from\n",
    "        max_len: int - maximum length of the generated sequence\n",
    "        \"\"\"\n",
    "        b, t = ixs.shape\n",
    "        for _ in range(max_len):\n",
    "            ixs_cond = ixs[:, -self.sequence_length:] # consider only the last sequence_length tokens\n",
    "            logits, loss = self.forward(ixs_cond) # logits=(b,t,c), loss is ignored\n",
    "            # get juse the final timestep\n",
    "            last_logits = logits[:, -1, :] # (1,c)\n",
    "            # normalize\n",
    "            last_probs = F.softmax(last_logits, dim=-1) # across c\n",
    "            next_tokens = torch.multinomial(last_probs, 1) # (b,c) -> (1)\n",
    "            print(next_tokens)\n",
    "            ixs = torch.cat((ixs, next_tokens), dim=1) # across t so (b,t) -> (b, t+1)\n",
    "        return ixs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mlj4sY57QLUb"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "uM9xrNVCQLUb"
   },
   "outputs": [],
   "source": [
    "# model = Transformer(embed_dim, vocab_size, sequence_length, num_heads, num_blocks, dropout).to(device)\n",
    "model = Transformer(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "RXZIOVpRQLUc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================================================\n",
      "                                                 Kernel Shape  \\\n",
      "Layer                                                           \n",
      "0_token_embeddings                               [512, 50257]   \n",
      "1_position_embeddings                              [512, 256]   \n",
      "2_block_list.0.LayerNorm_ln1                            [512]   \n",
      "3_block_list.0.sa.head_list.0.Linear_key            [512, 64]   \n",
      "4_block_list.0.sa.head_list.0.Linear_query          [512, 64]   \n",
      "5_block_list.0.sa.head_list.0.Linear_value          [512, 64]   \n",
      "6_block_list.0.sa.head_list.0.Dropout_dropout               -   \n",
      "7_block_list.0.sa.head_list.1.Linear_key            [512, 64]   \n",
      "8_block_list.0.sa.head_list.1.Linear_query          [512, 64]   \n",
      "9_block_list.0.sa.head_list.1.Linear_value          [512, 64]   \n",
      "10_block_list.0.sa.head_list.1.Dropout_dropout              -   \n",
      "11_block_list.0.sa.head_list.2.Linear_key           [512, 64]   \n",
      "12_block_list.0.sa.head_list.2.Linear_query         [512, 64]   \n",
      "13_block_list.0.sa.head_list.2.Linear_value         [512, 64]   \n",
      "14_block_list.0.sa.head_list.2.Dropout_dropout              -   \n",
      "15_block_list.0.sa.head_list.3.Linear_key           [512, 64]   \n",
      "16_block_list.0.sa.head_list.3.Linear_query         [512, 64]   \n",
      "17_block_list.0.sa.head_list.3.Linear_value         [512, 64]   \n",
      "18_block_list.0.sa.head_list.3.Dropout_dropout              -   \n",
      "19_block_list.0.sa.head_list.4.Linear_key           [512, 64]   \n",
      "20_block_list.0.sa.head_list.4.Linear_query         [512, 64]   \n",
      "21_block_list.0.sa.head_list.4.Linear_value         [512, 64]   \n",
      "22_block_list.0.sa.head_list.4.Dropout_dropout              -   \n",
      "23_block_list.0.sa.head_list.5.Linear_key           [512, 64]   \n",
      "24_block_list.0.sa.head_list.5.Linear_query         [512, 64]   \n",
      "25_block_list.0.sa.head_list.5.Linear_value         [512, 64]   \n",
      "26_block_list.0.sa.head_list.5.Dropout_dropout              -   \n",
      "27_block_list.0.sa.head_list.6.Linear_key           [512, 64]   \n",
      "28_block_list.0.sa.head_list.6.Linear_query         [512, 64]   \n",
      "29_block_list.0.sa.head_list.6.Linear_value         [512, 64]   \n",
      "30_block_list.0.sa.head_list.6.Dropout_dropout              -   \n",
      "31_block_list.0.sa.head_list.7.Linear_key           [512, 64]   \n",
      "32_block_list.0.sa.head_list.7.Linear_query         [512, 64]   \n",
      "33_block_list.0.sa.head_list.7.Linear_value         [512, 64]   \n",
      "34_block_list.0.sa.head_list.7.Dropout_dropout              -   \n",
      "35_block_list.0.sa.Linear_proj                     [512, 512]   \n",
      "36_block_list.0.sa.Dropout_dropout                          -   \n",
      "37_block_list.0.LayerNorm_ln2                           [512]   \n",
      "38_block_list.0.ff.layers.Linear_0                [512, 2048]   \n",
      "39_block_list.0.ff.layers.GELU_1                            -   \n",
      "40_block_list.0.ff.layers.Linear_2                [2048, 512]   \n",
      "41_block_list.0.ff.layers.Dropout_3                         -   \n",
      "42_block_list.1.LayerNorm_ln1                           [512]   \n",
      "43_block_list.1.sa.head_list.0.Linear_key           [512, 64]   \n",
      "44_block_list.1.sa.head_list.0.Linear_query         [512, 64]   \n",
      "45_block_list.1.sa.head_list.0.Linear_value         [512, 64]   \n",
      "46_block_list.1.sa.head_list.0.Dropout_dropout              -   \n",
      "47_block_list.1.sa.head_list.1.Linear_key           [512, 64]   \n",
      "48_block_list.1.sa.head_list.1.Linear_query         [512, 64]   \n",
      "49_block_list.1.sa.head_list.1.Linear_value         [512, 64]   \n",
      "50_block_list.1.sa.head_list.1.Dropout_dropout              -   \n",
      "51_block_list.1.sa.head_list.2.Linear_key           [512, 64]   \n",
      "52_block_list.1.sa.head_list.2.Linear_query         [512, 64]   \n",
      "53_block_list.1.sa.head_list.2.Linear_value         [512, 64]   \n",
      "54_block_list.1.sa.head_list.2.Dropout_dropout              -   \n",
      "55_block_list.1.sa.head_list.3.Linear_key           [512, 64]   \n",
      "56_block_list.1.sa.head_list.3.Linear_query         [512, 64]   \n",
      "57_block_list.1.sa.head_list.3.Linear_value         [512, 64]   \n",
      "58_block_list.1.sa.head_list.3.Dropout_dropout              -   \n",
      "59_block_list.1.sa.head_list.4.Linear_key           [512, 64]   \n",
      "60_block_list.1.sa.head_list.4.Linear_query         [512, 64]   \n",
      "61_block_list.1.sa.head_list.4.Linear_value         [512, 64]   \n",
      "62_block_list.1.sa.head_list.4.Dropout_dropout              -   \n",
      "63_block_list.1.sa.head_list.5.Linear_key           [512, 64]   \n",
      "64_block_list.1.sa.head_list.5.Linear_query         [512, 64]   \n",
      "65_block_list.1.sa.head_list.5.Linear_value         [512, 64]   \n",
      "66_block_list.1.sa.head_list.5.Dropout_dropout              -   \n",
      "67_block_list.1.sa.head_list.6.Linear_key           [512, 64]   \n",
      "68_block_list.1.sa.head_list.6.Linear_query         [512, 64]   \n",
      "69_block_list.1.sa.head_list.6.Linear_value         [512, 64]   \n",
      "70_block_list.1.sa.head_list.6.Dropout_dropout              -   \n",
      "71_block_list.1.sa.head_list.7.Linear_key           [512, 64]   \n",
      "72_block_list.1.sa.head_list.7.Linear_query         [512, 64]   \n",
      "73_block_list.1.sa.head_list.7.Linear_value         [512, 64]   \n",
      "74_block_list.1.sa.head_list.7.Dropout_dropout              -   \n",
      "75_block_list.1.sa.Linear_proj                     [512, 512]   \n",
      "76_block_list.1.sa.Dropout_dropout                          -   \n",
      "77_block_list.1.LayerNorm_ln2                           [512]   \n",
      "78_block_list.1.ff.layers.Linear_0                [512, 2048]   \n",
      "79_block_list.1.ff.layers.GELU_1                            -   \n",
      "80_block_list.1.ff.layers.Linear_2                [2048, 512]   \n",
      "81_block_list.1.ff.layers.Dropout_3                         -   \n",
      "82_block_list.2.LayerNorm_ln1                           [512]   \n",
      "83_block_list.2.sa.head_list.0.Linear_key           [512, 64]   \n",
      "84_block_list.2.sa.head_list.0.Linear_query         [512, 64]   \n",
      "85_block_list.2.sa.head_list.0.Linear_value         [512, 64]   \n",
      "86_block_list.2.sa.head_list.0.Dropout_dropout              -   \n",
      "87_block_list.2.sa.head_list.1.Linear_key           [512, 64]   \n",
      "88_block_list.2.sa.head_list.1.Linear_query         [512, 64]   \n",
      "89_block_list.2.sa.head_list.1.Linear_value         [512, 64]   \n",
      "90_block_list.2.sa.head_list.1.Dropout_dropout              -   \n",
      "91_block_list.2.sa.head_list.2.Linear_key           [512, 64]   \n",
      "92_block_list.2.sa.head_list.2.Linear_query         [512, 64]   \n",
      "93_block_list.2.sa.head_list.2.Linear_value         [512, 64]   \n",
      "94_block_list.2.sa.head_list.2.Dropout_dropout              -   \n",
      "95_block_list.2.sa.head_list.3.Linear_key           [512, 64]   \n",
      "96_block_list.2.sa.head_list.3.Linear_query         [512, 64]   \n",
      "97_block_list.2.sa.head_list.3.Linear_value         [512, 64]   \n",
      "98_block_list.2.sa.head_list.3.Dropout_dropout              -   \n",
      "99_block_list.2.sa.head_list.4.Linear_key           [512, 64]   \n",
      "100_block_list.2.sa.head_list.4.Linear_query        [512, 64]   \n",
      "101_block_list.2.sa.head_list.4.Linear_value        [512, 64]   \n",
      "102_block_list.2.sa.head_list.4.Dropout_dropout             -   \n",
      "103_block_list.2.sa.head_list.5.Linear_key          [512, 64]   \n",
      "104_block_list.2.sa.head_list.5.Linear_query        [512, 64]   \n",
      "105_block_list.2.sa.head_list.5.Linear_value        [512, 64]   \n",
      "106_block_list.2.sa.head_list.5.Dropout_dropout             -   \n",
      "107_block_list.2.sa.head_list.6.Linear_key          [512, 64]   \n",
      "108_block_list.2.sa.head_list.6.Linear_query        [512, 64]   \n",
      "109_block_list.2.sa.head_list.6.Linear_value        [512, 64]   \n",
      "110_block_list.2.sa.head_list.6.Dropout_dropout             -   \n",
      "111_block_list.2.sa.head_list.7.Linear_key          [512, 64]   \n",
      "112_block_list.2.sa.head_list.7.Linear_query        [512, 64]   \n",
      "113_block_list.2.sa.head_list.7.Linear_value        [512, 64]   \n",
      "114_block_list.2.sa.head_list.7.Dropout_dropout             -   \n",
      "115_block_list.2.sa.Linear_proj                    [512, 512]   \n",
      "116_block_list.2.sa.Dropout_dropout                         -   \n",
      "117_block_list.2.LayerNorm_ln2                          [512]   \n",
      "118_block_list.2.ff.layers.Linear_0               [512, 2048]   \n",
      "119_block_list.2.ff.layers.GELU_1                           -   \n",
      "120_block_list.2.ff.layers.Linear_2               [2048, 512]   \n",
      "121_block_list.2.ff.layers.Dropout_3                        -   \n",
      "122_block_list.3.LayerNorm_ln1                          [512]   \n",
      "123_block_list.3.sa.head_list.0.Linear_key          [512, 64]   \n",
      "124_block_list.3.sa.head_list.0.Linear_query        [512, 64]   \n",
      "125_block_list.3.sa.head_list.0.Linear_value        [512, 64]   \n",
      "126_block_list.3.sa.head_list.0.Dropout_dropout             -   \n",
      "127_block_list.3.sa.head_list.1.Linear_key          [512, 64]   \n",
      "128_block_list.3.sa.head_list.1.Linear_query        [512, 64]   \n",
      "129_block_list.3.sa.head_list.1.Linear_value        [512, 64]   \n",
      "130_block_list.3.sa.head_list.1.Dropout_dropout             -   \n",
      "131_block_list.3.sa.head_list.2.Linear_key          [512, 64]   \n",
      "132_block_list.3.sa.head_list.2.Linear_query        [512, 64]   \n",
      "133_block_list.3.sa.head_list.2.Linear_value        [512, 64]   \n",
      "134_block_list.3.sa.head_list.2.Dropout_dropout             -   \n",
      "135_block_list.3.sa.head_list.3.Linear_key          [512, 64]   \n",
      "136_block_list.3.sa.head_list.3.Linear_query        [512, 64]   \n",
      "137_block_list.3.sa.head_list.3.Linear_value        [512, 64]   \n",
      "138_block_list.3.sa.head_list.3.Dropout_dropout             -   \n",
      "139_block_list.3.sa.head_list.4.Linear_key          [512, 64]   \n",
      "140_block_list.3.sa.head_list.4.Linear_query        [512, 64]   \n",
      "141_block_list.3.sa.head_list.4.Linear_value        [512, 64]   \n",
      "142_block_list.3.sa.head_list.4.Dropout_dropout             -   \n",
      "143_block_list.3.sa.head_list.5.Linear_key          [512, 64]   \n",
      "144_block_list.3.sa.head_list.5.Linear_query        [512, 64]   \n",
      "145_block_list.3.sa.head_list.5.Linear_value        [512, 64]   \n",
      "146_block_list.3.sa.head_list.5.Dropout_dropout             -   \n",
      "147_block_list.3.sa.head_list.6.Linear_key          [512, 64]   \n",
      "148_block_list.3.sa.head_list.6.Linear_query        [512, 64]   \n",
      "149_block_list.3.sa.head_list.6.Linear_value        [512, 64]   \n",
      "150_block_list.3.sa.head_list.6.Dropout_dropout             -   \n",
      "151_block_list.3.sa.head_list.7.Linear_key          [512, 64]   \n",
      "152_block_list.3.sa.head_list.7.Linear_query        [512, 64]   \n",
      "153_block_list.3.sa.head_list.7.Linear_value        [512, 64]   \n",
      "154_block_list.3.sa.head_list.7.Dropout_dropout             -   \n",
      "155_block_list.3.sa.Linear_proj                    [512, 512]   \n",
      "156_block_list.3.sa.Dropout_dropout                         -   \n",
      "157_block_list.3.LayerNorm_ln2                          [512]   \n",
      "158_block_list.3.ff.layers.Linear_0               [512, 2048]   \n",
      "159_block_list.3.ff.layers.GELU_1                           -   \n",
      "160_block_list.3.ff.layers.Linear_2               [2048, 512]   \n",
      "161_block_list.3.ff.layers.Dropout_3                        -   \n",
      "162_block_list.4.LayerNorm_ln1                          [512]   \n",
      "163_block_list.4.sa.head_list.0.Linear_key          [512, 64]   \n",
      "164_block_list.4.sa.head_list.0.Linear_query        [512, 64]   \n",
      "165_block_list.4.sa.head_list.0.Linear_value        [512, 64]   \n",
      "166_block_list.4.sa.head_list.0.Dropout_dropout             -   \n",
      "167_block_list.4.sa.head_list.1.Linear_key          [512, 64]   \n",
      "168_block_list.4.sa.head_list.1.Linear_query        [512, 64]   \n",
      "169_block_list.4.sa.head_list.1.Linear_value        [512, 64]   \n",
      "170_block_list.4.sa.head_list.1.Dropout_dropout             -   \n",
      "171_block_list.4.sa.head_list.2.Linear_key          [512, 64]   \n",
      "172_block_list.4.sa.head_list.2.Linear_query        [512, 64]   \n",
      "173_block_list.4.sa.head_list.2.Linear_value        [512, 64]   \n",
      "174_block_list.4.sa.head_list.2.Dropout_dropout             -   \n",
      "175_block_list.4.sa.head_list.3.Linear_key          [512, 64]   \n",
      "176_block_list.4.sa.head_list.3.Linear_query        [512, 64]   \n",
      "177_block_list.4.sa.head_list.3.Linear_value        [512, 64]   \n",
      "178_block_list.4.sa.head_list.3.Dropout_dropout             -   \n",
      "179_block_list.4.sa.head_list.4.Linear_key          [512, 64]   \n",
      "180_block_list.4.sa.head_list.4.Linear_query        [512, 64]   \n",
      "181_block_list.4.sa.head_list.4.Linear_value        [512, 64]   \n",
      "182_block_list.4.sa.head_list.4.Dropout_dropout             -   \n",
      "183_block_list.4.sa.head_list.5.Linear_key          [512, 64]   \n",
      "184_block_list.4.sa.head_list.5.Linear_query        [512, 64]   \n",
      "185_block_list.4.sa.head_list.5.Linear_value        [512, 64]   \n",
      "186_block_list.4.sa.head_list.5.Dropout_dropout             -   \n",
      "187_block_list.4.sa.head_list.6.Linear_key          [512, 64]   \n",
      "188_block_list.4.sa.head_list.6.Linear_query        [512, 64]   \n",
      "189_block_list.4.sa.head_list.6.Linear_value        [512, 64]   \n",
      "190_block_list.4.sa.head_list.6.Dropout_dropout             -   \n",
      "191_block_list.4.sa.head_list.7.Linear_key          [512, 64]   \n",
      "192_block_list.4.sa.head_list.7.Linear_query        [512, 64]   \n",
      "193_block_list.4.sa.head_list.7.Linear_value        [512, 64]   \n",
      "194_block_list.4.sa.head_list.7.Dropout_dropout             -   \n",
      "195_block_list.4.sa.Linear_proj                    [512, 512]   \n",
      "196_block_list.4.sa.Dropout_dropout                         -   \n",
      "197_block_list.4.LayerNorm_ln2                          [512]   \n",
      "198_block_list.4.ff.layers.Linear_0               [512, 2048]   \n",
      "199_block_list.4.ff.layers.GELU_1                           -   \n",
      "200_block_list.4.ff.layers.Linear_2               [2048, 512]   \n",
      "201_block_list.4.ff.layers.Dropout_3                        -   \n",
      "202_block_list.5.LayerNorm_ln1                          [512]   \n",
      "203_block_list.5.sa.head_list.0.Linear_key          [512, 64]   \n",
      "204_block_list.5.sa.head_list.0.Linear_query        [512, 64]   \n",
      "205_block_list.5.sa.head_list.0.Linear_value        [512, 64]   \n",
      "206_block_list.5.sa.head_list.0.Dropout_dropout             -   \n",
      "207_block_list.5.sa.head_list.1.Linear_key          [512, 64]   \n",
      "208_block_list.5.sa.head_list.1.Linear_query        [512, 64]   \n",
      "209_block_list.5.sa.head_list.1.Linear_value        [512, 64]   \n",
      "210_block_list.5.sa.head_list.1.Dropout_dropout             -   \n",
      "211_block_list.5.sa.head_list.2.Linear_key          [512, 64]   \n",
      "212_block_list.5.sa.head_list.2.Linear_query        [512, 64]   \n",
      "213_block_list.5.sa.head_list.2.Linear_value        [512, 64]   \n",
      "214_block_list.5.sa.head_list.2.Dropout_dropout             -   \n",
      "215_block_list.5.sa.head_list.3.Linear_key          [512, 64]   \n",
      "216_block_list.5.sa.head_list.3.Linear_query        [512, 64]   \n",
      "217_block_list.5.sa.head_list.3.Linear_value        [512, 64]   \n",
      "218_block_list.5.sa.head_list.3.Dropout_dropout             -   \n",
      "219_block_list.5.sa.head_list.4.Linear_key          [512, 64]   \n",
      "220_block_list.5.sa.head_list.4.Linear_query        [512, 64]   \n",
      "221_block_list.5.sa.head_list.4.Linear_value        [512, 64]   \n",
      "222_block_list.5.sa.head_list.4.Dropout_dropout             -   \n",
      "223_block_list.5.sa.head_list.5.Linear_key          [512, 64]   \n",
      "224_block_list.5.sa.head_list.5.Linear_query        [512, 64]   \n",
      "225_block_list.5.sa.head_list.5.Linear_value        [512, 64]   \n",
      "226_block_list.5.sa.head_list.5.Dropout_dropout             -   \n",
      "227_block_list.5.sa.head_list.6.Linear_key          [512, 64]   \n",
      "228_block_list.5.sa.head_list.6.Linear_query        [512, 64]   \n",
      "229_block_list.5.sa.head_list.6.Linear_value        [512, 64]   \n",
      "230_block_list.5.sa.head_list.6.Dropout_dropout             -   \n",
      "231_block_list.5.sa.head_list.7.Linear_key          [512, 64]   \n",
      "232_block_list.5.sa.head_list.7.Linear_query        [512, 64]   \n",
      "233_block_list.5.sa.head_list.7.Linear_value        [512, 64]   \n",
      "234_block_list.5.sa.head_list.7.Dropout_dropout             -   \n",
      "235_block_list.5.sa.Linear_proj                    [512, 512]   \n",
      "236_block_list.5.sa.Dropout_dropout                         -   \n",
      "237_block_list.5.LayerNorm_ln2                          [512]   \n",
      "238_block_list.5.ff.layers.Linear_0               [512, 2048]   \n",
      "239_block_list.5.ff.layers.GELU_1                           -   \n",
      "240_block_list.5.ff.layers.Linear_2               [2048, 512]   \n",
      "241_block_list.5.ff.layers.Dropout_3                        -   \n",
      "242_block_list.6.LayerNorm_ln1                          [512]   \n",
      "243_block_list.6.sa.head_list.0.Linear_key          [512, 64]   \n",
      "244_block_list.6.sa.head_list.0.Linear_query        [512, 64]   \n",
      "245_block_list.6.sa.head_list.0.Linear_value        [512, 64]   \n",
      "246_block_list.6.sa.head_list.0.Dropout_dropout             -   \n",
      "247_block_list.6.sa.head_list.1.Linear_key          [512, 64]   \n",
      "248_block_list.6.sa.head_list.1.Linear_query        [512, 64]   \n",
      "249_block_list.6.sa.head_list.1.Linear_value        [512, 64]   \n",
      "250_block_list.6.sa.head_list.1.Dropout_dropout             -   \n",
      "251_block_list.6.sa.head_list.2.Linear_key          [512, 64]   \n",
      "252_block_list.6.sa.head_list.2.Linear_query        [512, 64]   \n",
      "253_block_list.6.sa.head_list.2.Linear_value        [512, 64]   \n",
      "254_block_list.6.sa.head_list.2.Dropout_dropout             -   \n",
      "255_block_list.6.sa.head_list.3.Linear_key          [512, 64]   \n",
      "256_block_list.6.sa.head_list.3.Linear_query        [512, 64]   \n",
      "257_block_list.6.sa.head_list.3.Linear_value        [512, 64]   \n",
      "258_block_list.6.sa.head_list.3.Dropout_dropout             -   \n",
      "259_block_list.6.sa.head_list.4.Linear_key          [512, 64]   \n",
      "260_block_list.6.sa.head_list.4.Linear_query        [512, 64]   \n",
      "261_block_list.6.sa.head_list.4.Linear_value        [512, 64]   \n",
      "262_block_list.6.sa.head_list.4.Dropout_dropout             -   \n",
      "263_block_list.6.sa.head_list.5.Linear_key          [512, 64]   \n",
      "264_block_list.6.sa.head_list.5.Linear_query        [512, 64]   \n",
      "265_block_list.6.sa.head_list.5.Linear_value        [512, 64]   \n",
      "266_block_list.6.sa.head_list.5.Dropout_dropout             -   \n",
      "267_block_list.6.sa.head_list.6.Linear_key          [512, 64]   \n",
      "268_block_list.6.sa.head_list.6.Linear_query        [512, 64]   \n",
      "269_block_list.6.sa.head_list.6.Linear_value        [512, 64]   \n",
      "270_block_list.6.sa.head_list.6.Dropout_dropout             -   \n",
      "271_block_list.6.sa.head_list.7.Linear_key          [512, 64]   \n",
      "272_block_list.6.sa.head_list.7.Linear_query        [512, 64]   \n",
      "273_block_list.6.sa.head_list.7.Linear_value        [512, 64]   \n",
      "274_block_list.6.sa.head_list.7.Dropout_dropout             -   \n",
      "275_block_list.6.sa.Linear_proj                    [512, 512]   \n",
      "276_block_list.6.sa.Dropout_dropout                         -   \n",
      "277_block_list.6.LayerNorm_ln2                          [512]   \n",
      "278_block_list.6.ff.layers.Linear_0               [512, 2048]   \n",
      "279_block_list.6.ff.layers.GELU_1                           -   \n",
      "280_block_list.6.ff.layers.Linear_2               [2048, 512]   \n",
      "281_block_list.6.ff.layers.Dropout_3                        -   \n",
      "282_block_list.7.LayerNorm_ln1                          [512]   \n",
      "283_block_list.7.sa.head_list.0.Linear_key          [512, 64]   \n",
      "284_block_list.7.sa.head_list.0.Linear_query        [512, 64]   \n",
      "285_block_list.7.sa.head_list.0.Linear_value        [512, 64]   \n",
      "286_block_list.7.sa.head_list.0.Dropout_dropout             -   \n",
      "287_block_list.7.sa.head_list.1.Linear_key          [512, 64]   \n",
      "288_block_list.7.sa.head_list.1.Linear_query        [512, 64]   \n",
      "289_block_list.7.sa.head_list.1.Linear_value        [512, 64]   \n",
      "290_block_list.7.sa.head_list.1.Dropout_dropout             -   \n",
      "291_block_list.7.sa.head_list.2.Linear_key          [512, 64]   \n",
      "292_block_list.7.sa.head_list.2.Linear_query        [512, 64]   \n",
      "293_block_list.7.sa.head_list.2.Linear_value        [512, 64]   \n",
      "294_block_list.7.sa.head_list.2.Dropout_dropout             -   \n",
      "295_block_list.7.sa.head_list.3.Linear_key          [512, 64]   \n",
      "296_block_list.7.sa.head_list.3.Linear_query        [512, 64]   \n",
      "297_block_list.7.sa.head_list.3.Linear_value        [512, 64]   \n",
      "298_block_list.7.sa.head_list.3.Dropout_dropout             -   \n",
      "299_block_list.7.sa.head_list.4.Linear_key          [512, 64]   \n",
      "300_block_list.7.sa.head_list.4.Linear_query        [512, 64]   \n",
      "301_block_list.7.sa.head_list.4.Linear_value        [512, 64]   \n",
      "302_block_list.7.sa.head_list.4.Dropout_dropout             -   \n",
      "303_block_list.7.sa.head_list.5.Linear_key          [512, 64]   \n",
      "304_block_list.7.sa.head_list.5.Linear_query        [512, 64]   \n",
      "305_block_list.7.sa.head_list.5.Linear_value        [512, 64]   \n",
      "306_block_list.7.sa.head_list.5.Dropout_dropout             -   \n",
      "307_block_list.7.sa.head_list.6.Linear_key          [512, 64]   \n",
      "308_block_list.7.sa.head_list.6.Linear_query        [512, 64]   \n",
      "309_block_list.7.sa.head_list.6.Linear_value        [512, 64]   \n",
      "310_block_list.7.sa.head_list.6.Dropout_dropout             -   \n",
      "311_block_list.7.sa.head_list.7.Linear_key          [512, 64]   \n",
      "312_block_list.7.sa.head_list.7.Linear_query        [512, 64]   \n",
      "313_block_list.7.sa.head_list.7.Linear_value        [512, 64]   \n",
      "314_block_list.7.sa.head_list.7.Dropout_dropout             -   \n",
      "315_block_list.7.sa.Linear_proj                    [512, 512]   \n",
      "316_block_list.7.sa.Dropout_dropout                         -   \n",
      "317_block_list.7.LayerNorm_ln2                          [512]   \n",
      "318_block_list.7.ff.layers.Linear_0               [512, 2048]   \n",
      "319_block_list.7.ff.layers.GELU_1                           -   \n",
      "320_block_list.7.ff.layers.Linear_2               [2048, 512]   \n",
      "321_block_list.7.ff.layers.Dropout_3                        -   \n",
      "322_final_ln                                            [512]   \n",
      "323_lm_head                                      [512, 50257]   \n",
      "\n",
      "                                                     Output Shape      Params  \\\n",
      "Layer                                                                           \n",
      "0_token_embeddings                                 [16, 256, 512]  25.731584M   \n",
      "1_position_embeddings                                  [256, 512]    131.072k   \n",
      "2_block_list.0.LayerNorm_ln1                       [16, 256, 512]      1.024k   \n",
      "3_block_list.0.sa.head_list.0.Linear_key            [16, 256, 64]     32.768k   \n",
      "4_block_list.0.sa.head_list.0.Linear_query          [16, 256, 64]     32.768k   \n",
      "5_block_list.0.sa.head_list.0.Linear_value          [16, 256, 64]     32.768k   \n",
      "6_block_list.0.sa.head_list.0.Dropout_dropout      [16, 256, 256]           -   \n",
      "7_block_list.0.sa.head_list.1.Linear_key            [16, 256, 64]     32.768k   \n",
      "8_block_list.0.sa.head_list.1.Linear_query          [16, 256, 64]     32.768k   \n",
      "9_block_list.0.sa.head_list.1.Linear_value          [16, 256, 64]     32.768k   \n",
      "10_block_list.0.sa.head_list.1.Dropout_dropout     [16, 256, 256]           -   \n",
      "11_block_list.0.sa.head_list.2.Linear_key           [16, 256, 64]     32.768k   \n",
      "12_block_list.0.sa.head_list.2.Linear_query         [16, 256, 64]     32.768k   \n",
      "13_block_list.0.sa.head_list.2.Linear_value         [16, 256, 64]     32.768k   \n",
      "14_block_list.0.sa.head_list.2.Dropout_dropout     [16, 256, 256]           -   \n",
      "15_block_list.0.sa.head_list.3.Linear_key           [16, 256, 64]     32.768k   \n",
      "16_block_list.0.sa.head_list.3.Linear_query         [16, 256, 64]     32.768k   \n",
      "17_block_list.0.sa.head_list.3.Linear_value         [16, 256, 64]     32.768k   \n",
      "18_block_list.0.sa.head_list.3.Dropout_dropout     [16, 256, 256]           -   \n",
      "19_block_list.0.sa.head_list.4.Linear_key           [16, 256, 64]     32.768k   \n",
      "20_block_list.0.sa.head_list.4.Linear_query         [16, 256, 64]     32.768k   \n",
      "21_block_list.0.sa.head_list.4.Linear_value         [16, 256, 64]     32.768k   \n",
      "22_block_list.0.sa.head_list.4.Dropout_dropout     [16, 256, 256]           -   \n",
      "23_block_list.0.sa.head_list.5.Linear_key           [16, 256, 64]     32.768k   \n",
      "24_block_list.0.sa.head_list.5.Linear_query         [16, 256, 64]     32.768k   \n",
      "25_block_list.0.sa.head_list.5.Linear_value         [16, 256, 64]     32.768k   \n",
      "26_block_list.0.sa.head_list.5.Dropout_dropout     [16, 256, 256]           -   \n",
      "27_block_list.0.sa.head_list.6.Linear_key           [16, 256, 64]     32.768k   \n",
      "28_block_list.0.sa.head_list.6.Linear_query         [16, 256, 64]     32.768k   \n",
      "29_block_list.0.sa.head_list.6.Linear_value         [16, 256, 64]     32.768k   \n",
      "30_block_list.0.sa.head_list.6.Dropout_dropout     [16, 256, 256]           -   \n",
      "31_block_list.0.sa.head_list.7.Linear_key           [16, 256, 64]     32.768k   \n",
      "32_block_list.0.sa.head_list.7.Linear_query         [16, 256, 64]     32.768k   \n",
      "33_block_list.0.sa.head_list.7.Linear_value         [16, 256, 64]     32.768k   \n",
      "34_block_list.0.sa.head_list.7.Dropout_dropout     [16, 256, 256]           -   \n",
      "35_block_list.0.sa.Linear_proj                     [16, 256, 512]    262.656k   \n",
      "36_block_list.0.sa.Dropout_dropout                 [16, 256, 512]           -   \n",
      "37_block_list.0.LayerNorm_ln2                      [16, 256, 512]      1.024k   \n",
      "38_block_list.0.ff.layers.Linear_0                [16, 256, 2048]   1.050624M   \n",
      "39_block_list.0.ff.layers.GELU_1                  [16, 256, 2048]           -   \n",
      "40_block_list.0.ff.layers.Linear_2                 [16, 256, 512]   1.049088M   \n",
      "41_block_list.0.ff.layers.Dropout_3                [16, 256, 512]           -   \n",
      "42_block_list.1.LayerNorm_ln1                      [16, 256, 512]      1.024k   \n",
      "43_block_list.1.sa.head_list.0.Linear_key           [16, 256, 64]     32.768k   \n",
      "44_block_list.1.sa.head_list.0.Linear_query         [16, 256, 64]     32.768k   \n",
      "45_block_list.1.sa.head_list.0.Linear_value         [16, 256, 64]     32.768k   \n",
      "46_block_list.1.sa.head_list.0.Dropout_dropout     [16, 256, 256]           -   \n",
      "47_block_list.1.sa.head_list.1.Linear_key           [16, 256, 64]     32.768k   \n",
      "48_block_list.1.sa.head_list.1.Linear_query         [16, 256, 64]     32.768k   \n",
      "49_block_list.1.sa.head_list.1.Linear_value         [16, 256, 64]     32.768k   \n",
      "50_block_list.1.sa.head_list.1.Dropout_dropout     [16, 256, 256]           -   \n",
      "51_block_list.1.sa.head_list.2.Linear_key           [16, 256, 64]     32.768k   \n",
      "52_block_list.1.sa.head_list.2.Linear_query         [16, 256, 64]     32.768k   \n",
      "53_block_list.1.sa.head_list.2.Linear_value         [16, 256, 64]     32.768k   \n",
      "54_block_list.1.sa.head_list.2.Dropout_dropout     [16, 256, 256]           -   \n",
      "55_block_list.1.sa.head_list.3.Linear_key           [16, 256, 64]     32.768k   \n",
      "56_block_list.1.sa.head_list.3.Linear_query         [16, 256, 64]     32.768k   \n",
      "57_block_list.1.sa.head_list.3.Linear_value         [16, 256, 64]     32.768k   \n",
      "58_block_list.1.sa.head_list.3.Dropout_dropout     [16, 256, 256]           -   \n",
      "59_block_list.1.sa.head_list.4.Linear_key           [16, 256, 64]     32.768k   \n",
      "60_block_list.1.sa.head_list.4.Linear_query         [16, 256, 64]     32.768k   \n",
      "61_block_list.1.sa.head_list.4.Linear_value         [16, 256, 64]     32.768k   \n",
      "62_block_list.1.sa.head_list.4.Dropout_dropout     [16, 256, 256]           -   \n",
      "63_block_list.1.sa.head_list.5.Linear_key           [16, 256, 64]     32.768k   \n",
      "64_block_list.1.sa.head_list.5.Linear_query         [16, 256, 64]     32.768k   \n",
      "65_block_list.1.sa.head_list.5.Linear_value         [16, 256, 64]     32.768k   \n",
      "66_block_list.1.sa.head_list.5.Dropout_dropout     [16, 256, 256]           -   \n",
      "67_block_list.1.sa.head_list.6.Linear_key           [16, 256, 64]     32.768k   \n",
      "68_block_list.1.sa.head_list.6.Linear_query         [16, 256, 64]     32.768k   \n",
      "69_block_list.1.sa.head_list.6.Linear_value         [16, 256, 64]     32.768k   \n",
      "70_block_list.1.sa.head_list.6.Dropout_dropout     [16, 256, 256]           -   \n",
      "71_block_list.1.sa.head_list.7.Linear_key           [16, 256, 64]     32.768k   \n",
      "72_block_list.1.sa.head_list.7.Linear_query         [16, 256, 64]     32.768k   \n",
      "73_block_list.1.sa.head_list.7.Linear_value         [16, 256, 64]     32.768k   \n",
      "74_block_list.1.sa.head_list.7.Dropout_dropout     [16, 256, 256]           -   \n",
      "75_block_list.1.sa.Linear_proj                     [16, 256, 512]    262.656k   \n",
      "76_block_list.1.sa.Dropout_dropout                 [16, 256, 512]           -   \n",
      "77_block_list.1.LayerNorm_ln2                      [16, 256, 512]      1.024k   \n",
      "78_block_list.1.ff.layers.Linear_0                [16, 256, 2048]   1.050624M   \n",
      "79_block_list.1.ff.layers.GELU_1                  [16, 256, 2048]           -   \n",
      "80_block_list.1.ff.layers.Linear_2                 [16, 256, 512]   1.049088M   \n",
      "81_block_list.1.ff.layers.Dropout_3                [16, 256, 512]           -   \n",
      "82_block_list.2.LayerNorm_ln1                      [16, 256, 512]      1.024k   \n",
      "83_block_list.2.sa.head_list.0.Linear_key           [16, 256, 64]     32.768k   \n",
      "84_block_list.2.sa.head_list.0.Linear_query         [16, 256, 64]     32.768k   \n",
      "85_block_list.2.sa.head_list.0.Linear_value         [16, 256, 64]     32.768k   \n",
      "86_block_list.2.sa.head_list.0.Dropout_dropout     [16, 256, 256]           -   \n",
      "87_block_list.2.sa.head_list.1.Linear_key           [16, 256, 64]     32.768k   \n",
      "88_block_list.2.sa.head_list.1.Linear_query         [16, 256, 64]     32.768k   \n",
      "89_block_list.2.sa.head_list.1.Linear_value         [16, 256, 64]     32.768k   \n",
      "90_block_list.2.sa.head_list.1.Dropout_dropout     [16, 256, 256]           -   \n",
      "91_block_list.2.sa.head_list.2.Linear_key           [16, 256, 64]     32.768k   \n",
      "92_block_list.2.sa.head_list.2.Linear_query         [16, 256, 64]     32.768k   \n",
      "93_block_list.2.sa.head_list.2.Linear_value         [16, 256, 64]     32.768k   \n",
      "94_block_list.2.sa.head_list.2.Dropout_dropout     [16, 256, 256]           -   \n",
      "95_block_list.2.sa.head_list.3.Linear_key           [16, 256, 64]     32.768k   \n",
      "96_block_list.2.sa.head_list.3.Linear_query         [16, 256, 64]     32.768k   \n",
      "97_block_list.2.sa.head_list.3.Linear_value         [16, 256, 64]     32.768k   \n",
      "98_block_list.2.sa.head_list.3.Dropout_dropout     [16, 256, 256]           -   \n",
      "99_block_list.2.sa.head_list.4.Linear_key           [16, 256, 64]     32.768k   \n",
      "100_block_list.2.sa.head_list.4.Linear_query        [16, 256, 64]     32.768k   \n",
      "101_block_list.2.sa.head_list.4.Linear_value        [16, 256, 64]     32.768k   \n",
      "102_block_list.2.sa.head_list.4.Dropout_dropout    [16, 256, 256]           -   \n",
      "103_block_list.2.sa.head_list.5.Linear_key          [16, 256, 64]     32.768k   \n",
      "104_block_list.2.sa.head_list.5.Linear_query        [16, 256, 64]     32.768k   \n",
      "105_block_list.2.sa.head_list.5.Linear_value        [16, 256, 64]     32.768k   \n",
      "106_block_list.2.sa.head_list.5.Dropout_dropout    [16, 256, 256]           -   \n",
      "107_block_list.2.sa.head_list.6.Linear_key          [16, 256, 64]     32.768k   \n",
      "108_block_list.2.sa.head_list.6.Linear_query        [16, 256, 64]     32.768k   \n",
      "109_block_list.2.sa.head_list.6.Linear_value        [16, 256, 64]     32.768k   \n",
      "110_block_list.2.sa.head_list.6.Dropout_dropout    [16, 256, 256]           -   \n",
      "111_block_list.2.sa.head_list.7.Linear_key          [16, 256, 64]     32.768k   \n",
      "112_block_list.2.sa.head_list.7.Linear_query        [16, 256, 64]     32.768k   \n",
      "113_block_list.2.sa.head_list.7.Linear_value        [16, 256, 64]     32.768k   \n",
      "114_block_list.2.sa.head_list.7.Dropout_dropout    [16, 256, 256]           -   \n",
      "115_block_list.2.sa.Linear_proj                    [16, 256, 512]    262.656k   \n",
      "116_block_list.2.sa.Dropout_dropout                [16, 256, 512]           -   \n",
      "117_block_list.2.LayerNorm_ln2                     [16, 256, 512]      1.024k   \n",
      "118_block_list.2.ff.layers.Linear_0               [16, 256, 2048]   1.050624M   \n",
      "119_block_list.2.ff.layers.GELU_1                 [16, 256, 2048]           -   \n",
      "120_block_list.2.ff.layers.Linear_2                [16, 256, 512]   1.049088M   \n",
      "121_block_list.2.ff.layers.Dropout_3               [16, 256, 512]           -   \n",
      "122_block_list.3.LayerNorm_ln1                     [16, 256, 512]      1.024k   \n",
      "123_block_list.3.sa.head_list.0.Linear_key          [16, 256, 64]     32.768k   \n",
      "124_block_list.3.sa.head_list.0.Linear_query        [16, 256, 64]     32.768k   \n",
      "125_block_list.3.sa.head_list.0.Linear_value        [16, 256, 64]     32.768k   \n",
      "126_block_list.3.sa.head_list.0.Dropout_dropout    [16, 256, 256]           -   \n",
      "127_block_list.3.sa.head_list.1.Linear_key          [16, 256, 64]     32.768k   \n",
      "128_block_list.3.sa.head_list.1.Linear_query        [16, 256, 64]     32.768k   \n",
      "129_block_list.3.sa.head_list.1.Linear_value        [16, 256, 64]     32.768k   \n",
      "130_block_list.3.sa.head_list.1.Dropout_dropout    [16, 256, 256]           -   \n",
      "131_block_list.3.sa.head_list.2.Linear_key          [16, 256, 64]     32.768k   \n",
      "132_block_list.3.sa.head_list.2.Linear_query        [16, 256, 64]     32.768k   \n",
      "133_block_list.3.sa.head_list.2.Linear_value        [16, 256, 64]     32.768k   \n",
      "134_block_list.3.sa.head_list.2.Dropout_dropout    [16, 256, 256]           -   \n",
      "135_block_list.3.sa.head_list.3.Linear_key          [16, 256, 64]     32.768k   \n",
      "136_block_list.3.sa.head_list.3.Linear_query        [16, 256, 64]     32.768k   \n",
      "137_block_list.3.sa.head_list.3.Linear_value        [16, 256, 64]     32.768k   \n",
      "138_block_list.3.sa.head_list.3.Dropout_dropout    [16, 256, 256]           -   \n",
      "139_block_list.3.sa.head_list.4.Linear_key          [16, 256, 64]     32.768k   \n",
      "140_block_list.3.sa.head_list.4.Linear_query        [16, 256, 64]     32.768k   \n",
      "141_block_list.3.sa.head_list.4.Linear_value        [16, 256, 64]     32.768k   \n",
      "142_block_list.3.sa.head_list.4.Dropout_dropout    [16, 256, 256]           -   \n",
      "143_block_list.3.sa.head_list.5.Linear_key          [16, 256, 64]     32.768k   \n",
      "144_block_list.3.sa.head_list.5.Linear_query        [16, 256, 64]     32.768k   \n",
      "145_block_list.3.sa.head_list.5.Linear_value        [16, 256, 64]     32.768k   \n",
      "146_block_list.3.sa.head_list.5.Dropout_dropout    [16, 256, 256]           -   \n",
      "147_block_list.3.sa.head_list.6.Linear_key          [16, 256, 64]     32.768k   \n",
      "148_block_list.3.sa.head_list.6.Linear_query        [16, 256, 64]     32.768k   \n",
      "149_block_list.3.sa.head_list.6.Linear_value        [16, 256, 64]     32.768k   \n",
      "150_block_list.3.sa.head_list.6.Dropout_dropout    [16, 256, 256]           -   \n",
      "151_block_list.3.sa.head_list.7.Linear_key          [16, 256, 64]     32.768k   \n",
      "152_block_list.3.sa.head_list.7.Linear_query        [16, 256, 64]     32.768k   \n",
      "153_block_list.3.sa.head_list.7.Linear_value        [16, 256, 64]     32.768k   \n",
      "154_block_list.3.sa.head_list.7.Dropout_dropout    [16, 256, 256]           -   \n",
      "155_block_list.3.sa.Linear_proj                    [16, 256, 512]    262.656k   \n",
      "156_block_list.3.sa.Dropout_dropout                [16, 256, 512]           -   \n",
      "157_block_list.3.LayerNorm_ln2                     [16, 256, 512]      1.024k   \n",
      "158_block_list.3.ff.layers.Linear_0               [16, 256, 2048]   1.050624M   \n",
      "159_block_list.3.ff.layers.GELU_1                 [16, 256, 2048]           -   \n",
      "160_block_list.3.ff.layers.Linear_2                [16, 256, 512]   1.049088M   \n",
      "161_block_list.3.ff.layers.Dropout_3               [16, 256, 512]           -   \n",
      "162_block_list.4.LayerNorm_ln1                     [16, 256, 512]      1.024k   \n",
      "163_block_list.4.sa.head_list.0.Linear_key          [16, 256, 64]     32.768k   \n",
      "164_block_list.4.sa.head_list.0.Linear_query        [16, 256, 64]     32.768k   \n",
      "165_block_list.4.sa.head_list.0.Linear_value        [16, 256, 64]     32.768k   \n",
      "166_block_list.4.sa.head_list.0.Dropout_dropout    [16, 256, 256]           -   \n",
      "167_block_list.4.sa.head_list.1.Linear_key          [16, 256, 64]     32.768k   \n",
      "168_block_list.4.sa.head_list.1.Linear_query        [16, 256, 64]     32.768k   \n",
      "169_block_list.4.sa.head_list.1.Linear_value        [16, 256, 64]     32.768k   \n",
      "170_block_list.4.sa.head_list.1.Dropout_dropout    [16, 256, 256]           -   \n",
      "171_block_list.4.sa.head_list.2.Linear_key          [16, 256, 64]     32.768k   \n",
      "172_block_list.4.sa.head_list.2.Linear_query        [16, 256, 64]     32.768k   \n",
      "173_block_list.4.sa.head_list.2.Linear_value        [16, 256, 64]     32.768k   \n",
      "174_block_list.4.sa.head_list.2.Dropout_dropout    [16, 256, 256]           -   \n",
      "175_block_list.4.sa.head_list.3.Linear_key          [16, 256, 64]     32.768k   \n",
      "176_block_list.4.sa.head_list.3.Linear_query        [16, 256, 64]     32.768k   \n",
      "177_block_list.4.sa.head_list.3.Linear_value        [16, 256, 64]     32.768k   \n",
      "178_block_list.4.sa.head_list.3.Dropout_dropout    [16, 256, 256]           -   \n",
      "179_block_list.4.sa.head_list.4.Linear_key          [16, 256, 64]     32.768k   \n",
      "180_block_list.4.sa.head_list.4.Linear_query        [16, 256, 64]     32.768k   \n",
      "181_block_list.4.sa.head_list.4.Linear_value        [16, 256, 64]     32.768k   \n",
      "182_block_list.4.sa.head_list.4.Dropout_dropout    [16, 256, 256]           -   \n",
      "183_block_list.4.sa.head_list.5.Linear_key          [16, 256, 64]     32.768k   \n",
      "184_block_list.4.sa.head_list.5.Linear_query        [16, 256, 64]     32.768k   \n",
      "185_block_list.4.sa.head_list.5.Linear_value        [16, 256, 64]     32.768k   \n",
      "186_block_list.4.sa.head_list.5.Dropout_dropout    [16, 256, 256]           -   \n",
      "187_block_list.4.sa.head_list.6.Linear_key          [16, 256, 64]     32.768k   \n",
      "188_block_list.4.sa.head_list.6.Linear_query        [16, 256, 64]     32.768k   \n",
      "189_block_list.4.sa.head_list.6.Linear_value        [16, 256, 64]     32.768k   \n",
      "190_block_list.4.sa.head_list.6.Dropout_dropout    [16, 256, 256]           -   \n",
      "191_block_list.4.sa.head_list.7.Linear_key          [16, 256, 64]     32.768k   \n",
      "192_block_list.4.sa.head_list.7.Linear_query        [16, 256, 64]     32.768k   \n",
      "193_block_list.4.sa.head_list.7.Linear_value        [16, 256, 64]     32.768k   \n",
      "194_block_list.4.sa.head_list.7.Dropout_dropout    [16, 256, 256]           -   \n",
      "195_block_list.4.sa.Linear_proj                    [16, 256, 512]    262.656k   \n",
      "196_block_list.4.sa.Dropout_dropout                [16, 256, 512]           -   \n",
      "197_block_list.4.LayerNorm_ln2                     [16, 256, 512]      1.024k   \n",
      "198_block_list.4.ff.layers.Linear_0               [16, 256, 2048]   1.050624M   \n",
      "199_block_list.4.ff.layers.GELU_1                 [16, 256, 2048]           -   \n",
      "200_block_list.4.ff.layers.Linear_2                [16, 256, 512]   1.049088M   \n",
      "201_block_list.4.ff.layers.Dropout_3               [16, 256, 512]           -   \n",
      "202_block_list.5.LayerNorm_ln1                     [16, 256, 512]      1.024k   \n",
      "203_block_list.5.sa.head_list.0.Linear_key          [16, 256, 64]     32.768k   \n",
      "204_block_list.5.sa.head_list.0.Linear_query        [16, 256, 64]     32.768k   \n",
      "205_block_list.5.sa.head_list.0.Linear_value        [16, 256, 64]     32.768k   \n",
      "206_block_list.5.sa.head_list.0.Dropout_dropout    [16, 256, 256]           -   \n",
      "207_block_list.5.sa.head_list.1.Linear_key          [16, 256, 64]     32.768k   \n",
      "208_block_list.5.sa.head_list.1.Linear_query        [16, 256, 64]     32.768k   \n",
      "209_block_list.5.sa.head_list.1.Linear_value        [16, 256, 64]     32.768k   \n",
      "210_block_list.5.sa.head_list.1.Dropout_dropout    [16, 256, 256]           -   \n",
      "211_block_list.5.sa.head_list.2.Linear_key          [16, 256, 64]     32.768k   \n",
      "212_block_list.5.sa.head_list.2.Linear_query        [16, 256, 64]     32.768k   \n",
      "213_block_list.5.sa.head_list.2.Linear_value        [16, 256, 64]     32.768k   \n",
      "214_block_list.5.sa.head_list.2.Dropout_dropout    [16, 256, 256]           -   \n",
      "215_block_list.5.sa.head_list.3.Linear_key          [16, 256, 64]     32.768k   \n",
      "216_block_list.5.sa.head_list.3.Linear_query        [16, 256, 64]     32.768k   \n",
      "217_block_list.5.sa.head_list.3.Linear_value        [16, 256, 64]     32.768k   \n",
      "218_block_list.5.sa.head_list.3.Dropout_dropout    [16, 256, 256]           -   \n",
      "219_block_list.5.sa.head_list.4.Linear_key          [16, 256, 64]     32.768k   \n",
      "220_block_list.5.sa.head_list.4.Linear_query        [16, 256, 64]     32.768k   \n",
      "221_block_list.5.sa.head_list.4.Linear_value        [16, 256, 64]     32.768k   \n",
      "222_block_list.5.sa.head_list.4.Dropout_dropout    [16, 256, 256]           -   \n",
      "223_block_list.5.sa.head_list.5.Linear_key          [16, 256, 64]     32.768k   \n",
      "224_block_list.5.sa.head_list.5.Linear_query        [16, 256, 64]     32.768k   \n",
      "225_block_list.5.sa.head_list.5.Linear_value        [16, 256, 64]     32.768k   \n",
      "226_block_list.5.sa.head_list.5.Dropout_dropout    [16, 256, 256]           -   \n",
      "227_block_list.5.sa.head_list.6.Linear_key          [16, 256, 64]     32.768k   \n",
      "228_block_list.5.sa.head_list.6.Linear_query        [16, 256, 64]     32.768k   \n",
      "229_block_list.5.sa.head_list.6.Linear_value        [16, 256, 64]     32.768k   \n",
      "230_block_list.5.sa.head_list.6.Dropout_dropout    [16, 256, 256]           -   \n",
      "231_block_list.5.sa.head_list.7.Linear_key          [16, 256, 64]     32.768k   \n",
      "232_block_list.5.sa.head_list.7.Linear_query        [16, 256, 64]     32.768k   \n",
      "233_block_list.5.sa.head_list.7.Linear_value        [16, 256, 64]     32.768k   \n",
      "234_block_list.5.sa.head_list.7.Dropout_dropout    [16, 256, 256]           -   \n",
      "235_block_list.5.sa.Linear_proj                    [16, 256, 512]    262.656k   \n",
      "236_block_list.5.sa.Dropout_dropout                [16, 256, 512]           -   \n",
      "237_block_list.5.LayerNorm_ln2                     [16, 256, 512]      1.024k   \n",
      "238_block_list.5.ff.layers.Linear_0               [16, 256, 2048]   1.050624M   \n",
      "239_block_list.5.ff.layers.GELU_1                 [16, 256, 2048]           -   \n",
      "240_block_list.5.ff.layers.Linear_2                [16, 256, 512]   1.049088M   \n",
      "241_block_list.5.ff.layers.Dropout_3               [16, 256, 512]           -   \n",
      "242_block_list.6.LayerNorm_ln1                     [16, 256, 512]      1.024k   \n",
      "243_block_list.6.sa.head_list.0.Linear_key          [16, 256, 64]     32.768k   \n",
      "244_block_list.6.sa.head_list.0.Linear_query        [16, 256, 64]     32.768k   \n",
      "245_block_list.6.sa.head_list.0.Linear_value        [16, 256, 64]     32.768k   \n",
      "246_block_list.6.sa.head_list.0.Dropout_dropout    [16, 256, 256]           -   \n",
      "247_block_list.6.sa.head_list.1.Linear_key          [16, 256, 64]     32.768k   \n",
      "248_block_list.6.sa.head_list.1.Linear_query        [16, 256, 64]     32.768k   \n",
      "249_block_list.6.sa.head_list.1.Linear_value        [16, 256, 64]     32.768k   \n",
      "250_block_list.6.sa.head_list.1.Dropout_dropout    [16, 256, 256]           -   \n",
      "251_block_list.6.sa.head_list.2.Linear_key          [16, 256, 64]     32.768k   \n",
      "252_block_list.6.sa.head_list.2.Linear_query        [16, 256, 64]     32.768k   \n",
      "253_block_list.6.sa.head_list.2.Linear_value        [16, 256, 64]     32.768k   \n",
      "254_block_list.6.sa.head_list.2.Dropout_dropout    [16, 256, 256]           -   \n",
      "255_block_list.6.sa.head_list.3.Linear_key          [16, 256, 64]     32.768k   \n",
      "256_block_list.6.sa.head_list.3.Linear_query        [16, 256, 64]     32.768k   \n",
      "257_block_list.6.sa.head_list.3.Linear_value        [16, 256, 64]     32.768k   \n",
      "258_block_list.6.sa.head_list.3.Dropout_dropout    [16, 256, 256]           -   \n",
      "259_block_list.6.sa.head_list.4.Linear_key          [16, 256, 64]     32.768k   \n",
      "260_block_list.6.sa.head_list.4.Linear_query        [16, 256, 64]     32.768k   \n",
      "261_block_list.6.sa.head_list.4.Linear_value        [16, 256, 64]     32.768k   \n",
      "262_block_list.6.sa.head_list.4.Dropout_dropout    [16, 256, 256]           -   \n",
      "263_block_list.6.sa.head_list.5.Linear_key          [16, 256, 64]     32.768k   \n",
      "264_block_list.6.sa.head_list.5.Linear_query        [16, 256, 64]     32.768k   \n",
      "265_block_list.6.sa.head_list.5.Linear_value        [16, 256, 64]     32.768k   \n",
      "266_block_list.6.sa.head_list.5.Dropout_dropout    [16, 256, 256]           -   \n",
      "267_block_list.6.sa.head_list.6.Linear_key          [16, 256, 64]     32.768k   \n",
      "268_block_list.6.sa.head_list.6.Linear_query        [16, 256, 64]     32.768k   \n",
      "269_block_list.6.sa.head_list.6.Linear_value        [16, 256, 64]     32.768k   \n",
      "270_block_list.6.sa.head_list.6.Dropout_dropout    [16, 256, 256]           -   \n",
      "271_block_list.6.sa.head_list.7.Linear_key          [16, 256, 64]     32.768k   \n",
      "272_block_list.6.sa.head_list.7.Linear_query        [16, 256, 64]     32.768k   \n",
      "273_block_list.6.sa.head_list.7.Linear_value        [16, 256, 64]     32.768k   \n",
      "274_block_list.6.sa.head_list.7.Dropout_dropout    [16, 256, 256]           -   \n",
      "275_block_list.6.sa.Linear_proj                    [16, 256, 512]    262.656k   \n",
      "276_block_list.6.sa.Dropout_dropout                [16, 256, 512]           -   \n",
      "277_block_list.6.LayerNorm_ln2                     [16, 256, 512]      1.024k   \n",
      "278_block_list.6.ff.layers.Linear_0               [16, 256, 2048]   1.050624M   \n",
      "279_block_list.6.ff.layers.GELU_1                 [16, 256, 2048]           -   \n",
      "280_block_list.6.ff.layers.Linear_2                [16, 256, 512]   1.049088M   \n",
      "281_block_list.6.ff.layers.Dropout_3               [16, 256, 512]           -   \n",
      "282_block_list.7.LayerNorm_ln1                     [16, 256, 512]      1.024k   \n",
      "283_block_list.7.sa.head_list.0.Linear_key          [16, 256, 64]     32.768k   \n",
      "284_block_list.7.sa.head_list.0.Linear_query        [16, 256, 64]     32.768k   \n",
      "285_block_list.7.sa.head_list.0.Linear_value        [16, 256, 64]     32.768k   \n",
      "286_block_list.7.sa.head_list.0.Dropout_dropout    [16, 256, 256]           -   \n",
      "287_block_list.7.sa.head_list.1.Linear_key          [16, 256, 64]     32.768k   \n",
      "288_block_list.7.sa.head_list.1.Linear_query        [16, 256, 64]     32.768k   \n",
      "289_block_list.7.sa.head_list.1.Linear_value        [16, 256, 64]     32.768k   \n",
      "290_block_list.7.sa.head_list.1.Dropout_dropout    [16, 256, 256]           -   \n",
      "291_block_list.7.sa.head_list.2.Linear_key          [16, 256, 64]     32.768k   \n",
      "292_block_list.7.sa.head_list.2.Linear_query        [16, 256, 64]     32.768k   \n",
      "293_block_list.7.sa.head_list.2.Linear_value        [16, 256, 64]     32.768k   \n",
      "294_block_list.7.sa.head_list.2.Dropout_dropout    [16, 256, 256]           -   \n",
      "295_block_list.7.sa.head_list.3.Linear_key          [16, 256, 64]     32.768k   \n",
      "296_block_list.7.sa.head_list.3.Linear_query        [16, 256, 64]     32.768k   \n",
      "297_block_list.7.sa.head_list.3.Linear_value        [16, 256, 64]     32.768k   \n",
      "298_block_list.7.sa.head_list.3.Dropout_dropout    [16, 256, 256]           -   \n",
      "299_block_list.7.sa.head_list.4.Linear_key          [16, 256, 64]     32.768k   \n",
      "300_block_list.7.sa.head_list.4.Linear_query        [16, 256, 64]     32.768k   \n",
      "301_block_list.7.sa.head_list.4.Linear_value        [16, 256, 64]     32.768k   \n",
      "302_block_list.7.sa.head_list.4.Dropout_dropout    [16, 256, 256]           -   \n",
      "303_block_list.7.sa.head_list.5.Linear_key          [16, 256, 64]     32.768k   \n",
      "304_block_list.7.sa.head_list.5.Linear_query        [16, 256, 64]     32.768k   \n",
      "305_block_list.7.sa.head_list.5.Linear_value        [16, 256, 64]     32.768k   \n",
      "306_block_list.7.sa.head_list.5.Dropout_dropout    [16, 256, 256]           -   \n",
      "307_block_list.7.sa.head_list.6.Linear_key          [16, 256, 64]     32.768k   \n",
      "308_block_list.7.sa.head_list.6.Linear_query        [16, 256, 64]     32.768k   \n",
      "309_block_list.7.sa.head_list.6.Linear_value        [16, 256, 64]     32.768k   \n",
      "310_block_list.7.sa.head_list.6.Dropout_dropout    [16, 256, 256]           -   \n",
      "311_block_list.7.sa.head_list.7.Linear_key          [16, 256, 64]     32.768k   \n",
      "312_block_list.7.sa.head_list.7.Linear_query        [16, 256, 64]     32.768k   \n",
      "313_block_list.7.sa.head_list.7.Linear_value        [16, 256, 64]     32.768k   \n",
      "314_block_list.7.sa.head_list.7.Dropout_dropout    [16, 256, 256]           -   \n",
      "315_block_list.7.sa.Linear_proj                    [16, 256, 512]    262.656k   \n",
      "316_block_list.7.sa.Dropout_dropout                [16, 256, 512]           -   \n",
      "317_block_list.7.LayerNorm_ln2                     [16, 256, 512]      1.024k   \n",
      "318_block_list.7.ff.layers.Linear_0               [16, 256, 2048]   1.050624M   \n",
      "319_block_list.7.ff.layers.GELU_1                 [16, 256, 2048]           -   \n",
      "320_block_list.7.ff.layers.Linear_2                [16, 256, 512]   1.049088M   \n",
      "321_block_list.7.ff.layers.Dropout_3               [16, 256, 512]           -   \n",
      "322_final_ln                                       [16, 256, 512]      1.024k   \n",
      "323_lm_head                                      [16, 256, 50257]  25.781841M   \n",
      "\n",
      "                                                  Mult-Adds  \n",
      "Layer                                                        \n",
      "0_token_embeddings                               25.731584M  \n",
      "1_position_embeddings                              131.072k  \n",
      "2_block_list.0.LayerNorm_ln1                          512.0  \n",
      "3_block_list.0.sa.head_list.0.Linear_key            32.768k  \n",
      "4_block_list.0.sa.head_list.0.Linear_query          32.768k  \n",
      "5_block_list.0.sa.head_list.0.Linear_value          32.768k  \n",
      "6_block_list.0.sa.head_list.0.Dropout_dropout             -  \n",
      "7_block_list.0.sa.head_list.1.Linear_key            32.768k  \n",
      "8_block_list.0.sa.head_list.1.Linear_query          32.768k  \n",
      "9_block_list.0.sa.head_list.1.Linear_value          32.768k  \n",
      "10_block_list.0.sa.head_list.1.Dropout_dropout            -  \n",
      "11_block_list.0.sa.head_list.2.Linear_key           32.768k  \n",
      "12_block_list.0.sa.head_list.2.Linear_query         32.768k  \n",
      "13_block_list.0.sa.head_list.2.Linear_value         32.768k  \n",
      "14_block_list.0.sa.head_list.2.Dropout_dropout            -  \n",
      "15_block_list.0.sa.head_list.3.Linear_key           32.768k  \n",
      "16_block_list.0.sa.head_list.3.Linear_query         32.768k  \n",
      "17_block_list.0.sa.head_list.3.Linear_value         32.768k  \n",
      "18_block_list.0.sa.head_list.3.Dropout_dropout            -  \n",
      "19_block_list.0.sa.head_list.4.Linear_key           32.768k  \n",
      "20_block_list.0.sa.head_list.4.Linear_query         32.768k  \n",
      "21_block_list.0.sa.head_list.4.Linear_value         32.768k  \n",
      "22_block_list.0.sa.head_list.4.Dropout_dropout            -  \n",
      "23_block_list.0.sa.head_list.5.Linear_key           32.768k  \n",
      "24_block_list.0.sa.head_list.5.Linear_query         32.768k  \n",
      "25_block_list.0.sa.head_list.5.Linear_value         32.768k  \n",
      "26_block_list.0.sa.head_list.5.Dropout_dropout            -  \n",
      "27_block_list.0.sa.head_list.6.Linear_key           32.768k  \n",
      "28_block_list.0.sa.head_list.6.Linear_query         32.768k  \n",
      "29_block_list.0.sa.head_list.6.Linear_value         32.768k  \n",
      "30_block_list.0.sa.head_list.6.Dropout_dropout            -  \n",
      "31_block_list.0.sa.head_list.7.Linear_key           32.768k  \n",
      "32_block_list.0.sa.head_list.7.Linear_query         32.768k  \n",
      "33_block_list.0.sa.head_list.7.Linear_value         32.768k  \n",
      "34_block_list.0.sa.head_list.7.Dropout_dropout            -  \n",
      "35_block_list.0.sa.Linear_proj                     262.144k  \n",
      "36_block_list.0.sa.Dropout_dropout                        -  \n",
      "37_block_list.0.LayerNorm_ln2                         512.0  \n",
      "38_block_list.0.ff.layers.Linear_0                1.048576M  \n",
      "39_block_list.0.ff.layers.GELU_1                          -  \n",
      "40_block_list.0.ff.layers.Linear_2                1.048576M  \n",
      "41_block_list.0.ff.layers.Dropout_3                       -  \n",
      "42_block_list.1.LayerNorm_ln1                         512.0  \n",
      "43_block_list.1.sa.head_list.0.Linear_key           32.768k  \n",
      "44_block_list.1.sa.head_list.0.Linear_query         32.768k  \n",
      "45_block_list.1.sa.head_list.0.Linear_value         32.768k  \n",
      "46_block_list.1.sa.head_list.0.Dropout_dropout            -  \n",
      "47_block_list.1.sa.head_list.1.Linear_key           32.768k  \n",
      "48_block_list.1.sa.head_list.1.Linear_query         32.768k  \n",
      "49_block_list.1.sa.head_list.1.Linear_value         32.768k  \n",
      "50_block_list.1.sa.head_list.1.Dropout_dropout            -  \n",
      "51_block_list.1.sa.head_list.2.Linear_key           32.768k  \n",
      "52_block_list.1.sa.head_list.2.Linear_query         32.768k  \n",
      "53_block_list.1.sa.head_list.2.Linear_value         32.768k  \n",
      "54_block_list.1.sa.head_list.2.Dropout_dropout            -  \n",
      "55_block_list.1.sa.head_list.3.Linear_key           32.768k  \n",
      "56_block_list.1.sa.head_list.3.Linear_query         32.768k  \n",
      "57_block_list.1.sa.head_list.3.Linear_value         32.768k  \n",
      "58_block_list.1.sa.head_list.3.Dropout_dropout            -  \n",
      "59_block_list.1.sa.head_list.4.Linear_key           32.768k  \n",
      "60_block_list.1.sa.head_list.4.Linear_query         32.768k  \n",
      "61_block_list.1.sa.head_list.4.Linear_value         32.768k  \n",
      "62_block_list.1.sa.head_list.4.Dropout_dropout            -  \n",
      "63_block_list.1.sa.head_list.5.Linear_key           32.768k  \n",
      "64_block_list.1.sa.head_list.5.Linear_query         32.768k  \n",
      "65_block_list.1.sa.head_list.5.Linear_value         32.768k  \n",
      "66_block_list.1.sa.head_list.5.Dropout_dropout            -  \n",
      "67_block_list.1.sa.head_list.6.Linear_key           32.768k  \n",
      "68_block_list.1.sa.head_list.6.Linear_query         32.768k  \n",
      "69_block_list.1.sa.head_list.6.Linear_value         32.768k  \n",
      "70_block_list.1.sa.head_list.6.Dropout_dropout            -  \n",
      "71_block_list.1.sa.head_list.7.Linear_key           32.768k  \n",
      "72_block_list.1.sa.head_list.7.Linear_query         32.768k  \n",
      "73_block_list.1.sa.head_list.7.Linear_value         32.768k  \n",
      "74_block_list.1.sa.head_list.7.Dropout_dropout            -  \n",
      "75_block_list.1.sa.Linear_proj                     262.144k  \n",
      "76_block_list.1.sa.Dropout_dropout                        -  \n",
      "77_block_list.1.LayerNorm_ln2                         512.0  \n",
      "78_block_list.1.ff.layers.Linear_0                1.048576M  \n",
      "79_block_list.1.ff.layers.GELU_1                          -  \n",
      "80_block_list.1.ff.layers.Linear_2                1.048576M  \n",
      "81_block_list.1.ff.layers.Dropout_3                       -  \n",
      "82_block_list.2.LayerNorm_ln1                         512.0  \n",
      "83_block_list.2.sa.head_list.0.Linear_key           32.768k  \n",
      "84_block_list.2.sa.head_list.0.Linear_query         32.768k  \n",
      "85_block_list.2.sa.head_list.0.Linear_value         32.768k  \n",
      "86_block_list.2.sa.head_list.0.Dropout_dropout            -  \n",
      "87_block_list.2.sa.head_list.1.Linear_key           32.768k  \n",
      "88_block_list.2.sa.head_list.1.Linear_query         32.768k  \n",
      "89_block_list.2.sa.head_list.1.Linear_value         32.768k  \n",
      "90_block_list.2.sa.head_list.1.Dropout_dropout            -  \n",
      "91_block_list.2.sa.head_list.2.Linear_key           32.768k  \n",
      "92_block_list.2.sa.head_list.2.Linear_query         32.768k  \n",
      "93_block_list.2.sa.head_list.2.Linear_value         32.768k  \n",
      "94_block_list.2.sa.head_list.2.Dropout_dropout            -  \n",
      "95_block_list.2.sa.head_list.3.Linear_key           32.768k  \n",
      "96_block_list.2.sa.head_list.3.Linear_query         32.768k  \n",
      "97_block_list.2.sa.head_list.3.Linear_value         32.768k  \n",
      "98_block_list.2.sa.head_list.3.Dropout_dropout            -  \n",
      "99_block_list.2.sa.head_list.4.Linear_key           32.768k  \n",
      "100_block_list.2.sa.head_list.4.Linear_query        32.768k  \n",
      "101_block_list.2.sa.head_list.4.Linear_value        32.768k  \n",
      "102_block_list.2.sa.head_list.4.Dropout_dropout           -  \n",
      "103_block_list.2.sa.head_list.5.Linear_key          32.768k  \n",
      "104_block_list.2.sa.head_list.5.Linear_query        32.768k  \n",
      "105_block_list.2.sa.head_list.5.Linear_value        32.768k  \n",
      "106_block_list.2.sa.head_list.5.Dropout_dropout           -  \n",
      "107_block_list.2.sa.head_list.6.Linear_key          32.768k  \n",
      "108_block_list.2.sa.head_list.6.Linear_query        32.768k  \n",
      "109_block_list.2.sa.head_list.6.Linear_value        32.768k  \n",
      "110_block_list.2.sa.head_list.6.Dropout_dropout           -  \n",
      "111_block_list.2.sa.head_list.7.Linear_key          32.768k  \n",
      "112_block_list.2.sa.head_list.7.Linear_query        32.768k  \n",
      "113_block_list.2.sa.head_list.7.Linear_value        32.768k  \n",
      "114_block_list.2.sa.head_list.7.Dropout_dropout           -  \n",
      "115_block_list.2.sa.Linear_proj                    262.144k  \n",
      "116_block_list.2.sa.Dropout_dropout                       -  \n",
      "117_block_list.2.LayerNorm_ln2                        512.0  \n",
      "118_block_list.2.ff.layers.Linear_0               1.048576M  \n",
      "119_block_list.2.ff.layers.GELU_1                         -  \n",
      "120_block_list.2.ff.layers.Linear_2               1.048576M  \n",
      "121_block_list.2.ff.layers.Dropout_3                      -  \n",
      "122_block_list.3.LayerNorm_ln1                        512.0  \n",
      "123_block_list.3.sa.head_list.0.Linear_key          32.768k  \n",
      "124_block_list.3.sa.head_list.0.Linear_query        32.768k  \n",
      "125_block_list.3.sa.head_list.0.Linear_value        32.768k  \n",
      "126_block_list.3.sa.head_list.0.Dropout_dropout           -  \n",
      "127_block_list.3.sa.head_list.1.Linear_key          32.768k  \n",
      "128_block_list.3.sa.head_list.1.Linear_query        32.768k  \n",
      "129_block_list.3.sa.head_list.1.Linear_value        32.768k  \n",
      "130_block_list.3.sa.head_list.1.Dropout_dropout           -  \n",
      "131_block_list.3.sa.head_list.2.Linear_key          32.768k  \n",
      "132_block_list.3.sa.head_list.2.Linear_query        32.768k  \n",
      "133_block_list.3.sa.head_list.2.Linear_value        32.768k  \n",
      "134_block_list.3.sa.head_list.2.Dropout_dropout           -  \n",
      "135_block_list.3.sa.head_list.3.Linear_key          32.768k  \n",
      "136_block_list.3.sa.head_list.3.Linear_query        32.768k  \n",
      "137_block_list.3.sa.head_list.3.Linear_value        32.768k  \n",
      "138_block_list.3.sa.head_list.3.Dropout_dropout           -  \n",
      "139_block_list.3.sa.head_list.4.Linear_key          32.768k  \n",
      "140_block_list.3.sa.head_list.4.Linear_query        32.768k  \n",
      "141_block_list.3.sa.head_list.4.Linear_value        32.768k  \n",
      "142_block_list.3.sa.head_list.4.Dropout_dropout           -  \n",
      "143_block_list.3.sa.head_list.5.Linear_key          32.768k  \n",
      "144_block_list.3.sa.head_list.5.Linear_query        32.768k  \n",
      "145_block_list.3.sa.head_list.5.Linear_value        32.768k  \n",
      "146_block_list.3.sa.head_list.5.Dropout_dropout           -  \n",
      "147_block_list.3.sa.head_list.6.Linear_key          32.768k  \n",
      "148_block_list.3.sa.head_list.6.Linear_query        32.768k  \n",
      "149_block_list.3.sa.head_list.6.Linear_value        32.768k  \n",
      "150_block_list.3.sa.head_list.6.Dropout_dropout           -  \n",
      "151_block_list.3.sa.head_list.7.Linear_key          32.768k  \n",
      "152_block_list.3.sa.head_list.7.Linear_query        32.768k  \n",
      "153_block_list.3.sa.head_list.7.Linear_value        32.768k  \n",
      "154_block_list.3.sa.head_list.7.Dropout_dropout           -  \n",
      "155_block_list.3.sa.Linear_proj                    262.144k  \n",
      "156_block_list.3.sa.Dropout_dropout                       -  \n",
      "157_block_list.3.LayerNorm_ln2                        512.0  \n",
      "158_block_list.3.ff.layers.Linear_0               1.048576M  \n",
      "159_block_list.3.ff.layers.GELU_1                         -  \n",
      "160_block_list.3.ff.layers.Linear_2               1.048576M  \n",
      "161_block_list.3.ff.layers.Dropout_3                      -  \n",
      "162_block_list.4.LayerNorm_ln1                        512.0  \n",
      "163_block_list.4.sa.head_list.0.Linear_key          32.768k  \n",
      "164_block_list.4.sa.head_list.0.Linear_query        32.768k  \n",
      "165_block_list.4.sa.head_list.0.Linear_value        32.768k  \n",
      "166_block_list.4.sa.head_list.0.Dropout_dropout           -  \n",
      "167_block_list.4.sa.head_list.1.Linear_key          32.768k  \n",
      "168_block_list.4.sa.head_list.1.Linear_query        32.768k  \n",
      "169_block_list.4.sa.head_list.1.Linear_value        32.768k  \n",
      "170_block_list.4.sa.head_list.1.Dropout_dropout           -  \n",
      "171_block_list.4.sa.head_list.2.Linear_key          32.768k  \n",
      "172_block_list.4.sa.head_list.2.Linear_query        32.768k  \n",
      "173_block_list.4.sa.head_list.2.Linear_value        32.768k  \n",
      "174_block_list.4.sa.head_list.2.Dropout_dropout           -  \n",
      "175_block_list.4.sa.head_list.3.Linear_key          32.768k  \n",
      "176_block_list.4.sa.head_list.3.Linear_query        32.768k  \n",
      "177_block_list.4.sa.head_list.3.Linear_value        32.768k  \n",
      "178_block_list.4.sa.head_list.3.Dropout_dropout           -  \n",
      "179_block_list.4.sa.head_list.4.Linear_key          32.768k  \n",
      "180_block_list.4.sa.head_list.4.Linear_query        32.768k  \n",
      "181_block_list.4.sa.head_list.4.Linear_value        32.768k  \n",
      "182_block_list.4.sa.head_list.4.Dropout_dropout           -  \n",
      "183_block_list.4.sa.head_list.5.Linear_key          32.768k  \n",
      "184_block_list.4.sa.head_list.5.Linear_query        32.768k  \n",
      "185_block_list.4.sa.head_list.5.Linear_value        32.768k  \n",
      "186_block_list.4.sa.head_list.5.Dropout_dropout           -  \n",
      "187_block_list.4.sa.head_list.6.Linear_key          32.768k  \n",
      "188_block_list.4.sa.head_list.6.Linear_query        32.768k  \n",
      "189_block_list.4.sa.head_list.6.Linear_value        32.768k  \n",
      "190_block_list.4.sa.head_list.6.Dropout_dropout           -  \n",
      "191_block_list.4.sa.head_list.7.Linear_key          32.768k  \n",
      "192_block_list.4.sa.head_list.7.Linear_query        32.768k  \n",
      "193_block_list.4.sa.head_list.7.Linear_value        32.768k  \n",
      "194_block_list.4.sa.head_list.7.Dropout_dropout           -  \n",
      "195_block_list.4.sa.Linear_proj                    262.144k  \n",
      "196_block_list.4.sa.Dropout_dropout                       -  \n",
      "197_block_list.4.LayerNorm_ln2                        512.0  \n",
      "198_block_list.4.ff.layers.Linear_0               1.048576M  \n",
      "199_block_list.4.ff.layers.GELU_1                         -  \n",
      "200_block_list.4.ff.layers.Linear_2               1.048576M  \n",
      "201_block_list.4.ff.layers.Dropout_3                      -  \n",
      "202_block_list.5.LayerNorm_ln1                        512.0  \n",
      "203_block_list.5.sa.head_list.0.Linear_key          32.768k  \n",
      "204_block_list.5.sa.head_list.0.Linear_query        32.768k  \n",
      "205_block_list.5.sa.head_list.0.Linear_value        32.768k  \n",
      "206_block_list.5.sa.head_list.0.Dropout_dropout           -  \n",
      "207_block_list.5.sa.head_list.1.Linear_key          32.768k  \n",
      "208_block_list.5.sa.head_list.1.Linear_query        32.768k  \n",
      "209_block_list.5.sa.head_list.1.Linear_value        32.768k  \n",
      "210_block_list.5.sa.head_list.1.Dropout_dropout           -  \n",
      "211_block_list.5.sa.head_list.2.Linear_key          32.768k  \n",
      "212_block_list.5.sa.head_list.2.Linear_query        32.768k  \n",
      "213_block_list.5.sa.head_list.2.Linear_value        32.768k  \n",
      "214_block_list.5.sa.head_list.2.Dropout_dropout           -  \n",
      "215_block_list.5.sa.head_list.3.Linear_key          32.768k  \n",
      "216_block_list.5.sa.head_list.3.Linear_query        32.768k  \n",
      "217_block_list.5.sa.head_list.3.Linear_value        32.768k  \n",
      "218_block_list.5.sa.head_list.3.Dropout_dropout           -  \n",
      "219_block_list.5.sa.head_list.4.Linear_key          32.768k  \n",
      "220_block_list.5.sa.head_list.4.Linear_query        32.768k  \n",
      "221_block_list.5.sa.head_list.4.Linear_value        32.768k  \n",
      "222_block_list.5.sa.head_list.4.Dropout_dropout           -  \n",
      "223_block_list.5.sa.head_list.5.Linear_key          32.768k  \n",
      "224_block_list.5.sa.head_list.5.Linear_query        32.768k  \n",
      "225_block_list.5.sa.head_list.5.Linear_value        32.768k  \n",
      "226_block_list.5.sa.head_list.5.Dropout_dropout           -  \n",
      "227_block_list.5.sa.head_list.6.Linear_key          32.768k  \n",
      "228_block_list.5.sa.head_list.6.Linear_query        32.768k  \n",
      "229_block_list.5.sa.head_list.6.Linear_value        32.768k  \n",
      "230_block_list.5.sa.head_list.6.Dropout_dropout           -  \n",
      "231_block_list.5.sa.head_list.7.Linear_key          32.768k  \n",
      "232_block_list.5.sa.head_list.7.Linear_query        32.768k  \n",
      "233_block_list.5.sa.head_list.7.Linear_value        32.768k  \n",
      "234_block_list.5.sa.head_list.7.Dropout_dropout           -  \n",
      "235_block_list.5.sa.Linear_proj                    262.144k  \n",
      "236_block_list.5.sa.Dropout_dropout                       -  \n",
      "237_block_list.5.LayerNorm_ln2                        512.0  \n",
      "238_block_list.5.ff.layers.Linear_0               1.048576M  \n",
      "239_block_list.5.ff.layers.GELU_1                         -  \n",
      "240_block_list.5.ff.layers.Linear_2               1.048576M  \n",
      "241_block_list.5.ff.layers.Dropout_3                      -  \n",
      "242_block_list.6.LayerNorm_ln1                        512.0  \n",
      "243_block_list.6.sa.head_list.0.Linear_key          32.768k  \n",
      "244_block_list.6.sa.head_list.0.Linear_query        32.768k  \n",
      "245_block_list.6.sa.head_list.0.Linear_value        32.768k  \n",
      "246_block_list.6.sa.head_list.0.Dropout_dropout           -  \n",
      "247_block_list.6.sa.head_list.1.Linear_key          32.768k  \n",
      "248_block_list.6.sa.head_list.1.Linear_query        32.768k  \n",
      "249_block_list.6.sa.head_list.1.Linear_value        32.768k  \n",
      "250_block_list.6.sa.head_list.1.Dropout_dropout           -  \n",
      "251_block_list.6.sa.head_list.2.Linear_key          32.768k  \n",
      "252_block_list.6.sa.head_list.2.Linear_query        32.768k  \n",
      "253_block_list.6.sa.head_list.2.Linear_value        32.768k  \n",
      "254_block_list.6.sa.head_list.2.Dropout_dropout           -  \n",
      "255_block_list.6.sa.head_list.3.Linear_key          32.768k  \n",
      "256_block_list.6.sa.head_list.3.Linear_query        32.768k  \n",
      "257_block_list.6.sa.head_list.3.Linear_value        32.768k  \n",
      "258_block_list.6.sa.head_list.3.Dropout_dropout           -  \n",
      "259_block_list.6.sa.head_list.4.Linear_key          32.768k  \n",
      "260_block_list.6.sa.head_list.4.Linear_query        32.768k  \n",
      "261_block_list.6.sa.head_list.4.Linear_value        32.768k  \n",
      "262_block_list.6.sa.head_list.4.Dropout_dropout           -  \n",
      "263_block_list.6.sa.head_list.5.Linear_key          32.768k  \n",
      "264_block_list.6.sa.head_list.5.Linear_query        32.768k  \n",
      "265_block_list.6.sa.head_list.5.Linear_value        32.768k  \n",
      "266_block_list.6.sa.head_list.5.Dropout_dropout           -  \n",
      "267_block_list.6.sa.head_list.6.Linear_key          32.768k  \n",
      "268_block_list.6.sa.head_list.6.Linear_query        32.768k  \n",
      "269_block_list.6.sa.head_list.6.Linear_value        32.768k  \n",
      "270_block_list.6.sa.head_list.6.Dropout_dropout           -  \n",
      "271_block_list.6.sa.head_list.7.Linear_key          32.768k  \n",
      "272_block_list.6.sa.head_list.7.Linear_query        32.768k  \n",
      "273_block_list.6.sa.head_list.7.Linear_value        32.768k  \n",
      "274_block_list.6.sa.head_list.7.Dropout_dropout           -  \n",
      "275_block_list.6.sa.Linear_proj                    262.144k  \n",
      "276_block_list.6.sa.Dropout_dropout                       -  \n",
      "277_block_list.6.LayerNorm_ln2                        512.0  \n",
      "278_block_list.6.ff.layers.Linear_0               1.048576M  \n",
      "279_block_list.6.ff.layers.GELU_1                         -  \n",
      "280_block_list.6.ff.layers.Linear_2               1.048576M  \n",
      "281_block_list.6.ff.layers.Dropout_3                      -  \n",
      "282_block_list.7.LayerNorm_ln1                        512.0  \n",
      "283_block_list.7.sa.head_list.0.Linear_key          32.768k  \n",
      "284_block_list.7.sa.head_list.0.Linear_query        32.768k  \n",
      "285_block_list.7.sa.head_list.0.Linear_value        32.768k  \n",
      "286_block_list.7.sa.head_list.0.Dropout_dropout           -  \n",
      "287_block_list.7.sa.head_list.1.Linear_key          32.768k  \n",
      "288_block_list.7.sa.head_list.1.Linear_query        32.768k  \n",
      "289_block_list.7.sa.head_list.1.Linear_value        32.768k  \n",
      "290_block_list.7.sa.head_list.1.Dropout_dropout           -  \n",
      "291_block_list.7.sa.head_list.2.Linear_key          32.768k  \n",
      "292_block_list.7.sa.head_list.2.Linear_query        32.768k  \n",
      "293_block_list.7.sa.head_list.2.Linear_value        32.768k  \n",
      "294_block_list.7.sa.head_list.2.Dropout_dropout           -  \n",
      "295_block_list.7.sa.head_list.3.Linear_key          32.768k  \n",
      "296_block_list.7.sa.head_list.3.Linear_query        32.768k  \n",
      "297_block_list.7.sa.head_list.3.Linear_value        32.768k  \n",
      "298_block_list.7.sa.head_list.3.Dropout_dropout           -  \n",
      "299_block_list.7.sa.head_list.4.Linear_key          32.768k  \n",
      "300_block_list.7.sa.head_list.4.Linear_query        32.768k  \n",
      "301_block_list.7.sa.head_list.4.Linear_value        32.768k  \n",
      "302_block_list.7.sa.head_list.4.Dropout_dropout           -  \n",
      "303_block_list.7.sa.head_list.5.Linear_key          32.768k  \n",
      "304_block_list.7.sa.head_list.5.Linear_query        32.768k  \n",
      "305_block_list.7.sa.head_list.5.Linear_value        32.768k  \n",
      "306_block_list.7.sa.head_list.5.Dropout_dropout           -  \n",
      "307_block_list.7.sa.head_list.6.Linear_key          32.768k  \n",
      "308_block_list.7.sa.head_list.6.Linear_query        32.768k  \n",
      "309_block_list.7.sa.head_list.6.Linear_value        32.768k  \n",
      "310_block_list.7.sa.head_list.6.Dropout_dropout           -  \n",
      "311_block_list.7.sa.head_list.7.Linear_key          32.768k  \n",
      "312_block_list.7.sa.head_list.7.Linear_query        32.768k  \n",
      "313_block_list.7.sa.head_list.7.Linear_value        32.768k  \n",
      "314_block_list.7.sa.head_list.7.Dropout_dropout           -  \n",
      "315_block_list.7.sa.Linear_proj                    262.144k  \n",
      "316_block_list.7.sa.Dropout_dropout                       -  \n",
      "317_block_list.7.LayerNorm_ln2                        512.0  \n",
      "318_block_list.7.ff.layers.Linear_0               1.048576M  \n",
      "319_block_list.7.ff.layers.GELU_1                         -  \n",
      "320_block_list.7.ff.layers.Linear_2               1.048576M  \n",
      "321_block_list.7.ff.layers.Dropout_3                      -  \n",
      "322_final_ln                                          512.0  \n",
      "323_lm_head                                      25.731584M  \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "                          Totals\n",
      "Total params          76.852305M\n",
      "Trainable params      76.852305M\n",
      "Non-trainable params         0.0\n",
      "Mult-Adds             76.768768M\n",
      "=======================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssg2/miniconda3/envs/idl/lib/python3.8/site-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: The default value of numeric_only in DataFrame.sum is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df_sum = df.sum()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_token_embeddings</th>\n",
       "      <td>[512, 50257]</td>\n",
       "      <td>[16, 256, 512]</td>\n",
       "      <td>25731584.0</td>\n",
       "      <td>25731584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_position_embeddings</th>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[256, 512]</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>131072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_block_list.0.LayerNorm_ln1</th>\n",
       "      <td>[512]</td>\n",
       "      <td>[16, 256, 512]</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_block_list.0.sa.head_list.0.Linear_key</th>\n",
       "      <td>[512, 64]</td>\n",
       "      <td>[16, 256, 64]</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>32768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_block_list.0.sa.head_list.0.Linear_query</th>\n",
       "      <td>[512, 64]</td>\n",
       "      <td>[16, 256, 64]</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>32768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319_block_list.7.ff.layers.GELU_1</th>\n",
       "      <td>-</td>\n",
       "      <td>[16, 256, 2048]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320_block_list.7.ff.layers.Linear_2</th>\n",
       "      <td>[2048, 512]</td>\n",
       "      <td>[16, 256, 512]</td>\n",
       "      <td>1049088.0</td>\n",
       "      <td>1048576.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321_block_list.7.ff.layers.Dropout_3</th>\n",
       "      <td>-</td>\n",
       "      <td>[16, 256, 512]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322_final_ln</th>\n",
       "      <td>[512]</td>\n",
       "      <td>[16, 256, 512]</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323_lm_head</th>\n",
       "      <td>[512, 50257]</td>\n",
       "      <td>[16, 256, 50257]</td>\n",
       "      <td>25781841.0</td>\n",
       "      <td>25731584.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Kernel Shape      Output Shape  \\\n",
       "Layer                                                                        \n",
       "0_token_embeddings                          [512, 50257]    [16, 256, 512]   \n",
       "1_position_embeddings                         [512, 256]        [256, 512]   \n",
       "2_block_list.0.LayerNorm_ln1                       [512]    [16, 256, 512]   \n",
       "3_block_list.0.sa.head_list.0.Linear_key       [512, 64]     [16, 256, 64]   \n",
       "4_block_list.0.sa.head_list.0.Linear_query     [512, 64]     [16, 256, 64]   \n",
       "...                                                  ...               ...   \n",
       "319_block_list.7.ff.layers.GELU_1                      -   [16, 256, 2048]   \n",
       "320_block_list.7.ff.layers.Linear_2          [2048, 512]    [16, 256, 512]   \n",
       "321_block_list.7.ff.layers.Dropout_3                   -    [16, 256, 512]   \n",
       "322_final_ln                                       [512]    [16, 256, 512]   \n",
       "323_lm_head                                 [512, 50257]  [16, 256, 50257]   \n",
       "\n",
       "                                                Params   Mult-Adds  \n",
       "Layer                                                               \n",
       "0_token_embeddings                          25731584.0  25731584.0  \n",
       "1_position_embeddings                         131072.0    131072.0  \n",
       "2_block_list.0.LayerNorm_ln1                    1024.0       512.0  \n",
       "3_block_list.0.sa.head_list.0.Linear_key       32768.0     32768.0  \n",
       "4_block_list.0.sa.head_list.0.Linear_query     32768.0     32768.0  \n",
       "...                                                ...         ...  \n",
       "319_block_list.7.ff.layers.GELU_1                  NaN         NaN  \n",
       "320_block_list.7.ff.layers.Linear_2          1049088.0   1048576.0  \n",
       "321_block_list.7.ff.layers.Dropout_3               NaN         NaN  \n",
       "322_final_ln                                    1024.0       512.0  \n",
       "323_lm_head                                 25781841.0  25731584.0  \n",
       "\n",
       "[324 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, xb.to(device), yb.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "eT5YkoSNQLUc"
   },
   "outputs": [],
   "source": [
    "# # poor man's lr scheduler. why? because cosine with warmup isn't readily available on torch (it's warm RESTARTS)\n",
    "# # but idc about restarting eh?\n",
    "# def get_lr(it):\n",
    "#     \"get lr at a specific iteration\"\n",
    "#     max_lr = config.lr\n",
    "#     min_lr = config.min_lr\n",
    "#     warmup_iters = config.warmup_iters\n",
    "#     max_lr_decay_iters = config.num_iters # can also be made into another param\n",
    "#     if it <= warmup_iters:\n",
    "#         return max_lr * (it / warmup_iters)\n",
    "\n",
    "#     if it > max_lr_decay_iters:\n",
    "#         # decaying only up to a certain point, interesting\n",
    "#         return min_lr\n",
    "#     ratio = (it - warmup_iters) / (max_lr_decay_iters - warmup_iters) # how much % of decay cycle is done?\n",
    "#     coeff = 0.5 * (1 + math.cos(math.pi * ratio)) # [0,1]\n",
    "#     return min_lr + coeff * (max_lr - min_lr) # beautiful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "9X5IiaarQLUc"
   },
   "outputs": [],
   "source": [
    "# def test_lr():\n",
    "#     import random\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     x = [i for i in range(0,10000,100)]\n",
    "#     y = [get_lr(i) for i in x]\n",
    "#     plt.plot(x, y)\n",
    "#     plt.show()\n",
    "\n",
    "# test_lr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "CVOkmmi_QLUc"
   },
   "outputs": [],
   "source": [
    "# '''\n",
    "# @torch.no_grad()\n",
    "# def estimate_losses(config):\n",
    "#     model.eval()\n",
    "#     losses = {'train': -1., 'val': -1.}\n",
    "#     for split in ['train', 'val']:\n",
    "#         loss = 0\n",
    "#         for _ in range(config.eval_iters):\n",
    "#             # xb, yb = next(iter(val_loader))\n",
    "#             # xb, yb = xb.to(device), yb.to(device)\n",
    "#             xb, yb = get_batch('val')\n",
    "#             loss += model(xb, yb)[1].item()\n",
    "#         loss /= config.eval_iters\n",
    "#         if split == 'train':\n",
    "#             losses['train'] = loss\n",
    "#         else:\n",
    "#             losses['val'] = loss\n",
    "#     model.train()\n",
    "#     return losses\n",
    "#     '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "47ZGa3tkMSAi"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_losses(config, train_loader, val_loader):\n",
    "    model.eval()\n",
    "    losses = {'train': -1., 'val': -1.}\n",
    "    # train_loss = 0\n",
    "    # train_iters = min(config.eval_iters, len(train_loader))\n",
    "    # for i, (xb, yb) in enumerate(train_loader):\n",
    "    #     if i >= train_iters:\n",
    "    #         break\n",
    "    #     xb, yb = xb.to(device), yb.to(device)\n",
    "    #     _, loss = model(xb, yb)\n",
    "    #     train_loss += loss.item()\n",
    "    # losses['train'] = train_loss / train_iters\n",
    "\n",
    "    # Evaluate validation loss (considering only config.eval_iters iterations)\n",
    "    val_loss = 0\n",
    "    val_iters = min(config.eval_iters, len(val_loader))\n",
    "    for i, (xb, yb) in enumerate(val_loader):\n",
    "        if i >= val_iters:\n",
    "            break\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        _, loss = model(xb, yb)\n",
    "        val_loss += loss.item()\n",
    "    losses['val'] = val_loss / val_iters\n",
    "\n",
    "    model.train()\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "kEvNGlwJ1aPr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Load Pretrained\n",
    "CKPT_PATH = 'exps/pretrain_v2/best_model.pth'\n",
    "ckpt = torch.load(CKPT_PATH)\n",
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJfqzDg2QLUc"
   },
   "source": [
    "## WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "no1t4aJ5QLUc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mssgandhi1\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/bos/tmp2/ssg2/idl/hw5/wandb/run-20240428_174748-h380wd4x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ssgandhi1/ideal_gpt/runs/h380wd4x' target=\"_blank\">finetune_try2</a></strong> to <a href='https://wandb.ai/ssgandhi1/ideal_gpt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ssgandhi1/ideal_gpt' target=\"_blank\">https://wandb.ai/ssgandhi1/ideal_gpt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ssgandhi1/ideal_gpt/runs/h380wd4x' target=\"_blank\">https://wandb.ai/ssgandhi1/ideal_gpt/runs/h380wd4x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wandb.login(key=\"8f970021374ae46aad44762a771dd8136c460b2d\")\n",
    "run = wandb.init(\n",
    "        name    = 'finetune_try2', ## Wandb creates random run names if you skip this field\n",
    "        reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
    "        # entity = 'thunderbuddies',\n",
    "        # run_id = ### Insert specific run id here if you want to resume a previous run\n",
    "        # resume = \"must\" ### You need this to resume previous runs, but comment out reinit = True when using this\n",
    "        project = \"ideal_gpt\", ### Project should be created in your wandb account\n",
    "        config = config, ### Wandb Config for your run,\n",
    "        # mode='disabled'\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "smwh3FSyQLUc"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start_ix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstart_ix\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'start_ix' is not defined"
     ]
    }
   ],
   "source": [
    "start_ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "XLdX2OG3QLUd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "cur_iter = 0\n",
    "best_val = 1e9\n",
    "best_path = 'finetune_best_model.pth'\n",
    "running_loss = 0.0\n",
    "loss_counter=0\n",
    "pbar = tqdm(total=config.num_iters, dynamic_ncols=True, leave=False, position=0, desc=\"Train\")\n",
    "e = 0\n",
    "cur_iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "N8rVNj48QLUc"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.finetune_lr, weight_decay=config.weight_decay)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader) * config.finetune_epochs, eta_min=1e-6)\n",
    "\n",
    "\n",
    "# for generation\n",
    "start_ix = torch.zeros((1,1), dtype=torch.long, device=device) # (newline character in a single batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.eval_interval = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   8%|▊         | 2000/24540 [08:05<1:31:05,  4.12it/s, loss=2.8509, lr=9.93e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val @ Epoch 4000: Train Loss=2.8509, Val Loss=2.8382\n",
      "Saved best model to finetune_best_model.pth\n",
      "Sample Generation\n",
      "!|system|>\n",
      "<|endoftext|>Summarize the following CNN article: (CNN) -- Palm tells you that after following the advice of colleagues and butler Hankinson, he isn't one of the better ones. Maybe he could even do an evening out. So, personal best wishes baby Mario 16, now known as too young, took her first letter from Ronnie Scott and wrote telling her how fantastic it would be. You know what? Jim Butler, the go-your-own guidebook can\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  16%|█▋        | 4000/24540 [16:14<1:23:20,  4.11it/s, loss=2.8260, lr=9.84e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val @ Epoch 6000: Train Loss=2.8260, Val Loss=2.8082\n",
      "Saved best model to finetune_best_model.pth\n",
      "Sample Generation\n",
      "!|system|>\n",
      "<|endoftext|>Police in Majestic province near Bengaluru, India, and the municipality of Jammu and Kashmir as well as Azad Kashmir and neighbouring states exited into the Indian Ocean. The federal government of India (Erdotō Moedai) denied (and tendence) the arrest of the alleged 3rd Charged Bankers of Delhi or the first Manorte (BID) by the Central Control Board along with the stated apologetic nebul (KIN),\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  24%|██▍       | 6000/24540 [24:24<1:15:00,  4.12it/s, loss=2.8088, lr=9.71e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val @ Epoch 8000: Train Loss=2.8088, Val Loss=2.7905\n",
      "Saved best model to finetune_best_model.pth\n",
      "Sample Generation\n",
      "!|system|>\n",
      "<|endoftext|>Mali President Mikael Mogilov says the conflict in Libya ended up being the greatest civil war that he has seen since the fall of Gaddafi and his political<|endoftext|>A member of the Prime Minister's Cabinet has voiced his Viewpoint position on Libya, so long as he ends with statements like 'betterUseOne'\" in which he said misleading opposition of arms blasting abroad. The president was nominated for a Cabinet position in July by a narrow margin, but was seriously questioned by\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  33%|███▎      | 8000/24540 [36:41<2:01:48,  2.26it/s, loss=2.7961, lr=9.56e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val @ Epoch 10000: Train Loss=2.7961, Val Loss=2.7886\n",
      "Saved best model to finetune_best_model.pth\n",
      "Sample Generation\n",
      "!|system|>\n",
      "<|endoftext|>Key points: A series of expensive delays on Thanksgiving Wednesday more than half of the 50 minutes work scheduled to start for the Thanksgiving Day subseason. Career service in a number of the last four weeks ended before Lights Up, which fell spectacularly across the interior of mid-October, and accounted for one-fifth of a second of a<|endoftext|>New York's masters Houses of Congress raise funds for infrastructure workers thank Youc Con for building concessions and earning them commissioning vast add\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  41%|████      | 10000/24540 [45:17<58:51,  4.12it/s, loss=2.7847, lr=9.37e-5] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val @ Epoch 12000: Train Loss=2.7847, Val Loss=2.7814\n",
      "Saved best model to finetune_best_model.pth\n",
      "Sample Generation\n",
      "!|system|>\n",
      "<|endoftext|>Montevideo,_ Venezuelans, the Allies in the Luhansk administration list Latin saints as 51/50. According to the official figures by the International Council for Religious Death (ICRIC) in 24 hours, the Unknown ThirteenOrders number 49 in the following denominations: two Episcopalians, one born into the investigation of the conflict in Colombia (Anger, Cunha); two Americans, an Italian Asylum inmate of the United States, a Scottish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  49%|████▉     | 12000/24540 [53:26<50:37,  4.13it/s, loss=2.7749, lr=9.14e-5]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val @ Epoch 14000: Train Loss=2.7749, Val Loss=2.7780\n",
      "Saved best model to finetune_best_model.pth\n",
      "Sample Generation\n",
      "!|system|>\n",
      "<|endoftext|>Summarize the following CNN article: Docks and flights are at a phenomenal speed as customers aboard Air France travel to Disney World in France, according to the National Grid corporation subsidiary. Most international airlines carry Moroccan software with their own complaining about weather forecasts, on 26 of which the UK gets promoted to per Devil January 1. But in the UK, it is an annual scrutiny rate of 1,750. for Air France flights, according to.ac UK ratings STAR bulb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  57%|█████▋    | 14000/24540 [1:01:35<42:40,  4.12it/s, loss=2.7666, lr=8.89e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val @ Epoch 16000: Train Loss=2.7666, Val Loss=2.7669\n",
      "Saved best model to finetune_best_model.pth\n",
      "Sample Generation\n",
      "!|system|>\n",
      "<|endoftext|>It's been one of Anne Britain's most important cultural traits by Periodic Eysen Bowers' domination of life has Romulus Castellum for the first time and her last constituting an urban artist and philosopher. In Romulus and his Friends in Gillingham, Charshaw delineates the primacy between architecture and architecture on the twenty-fourth. No heritage is given and all humans have connections, cities or towns. The monasteries (names then\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  65%|██████▌   | 16000/24540 [1:09:44<34:31,  4.12it/s, loss=2.7589, lr=8.61e-5]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val @ Epoch 18000: Train Loss=2.7589, Val Loss=2.7702\n",
      "Sample Generation\n",
      "!|system|>\n",
      "<|endoftext|>Benjamin Maye for a political fight against cancer and the anti-poison claim claiming that mammoths would help the diseases cause high obesity rates. researchers this week said the reason that the battle against cancer were caused by these claims reflected the horrifically morbidity and desperation of British women from colonisation. He insisted critics had managed to calm the situation down South Korea because clinical scientists rather than textured cells could be counted to accommodate disease. Some recent research suggested that the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  73%|███████▎  | 18000/24540 [1:17:52<26:20,  4.14it/s, loss=2.7523, lr=8.3e-5]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val @ Epoch 20000: Train Loss=2.7523, Val Loss=2.7665\n",
      "Saved best model to finetune_best_model.pth\n",
      "Sample Generation\n",
      "!|system|>\n",
      "<|endoftext|><<|endoftext|>There's been controversy over the Census Ise Gymnastics is popular and happened to programme journalist and radio personality Louise Mensch. The manipulation focus on championships of higher and middle class Hockey, with New Year General, Croydon, Cardiff and San Marino having had an employment association run by Mensch running the show and positive events. Gymnastic friendships are common among PGA users, particularly after the Melbourne Open, and times when Wimbledon was also a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  81%|████████▏ | 20000/24540 [1:26:01<18:21,  4.12it/s, loss=2.7458, lr=7.97e-5] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val @ Epoch 22000: Train Loss=2.7458, Val Loss=2.7705\n",
      "Sample Generation\n",
      "!|system|>\n",
      "<|endoftext|>What's the sentiment of the sentence it does not think it has a good reputation following Russia's Moslem war in 1918, however, she has dismissed the appeal'. She has denied concerns about Russian-backed separatists trying to oust President Putin at international airports as a pretext for sanctions against Moscow and has denied they were uprooted. In Moscow her membership could be revoked. In a statement the President called upon Russia to'restart’ the Germans who had annexed Afghanistan in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  90%|████████▉ | 22000/24540 [1:34:09<10:16,  4.12it/s, loss=2.7397, lr=7.62e-5]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val @ Epoch 24000: Train Loss=2.7397, Val Loss=2.7654\n",
      "Saved best model to finetune_best_model.pth\n",
      "Sample Generation\n",
      "!|system|>\n",
      "<|endoftext|>(<|endoftext|>Palm Park in the Newmarket railway station under the Strauss-Kahn act can be described as primitive, flying prints that stopped only for the surface to reveal and run in narrow service routes, in which case Piotr and Constantine consciously crashed, as Piotr inherited a unique type of groping which had become the means by which, at great Mahanzar, and others<|endoftext|>In the era of the Piotr Sam Dress Code, ladies often\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  98%|█████████▊| 24000/24540 [1:42:18<02:10,  4.13it/s, loss=2.7338, lr=7.25e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val @ Epoch 26000: Train Loss=2.7338, Val Loss=2.7654\n",
      "Sample Generation\n",
      "!|system|>\n",
      "<|endoftext|>’|user|>\n",
      "Summarize the following CNN article: A 'n Nutcracker' who stole £3million in lottery prize debts of more than 38 per cent, has filed a Destroyed Old Fillon pension to herself. Jeremiah topper, 48, claimed his employers raided their accounts minutes after collecting lump sum payments, and then left it all on a sofa in the house where he lived. Customers on his Isleworth work weekly, dressed in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   1%|          | 169/24540 [00:41<1:38:16,  4.13it/s, loss=2.7313, lr=7.12e-5]  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     scaler\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m     16\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), config\u001b[38;5;241m.\u001b[39mgrad_clip)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/idl/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:338\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 338\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/miniconda3/envs/idl/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:285\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m--> 285\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/miniconda3/envs/idl/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:65\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     64\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/idl/lib/python3.8/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/idl/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/idl/lib/python3.8/site-packages/torch/optim/adamw.py:161\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    157\u001b[0m             max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    159\u001b[0m         state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 161\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m          \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m          \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m          \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m          \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m          \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m          \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m          \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m          \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m          \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/idl/lib/python3.8/site-packages/torch/optim/adamw.py:218\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 218\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/idl/lib/python3.8/site-packages/torch/optim/adamw.py:266\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    263\u001b[0m param\u001b[38;5;241m.\u001b[39mmul_(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m lr \u001b[38;5;241m*\u001b[39m weight_decay)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(e, e+config.finetune_epochs):\n",
    "    steps = 0\n",
    "    pbar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc=\"Train\")\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        cur_lr = optimizer.param_groups[0]['lr']\n",
    "        with torch.cuda.amp.autocast():\n",
    "            logits, loss = model(xb, yb)\n",
    "        running_loss += loss.item()\n",
    "        train_loss = running_loss / (loss_counter + 1)\n",
    "        loss_counter += 1\n",
    "        scaler.scale(loss).backward()\n",
    "        if steps % config.gradient_accumulation_steps == 0:\n",
    "            if config.grad_clip != 0.0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip)\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            scheduler.step()\n",
    "        wandb.log({\n",
    "            'train_loss': train_loss,\n",
    "            'iter': cur_iter,\n",
    "            'lr': cur_lr\n",
    "        })\n",
    "        pbar.set_postfix(loss=\"{:.04f}\".format(train_loss), lr=cur_lr)\n",
    "        pbar.update()\n",
    "        cur_iter += 1\n",
    "        if cur_iter % config.eval_interval == 0:\n",
    "        \n",
    "            losses = estimate_losses(config, train_loader, val_loader)  # Now we pass val_loader to estimate_losses\n",
    "            val_loss = losses['val']\n",
    "            # train_loss = losses['train']\n",
    "            print(f'Val @ Epoch {cur_iter}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}')\n",
    "            wandb.log({\n",
    "                'val_loss': val_loss,\n",
    "                'iter': cur_iter,\n",
    "                'lr': optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "            if val_loss < best_val:\n",
    "                best_val = val_loss\n",
    "                torch.save(model.state_dict(), best_path)\n",
    "                print(f'Saved best model to {best_path}')\n",
    "            print('Sample Generation')\n",
    "            print(tokenizer.decode(model.generate(start_ix, 100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BRMAeKP5PfOJ",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "\n",
    "\n",
    "# NUM_EPOCHS=5\n",
    "# cur_iter=0\n",
    "\n",
    "# while cur_iter <= NUM_EPOCHS:\n",
    "#     optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "#     cur_lr = get_lr(curb_iter) if config.lr_decay else config.lr\n",
    "#     for param_group in optimizer.param_groups:\n",
    "#         param_group['lr'] = cur_lr\n",
    "\n",
    "#     # Iterate over batches from the DataLoader\n",
    "#     steps = 0\n",
    "#     for xb, yb in train_loader:\n",
    "#         xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "#         with torch.cuda.amp.autocast():\n",
    "#             logits, loss = model(xb, yb)\n",
    "#         running_loss += loss.item()\n",
    "#         train_loss = running_loss / (loss_counter + 1)\n",
    "#         loss_counter += 1\n",
    "\n",
    "#         scaler.scale(loss).backward()\n",
    "\n",
    "#         steps += 1\n",
    "#         if steps % config.gradient_accumulation_steps == 0:\n",
    "#             if config.grad_clip != 0.0:\n",
    "#                 scaler.unscale_(optimizer)\n",
    "#                 torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip)\n",
    "\n",
    "#             scaler.step(optimizer)\n",
    "#             scaler.update()\n",
    "#             optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "#         del xb, yb, logits, loss\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "#     if cur_iter % config.eval_interval == 0:\n",
    "#         losses = estimate_losses(config, train_loader, val_loader)  # Now we pass val_loader to estimate_losses\n",
    "#         val_loss = losses['val']\n",
    "#         train_loss = losses['train']\n",
    "#         print(f'Val @ Epoch {cur_iter}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}')\n",
    "#         wandb.log({\n",
    "#             'val_loss': val_loss,\n",
    "#             'iter': cur_iter,\n",
    "#             'lr': optimizer.param_groups[0]['lr']\n",
    "#         })\n",
    "#         if val_loss < best_val:\n",
    "#             best_val = val_loss\n",
    "#             torch.save(model.state_dict(), best_path)\n",
    "#             print(f'Saved best model to {best_path}')\n",
    "#         print('Sample Generation')\n",
    "#         print(tokenizer.decode(model.generate(start_ix, 100)[0].tolist()))\n",
    "\n",
    "#     # Log training metrics for current iteration\n",
    "#     wandb.log({\n",
    "#         'train_loss': train_loss,\n",
    "#         'iter': cur_iter,\n",
    "#         'lr': cur_lr\n",
    "#     })\n",
    "#     pbar.set_postfix(loss=\"{:.04f}\".format(train_loss), lr=cur_lr)\n",
    "#     pbar.update()\n",
    "\n",
    "#     cur_iter += 1  # Increment iteration count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "wgKbRvnvQLUd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!|system|>\n",
      "<|endoftext|>Miami Crater, Florida Crater, lies in 1924 Southern Florida lies approximately 62 miles (72 km) from Florida to Florida.[citation needed] In July, in May, a 7-feet (1.2) tour to help expand the Florida coastline entered into service as the U.S. Navy Air Arm is due to drop a 500-mile violation directive against commercial air traffic control airspace above the ocean line. On August 17, 1942, the United States\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(model.generate(start_ix, 100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNo-EkEkQLUd"
   },
   "outputs": [],
   "source": [
    "def prompt(p, max_len=100):\n",
    "    if not p:\n",
    "        print('Enter non-empty string!')\n",
    "        return\n",
    "\n",
    "    tokens = torch.tensor(tokenizer.encode_ordinary(p))\n",
    "    tokens = tokens.unsqueeze(0) # add batch dimension\n",
    "    tokens = tokens.to(device)\n",
    "    return tokenizer.decode(model.generate(tokens, max_len)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<|system|>\n",
    "<|endoftext|>\n",
    "<|user|>\n",
    "Summarize the following CNN article: Controversial CNN anchor Don Lemon has raised more eyebrows after inviting a member of the Ku Klux Klan to speak on his show about alleged racist chants by a fraternity at the University of Oklahoma. The news host interviewed James Moore, also known as Imperial Kludd of the Loyal White Knights, on his programme about race relations in America. The interview was conducted via Skype, with Moore in traditional KKK dress and sunglasses. CNN anchor Don Lemon interviewed a James Moore, also known as Imperial Kludd of the Loyal White Knights about race relations . It came as Mr Lemon attempted to talk to the KKK member about the controversy surrounding racist chanting by a fraternity at the University of Oklahoma and ongoing tension in Ferguson, Missouri. The exchange started with Moore claiming there were double standards when it came to race relations in unversities<|endoftext|>\n",
    "<|assistant|>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_seq):\n",
    "    prompt = prompt.strip() # remove leading and ending white spaces - leads to weird things\n",
    "    # Encode the prompt using the tokenizer\n",
    "\n",
    "    # chat_template = f\"<|system|>\\n<|endoftext|>\\n<|user|>\\n{' '.join(prompt.split()[:100])}<|endoftext|>\\n<|assistant|>\"    \n",
    "    chat_template = f\"<|user|>\\n{' '.join(prompt.split()[:100])}<|endoftext|>\\n<|assistant|>\"\n",
    "    prompt_tokens = tokenizer.encode(chat_template, return_tensors='pt').to(device)\n",
    "\n",
    "    # Generate text using the model\n",
    "    generated_tokens = model.generate(prompt_tokens, max_seq)\n",
    "\n",
    "    # Decode the tokens back to text\n",
    "    generated_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)  # Remove batch dimension\n",
    "\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(CNN)Share, and your gift will be multiplied. That may sound like an esoteric adage, but when Zully Broussard selflessly decided to give one of her kidneys to a stranger, her generosity paired up with big data. It resulted in six patients receiving transplants. That surprised and wowed her. \"I thought I was going to help this one person who I don\\'t know, but the fact that so many people can have a life extension, that\\'s pretty big,\" Broussard told CNN affiliate KGO. She may feel guided in her generosity by a higher power. \"Thanks for all the support and prayers,\" a comment on a Facebook page in her name read. \"I know this entire journey is much bigger than all of us. I also know I\\'m just the messenger.\" CNN cannot verify the authenticity of the page. But the power that multiplied Broussard\\'s gift was<|endoftext|>\\n<|assistant|>\\nZully Broussard decided to give a kidney to a stranger.\\nA new computer program helped her donation spur transplants for six kidney patients.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = '''(CNN)Share, and your gift will be multiplied. That may sound like an esoteric adage, but when Zully Broussard selflessly decided to give one of her kidneys to a stranger, her generosity paired up with big data. It resulted in six patients receiving transplants. That surprised and wowed her. \"I thought I was going to help this one person who I don\\'t know, but the fact that so many people can have a life extension, that\\'s pretty big,\" Broussard told CNN affiliate KGO. She may feel guided in her generosity by a higher power. \"Thanks for all the support and prayers,\" a comment on a Facebook page in her name read. \"I know this entire journey is much bigger than all of us. I also know I\\'m just the messenger.\" CNN cannot verify the authenticity of the page. But the power that multiplied Broussard\\'s gift was<|endoftext|>\\n<|assistant|>\\nZully Broussard decided to give a kidney to a stranger.\\nA new computer program helped her donation spur transplants for six kidney patients.'''\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|system|>\\n<|endoftext|>\\n<|user|>\\nSummarize the following CNN article: (CNN)Share, and your gift will be multiplied. That may sound like an esoteric adage, but when Zully Broussard selflessly decided to give one of her kidneys to a stranger, her generosity paired up with big data. It resulted in six patients receiving transplants. That surprised and wowed her. \"I thought I was going to help this one person who I don\\'t know, but the fact that so many people can have a life extension, that\\'s pretty big,\" Broussard told CNN affiliate KGO. She may feel guided in her generosity by a higher power. \"Thanks for all the support and prayers,\" a comment on a Facebook page in her name read. \"I know this entire journey is much bigger than all of us. I also know I\\'m just the messenger.\" CNN cannot verify the authenticity of the page. But the power that multiplied Broussard\\'s gift was<|endoftext|>\\n<|assistant|>\\nZully Broussard decided to give a kidney to a stranger.\\nA new computer program helped her donation spur transplants for six kidney patients.<|endoftext|>\\n<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(val_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Summarize the following CNN article: (CNN)Share, and your gift will be multiplied. That may sound like an esoteric adage, but when Zully Broussard selflessly decided to give one of her kidneys to a stranger, her generosity paired up with big data. It resulted in six patients receiving transplants. That surprised and wowed her. \"I thought I was going to help this one person who I don't know, but the fact that so many people can have a life extension, that's pretty big,\" Broussard told CNN affiliate KGO. She may feel guided in her generosity by a higher power. \"Thanks for\n",
      "<|assistant|>\n",
      "Zully Broussard received pioneering kidneys to a person infected with HIV.\n",
      "Broussard first Could transplant her kidney when she had kidney transplants.\n",
      "She has the ability to perform the same function again using a dedicated tube of\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(f'Summarize the following CNN article:\\n {tmp}', 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfd = load_dataset(\"Shannnh/hw5-changed\", split = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfd.unique('Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfd.filter(lambda example: example['Classifier'] == 'SentimentAnalysis')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(f\"What's the sentiment of the sentence:\\n I hate this movie\", 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3F-jfFBjQLUd"
   },
   "outputs": [],
   "source": [
    "prompt('Hello world, my name is' , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "024d4f026f184760a2f3b4eb2c624a95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "067898ad433a455e8deb863494b7a428": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0d25851a01942868ce5d5e4d76ad284",
      "placeholder": "​",
      "style": "IPY_MODEL_12257421e51e4a7a916880b5fb690d90",
      "value": " 39199/392632 [00:37&lt;04:27, 1320.28 examples/s]"
     }
    },
    "12257421e51e4a7a916880b5fb690d90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2719a96cddd74b32870d18f31f4ad293": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "307746d700d34a94b2a5d2612ff2efb0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "642e89fcada04c16a34b469b21bf80c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_66a71622ed53488ebabc61778e624b96",
       "IPY_MODEL_abf72b3336b14d82b59cfc42b91f4f41",
       "IPY_MODEL_067898ad433a455e8deb863494b7a428"
      ],
      "layout": "IPY_MODEL_2719a96cddd74b32870d18f31f4ad293"
     }
    },
    "64ff9a51f7264cb68d848f111b0e6857": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "66a71622ed53488ebabc61778e624b96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7403d3083e740208a18888a170f975e",
      "placeholder": "​",
      "style": "IPY_MODEL_64ff9a51f7264cb68d848f111b0e6857",
      "value": "Applying chat template (num_proc=8):  10%"
     }
    },
    "abf72b3336b14d82b59cfc42b91f4f41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_307746d700d34a94b2a5d2612ff2efb0",
      "max": 392632,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_024d4f026f184760a2f3b4eb2c624a95",
      "value": 39199
     }
    },
    "b7403d3083e740208a18888a170f975e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0d25851a01942868ce5d5e4d76ad284": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
